//! Demonstration of automatic hyperparameter tuning and algorithm selection
//!
//! This example shows how to use the comprehensive auto-tuning capabilities in scirs2-cluster
//! to automatically find the best clustering algorithm and parameters for your data.

use ndarray::Array2;
use scirs2_cluster::preprocess::standardize;

// Auto-tuning imports
use scirs2_cluster::{
    auto_select_clustering_algorithm, quick_algorithm_selection, AutoClusteringSelector, AutoTuner,
    CVStrategy, ClusteringAlgorithm, CrossValidationConfig, EarlyStoppingConfig, EvaluationMetric,
    SearchStrategy, StandardSearchSpaces, TuningConfig,
};

#[allow(dead_code)]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("Automatic Hyperparameter Tuning Demo for scirs2-cluster");
    println!("=======================================================");

    // Create sample datasets with different characteristics
    let datasets = vec![
        ("Small Dense Clusters", create_dense_clusters_data(200, 2)),
        ("Large Sparse Data", create_sparse_data(2000, 5)),
        ("High Dimensional", create_high_dimensional_data(500, 20)),
        ("Noisy Data", create_noisy_data(800, 3)),
    ];

    for (dataset_name, data) in datasets {
        println!("\n{}", "=".repeat(60));
        println!("Dataset: {dataset_name}");
        println!(
            "Shape: {} samples × {} features",
            data.nrows(),
            data.ncols()
        );
        println!("{}", "=".repeat(60));

        // Standardize the data
        let standardized = standardize(data.view(), true)?;

        // Test different tuning approaches
        test_individual_algorithm_tuning(&standardized, dataset_name)?;
        test_automatic_algorithm_selection(&standardized, dataset_name)?;
        test_quick_selection(&standardized, dataset_name)?;
    }

    println!("\nAuto-tuning demo completed!");

    Ok(())
}

/// Test tuning individual algorithms
#[allow(dead_code)]
fn test_individual_algorithm_tuning(
    data: &Array2<f64>,
    dataset_name: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    println!("\n1. Individual Algorithm Tuning");
    println!("------------------------------");

    // Configure tuning with different strategies
    let tuning_configs = vec![
        (
            "Grid Search",
            TuningConfig {
                strategy: SearchStrategy::GridSearch,
                max_evaluations: 25,
                metric: EvaluationMetric::SilhouetteScore,
                cv_config: CrossValidationConfig {
                    strategy: CVStrategy::KFold { k: 3 },
                    shuffle: true,
                    random_seed: Some(42),
                },
                early_stopping: Some(EarlyStoppingConfig {
                    patience: 5,
                    min_improvement: 0.001,
                }),
                ..Default::default()
            },
        ),
        (
            "Random Search",
            TuningConfig {
                strategy: SearchStrategy::RandomSearch { n, trials: 30 },
                max_evaluations: 30,
                metric: EvaluationMetric::CalinskiHarabaszIndex,
                cv_config: CrossValidationConfig {
                    strategy: CVStrategy::KFold { k: 5 },
                    shuffle: true,
                    random_seed: Some(42),
                },
                early_stopping: Some(EarlyStoppingConfig {
                    patience: 8,
                    min_improvement: 0.01,
                }),
                ..Default::default()
            },
        ),
        (
            "Bayesian Optimization",
            TuningConfig {
                strategy: SearchStrategy::BayesianOptimization {
                    n_initial_points: 10,
                    acquisition_function: scirs2,
                    _cluster: AcquisitionFunction::ExpectedImprovement,
                },
                max_evaluations: 40,
                metric: EvaluationMetric::DaviesBouldinIndex,
                ..Default::default()
            },
        ),
    ];

    for (strategy_name, config) in tuning_configs {
        println!("\nTesting {strategy_name} for K-means:");

        let tuner = AutoTuner::new(config);
        let start_time = std::time::Instant::now();

        match tuner.tune_kmeans(data.view(), StandardSearchSpaces::kmeans()) {
            Ok(result) => {
                let duration = start_time.elapsed();
                println!("✓ {strategy_name} completed in {duration:.2?}");
                let best_score = result.best_score;
                println!("  - Best score: {best_score:.4}");
                println!(
                    "  - Best k: {:.0}",
                    result.best_parameters.get("n_clusters").unwrap_or(&0.0)
                );
                let evaluations = result.evaluation_history.len();
                println!("  - Evaluations: {evaluations}");
                println!(
                    "  - Convergence: {:?}",
                    result.convergence_info.stopping_reason
                );

                if !result.evaluation_history.is_empty() {
                    let scores: Vec<f64> =
                        result.evaluation_history.iter().map(|r| r.score).collect();
                    let improvement = scores.last().unwrap() - scores.first().unwrap();
                    println!("  - Score improvement: {improvement:.4}");
                }
            }
            Err(e) => {
                println!("× {strategy_name} failed: {e}");
            }
        }
    }

    // Test DBSCAN tuning with evolutionary search
    println!("\nTesting Evolutionary Search for DBSCAN:");
    let evolutionary_config = TuningConfig {
        strategy: SearchStrategy::EvolutionarySearch {
            population_size: 20,
            n_generations: 15,
            mutation_rate: 0.1,
            crossover_rate: 0.8,
        },
        max_evaluations: 50,
        metric: EvaluationMetric::SilhouetteScore,
        ..Default::default()
    };

    let tuner = AutoTuner::new(evolutionary_config);
    let start_time = std::time::Instant::now();

    match tuner.tune_dbscan(data.view(), StandardSearchSpaces::dbscan()) {
        Ok(result) => {
            let duration = start_time.elapsed();
            println!("✓ Evolutionary DBSCAN tuning completed in {duration:.2?}");
            let best_score_dbscan = result.best_score;
            println!("  - Best score: {best_score_dbscan:.4}");
            println!(
                "  - Best eps: {:.4}",
                result.best_parameters.get("eps").unwrap_or(&0.0)
            );
            println!(
                "  - Best min_samples: {:.0}",
                result.best_parameters.get("min_samples").unwrap_or(&0.0)
            );
            println!(
                "  - Final generation reached: {}",
                result.evaluation_history.len()
            );
        }
        Err(e) => {
            println!("× Evolutionary DBSCAN tuning failed: {e}");
        }
    }

    Ok(())
}

/// Test automatic algorithm selection
#[allow(dead_code)]
fn test_automatic_algorithm_selection(
    data: &Array2<f64>,
    dataset_name: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    println!("\n2. Automatic Algorithm Selection");
    println!("--------------------------------");

    // Full algorithm comparison
    let full_config = TuningConfig {
        strategy: SearchStrategy::RandomSearch { n, trials: 15 },
        max_evaluations: 15,
        metric: EvaluationMetric::SilhouetteScore,
        cv_config: CrossValidationConfig {
            strategy: CVStrategy::KFold { k: 3 },
            shuffle: true,
            random_seed: Some(42),
        },
        early_stopping: Some(EarlyStoppingConfig {
            patience: 5,
            min_improvement: 0.005,
        }),
        ..Default::default()
    };

    println!("Running comprehensive algorithm comparison...");
    let start_time = std::time::Instant::now();

    match auto_select_clustering_algorithm(data.view(), Some(full_config)) {
        Ok(result) => {
            let duration = start_time.elapsed();
            println!("✓ Algorithm selection completed in {duration:.2?}");
            println!("\nResults Summary:");
            let best_algo = &result.best_algorithm;
            println!("  - Best algorithm: {best_algo:?}");
            let best_score_selection = result.best_score;
            println!("  - Best score: {best_score_selection:.4}");
            let total_time = result.total_time;
            println!("  - Total evaluation time: {total_time:.2}s");

            // Show parameter details for best algorithm
            println!("\nBest Parameters:");
            for (param, value) in &result.best_parameters {
                println!("  - {}: {:.4}", param, value);
            }

            // Show all algorithm results
            println!("\nAll Algorithm Results:");
            let mut algorithm_scores: Vec<_> = result.algorithm_results.iter().collect();
            algorithm_scores.sort_by(|a, b| b.1.best_score.partial_cmp(&a.1.best_score).unwrap());

            for (algorithm, tuning_result) in algorithm_scores {
                println!(
                    "  - {:?}: {:.4} ({}s)",
                    algorithm, tuning_result.best_score, tuning_result.total_time as u32
                );
            }

            // Show recommendations
            if !result.recommendations.is_empty() {
                println!("\nRecommendations for '{dataset_name}':");
                for (i, recommendation) in result.recommendations.iter().enumerate() {
                    println!("  {}. {}", i + 1, recommendation);
                }
            }
        }
        Err(e) => {
            println!("× Algorithm selection failed: {e}");
        }
    }

    Ok(())
}

/// Test quick algorithm selection
#[allow(dead_code)]
fn test_quick_selection(
    data: &Array2<f64>,
    dataset_name: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    println!("\n3. Quick Algorithm Selection");
    println!("----------------------------");

    println!("Running quick selection (reduced search space)...");
    let start_time = std::time::Instant::now();

    match quick_algorithm_selection(data.view()) {
        Ok(result) => {
            let duration = start_time.elapsed();
            println!("✓ Quick selection completed in {duration:.2?}");
            let recommended = &result.best_algorithm;
            println!("  - Recommended algorithm: {recommended:?}");
            let quick_score = result.best_score;
            println!("  - Score: {quick_score:.4}");
            let tested_count = result.algorithm_results.len();
            println!("  - Algorithms tested: {tested_count}");

            // Show quick comparison
            for (algorithm, tuning_result) in &result.algorithm_results {
                println!("    - {:?}: {:.4}", algorithm, tuning_result.best_score);
            }

            if !result.recommendations.is_empty() {
                let tip = &result.recommendations[0];
                println!("  - Quick tip: {tip}");
            }
        }
        Err(e) => {
            println!("× Quick selection failed: {e}");
        }
    }

    Ok(())
}

/// Create dense cluster data for testing
#[allow(dead_code)]
fn create_dense_clusters_data(_n_samples: usize, nfeatures: usize) -> Array2<f64> {
    use rand::prelude::*;
    use rand_distr::Normal;

    let mut rng = StdRng::seed_from_u64(12345);
    let mut data = Vec::with_capacity(_n_samples * n_features);

    let n_clusters = 3;
    let samples_per_cluster = _n_samples / n_clusters;

    // Well-separated clusters
    let cluster_centers = vec![(0.0, 0.0), (5.0, 5.0), (-3.0, 4.0)];

    for (i, &(cx, cy)) in cluster_centers.iter().enumerate() {
        let cluster_samples = if i == cluster_centers.len() - 1 {
            _n_samples - i * samples_per_cluster
        } else {
            samples_per_cluster
        };

        let normal_x = Normal::new(cx, 0.8).unwrap();
        let normal_y = Normal::new(cy, 0.8).unwrap();

        for _ in 0..cluster_samples {
            data.push(rng.sample(normal_x));
            data.push(rng.sample(normal_y));

            // Add random _features
            for _ in 2..n_features {
                data.push(rng.random_range(-1.0..1.0));
            }
        }
    }

    Array2::from_shape_vec((n_samples..n_features), data).unwrap()
}

/// Create sparse data for testing
#[allow(dead_code)]
fn create_sparse_data(_n_samples: usize, nfeatures: usize) -> Array2<f64> {
    use rand::prelude::*;

    let mut rng = StdRng::seed_from_u64(67890);
    let mut data = Vec::with_capacity(_n_samples * n_features);

    // Create sparse clusters with many noise points
    for _ in 0.._n_samples {
        for _ in 0..n_features {
            if rng.random::<f64>() < 0.1 {
                // 10% density
                data.push(rng.random_range(-10.0..10.0));
            } else {
                data.push(0.0);
            }
        }
    }

    Array2::from_shape_vec((n_samples..n_features), data).unwrap()
}

/// Create high-dimensional data for testing
#[allow(dead_code)]
fn create_high_dimensional_data(_n_samples: usize, nfeatures: usize) -> Array2<f64> {
    use rand::prelude::*;

    let mut rng = StdRng::seed_from_u64(11111);
    let mut data = Vec::with_capacity(_n_samples * n_features);

    // Create data where only first few dimensions contain signal
    let signal_dims = 3;

    for _ in 0.._n_samples {
        // Signal dimensions
        for dim in 0..signal_dims {
            let cluster_id = dim % 3;
            let value = cluster_id as f64 * 3.0 + rng.random_range(-1.0..1.0);
            data.push(value);
        }

        // Noise dimensions
        for _ in signal_dims..n_features {
            data.push(rng.random_range(-0.5..0.5));
        }
    }

    Array2::from_shape_vec((n_samples..n_features), data).unwrap()
}

/// Create noisy data for testing
#[allow(dead_code)]
fn create_noisy_data(_n_samples: usize, nfeatures: usize) -> Array2<f64> {
    use rand::prelude::*;
    use rand_distr::Normal;

    let mut rng = StdRng::seed_from_u64(99999);
    let mut data = Vec::with_capacity(_n_samples * n_features);

    // Create clusters with significant noise
    let cluster_centers = vec![(2.0, 2.0), (-2.0, -2.0), (0.0, 3.0)];
    let noise_level = 2.0; // High noise

    for i in 0.._n_samples {
        let cluster_id = i % cluster_centers.len();
        let (cx, cy) = cluster_centers[cluster_id];

        let normal_x = Normal::new(cx, noise_level).unwrap();
        let normal_y = Normal::new(cy, noise_level).unwrap();

        data.push(rng.sample(normal_x));
        data.push(rng.sample(normal_y));

        // Additional noisy _features
        for _ in 2..n_features {
            data.push(rng.random_range(-3.0..3.0));
        }
    }

    Array2::from_shape_vec((n_samples..n_features), data).unwrap()
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_data_generation() {
        let dense_data = create_dense_clusters_data(150, 4);
        assert_eq!(dense_data.shape(), &[150, 4]);

        let sparse_data = create_sparse_data(100, 10);
        assert_eq!(sparse_data.shape(), &[100, 10]);

        let high_dim_data = create_high_dimensional_data(200, 50);
        assert_eq!(high_dim_data.shape(), &[200, 50]);

        let noisy_data = create_noisy_data(120, 3);
        assert_eq!(noisy_data.shape(), &[120, 3]);
    }

    #[test]
    fn test_auto_tuning_api() {
        let data = create_dense_clusters_data(50, 2);
        let standardized = standardize(data.view(), true).unwrap();

        // Test quick selection
        let result = quick_algorithm_selection(standardized.view());
        match result {
            Ok(selection_result) => {
                assert!(!selection_result.algorithm_results.is_empty());
                assert!(selection_result.best_score.is_finite());
            }
            Err(_) => {
                // Auto-tuning might fail in test environment due to insufficient data
                // This is acceptable for unit tests
            }
        }
    }
}
