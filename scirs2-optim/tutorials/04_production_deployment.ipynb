{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Production Deployment with SciRS2-Optim\n",
    "\n",
    "This tutorial covers best practices for deploying SciRS2-Optim in production environments, including scaling, monitoring, and maintenance strategies.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Production Architecture](#production-architecture)\n",
    "2. [Scaling and Performance](#scaling-performance)\n",
    "3. [Monitoring and Observability](#monitoring-observability)\n",
    "4. [Error Handling and Recovery](#error-handling)\n",
    "5. [Security and Compliance](#security-compliance)\n",
    "6. [Maintenance and Updates](#maintenance-updates)\n",
    "\n",
    "## Prerequisites\n",
    "- Completion of previous tutorials\n",
    "- Basic understanding of production systems\n",
    "- Familiarity with containerization and cloud platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up visualization style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"Set2\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"🚀 Production Deployment Tutorial - Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Production Architecture {#production-architecture}\n",
    "\n",
    "Designing scalable and maintainable production architectures for optimization systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_production_architecture():\n",
    "    \"\"\"Simulate different production architecture patterns for optimization systems.\"\"\"\n",
    "    \n",
    "    # Architecture patterns\n",
    "    architectures = {\n",
    "        'Monolithic': {\n",
    "            'scalability': 0.3,\n",
    "            'maintainability': 0.4,\n",
    "            'fault_tolerance': 0.2,\n",
    "            'deployment_complexity': 0.2,\n",
    "            'resource_efficiency': 0.8,\n",
    "            'development_speed': 0.9\n",
    "        },\n",
    "        'Microservices': {\n",
    "            'scalability': 0.9,\n",
    "            'maintainability': 0.7,\n",
    "            'fault_tolerance': 0.8,\n",
    "            'deployment_complexity': 0.8,\n",
    "            'resource_efficiency': 0.6,\n",
    "            'development_speed': 0.5\n",
    "        },\n",
    "        'Serverless': {\n",
    "            'scalability': 0.95,\n",
    "            'maintainability': 0.8,\n",
    "            'fault_tolerance': 0.9,\n",
    "            'deployment_complexity': 0.4,\n",
    "            'resource_efficiency': 0.9,\n",
    "            'development_speed': 0.7\n",
    "        },\n",
    "        'Hybrid (Edge + Cloud)': {\n",
    "            'scalability': 0.85,\n",
    "            'maintainability': 0.6,\n",
    "            'fault_tolerance': 0.85,\n",
    "            'deployment_complexity': 0.9,\n",
    "            'resource_efficiency': 0.8,\n",
    "            'development_speed': 0.4\n",
    "        },\n",
    "        'Container Orchestration': {\n",
    "            'scalability': 0.85,\n",
    "            'maintainability': 0.75,\n",
    "            'fault_tolerance': 0.8,\n",
    "            'deployment_complexity': 0.7,\n",
    "            'resource_efficiency': 0.7,\n",
    "            'development_speed': 0.6\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Deployment environments\n",
    "    environments = {\n",
    "        'Development': {\n",
    "            'instances': 1,\n",
    "            'cpu_cores': 4,\n",
    "            'memory_gb': 16,\n",
    "            'storage_gb': 100,\n",
    "            'availability_target': 0.95\n",
    "        },\n",
    "        'Staging': {\n",
    "            'instances': 2,\n",
    "            'cpu_cores': 8,\n",
    "            'memory_gb': 32,\n",
    "            'storage_gb': 500,\n",
    "            'availability_target': 0.98\n",
    "        },\n",
    "        'Production': {\n",
    "            'instances': 10,\n",
    "            'cpu_cores': 16,\n",
    "            'memory_gb': 64,\n",
    "            'storage_gb': 2000,\n",
    "            'availability_target': 0.999\n",
    "        },\n",
    "        'DR (Disaster Recovery)': {\n",
    "            'instances': 5,\n",
    "            'cpu_cores': 8,\n",
    "            'memory_gb': 32,\n",
    "            'storage_gb': 1000,\n",
    "            'availability_target': 0.99\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Performance characteristics\n",
    "    performance_metrics = {\n",
    "        'Request Latency (ms)': {\n",
    "            'p50': [50, 75, 120, 200, 90],\n",
    "            'p95': [100, 150, 300, 500, 180],\n",
    "            'p99': [200, 300, 600, 1000, 350]\n",
    "        },\n",
    "        'Throughput (req/s)': [1000, 5000, 10000, 3000, 7000],\n",
    "        'Resource Utilization (%)': [60, 40, 20, 55, 45],\n",
    "        'Cost Efficiency': [0.8, 0.6, 0.9, 0.5, 0.7]\n",
    "    }\n",
    "    \n",
    "    return architectures, environments, performance_metrics\n",
    "\n",
    "arch_patterns, deploy_envs, perf_metrics = simulate_production_architecture()\n",
    "\n",
    "# Visualize production architecture analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Production Architecture Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Architecture pattern comparison\n",
    "arch_names = list(arch_patterns.keys())\n",
    "metrics = ['Scalability', 'Maintainability', 'Fault Tolerance', 'Resource Efficiency']\n",
    "\n",
    "# Create radar chart for architecture patterns\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "ax_radar = plt.subplot(2, 3, 1, projection='polar')\n",
    "\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(arch_names)))\n",
    "for i, arch_name in enumerate(arch_names):\n",
    "    arch_data = arch_patterns[arch_name]\n",
    "    values = [\n",
    "        arch_data['scalability'],\n",
    "        arch_data['maintainability'],\n",
    "        arch_data['fault_tolerance'],\n",
    "        arch_data['resource_efficiency']\n",
    "    ]\n",
    "    values += [values[0]]  # Complete the circle\n",
    "    \n",
    "    ax_radar.plot(angles, values, 'o-', linewidth=2, \n",
    "                 label=arch_name.replace(' ', '\\n'), color=colors[i])\n",
    "    ax_radar.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "\n",
    "ax_radar.set_xticks(angles[:-1])\n",
    "ax_radar.set_xticklabels(metrics)\n",
    "ax_radar.set_ylim(0, 1)\n",
    "ax_radar.set_title('Architecture Pattern Comparison')\n",
    "ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "# Plot 2: Environment resource allocation\n",
    "env_names = list(deploy_envs.keys())\n",
    "cpu_cores = [deploy_envs[env]['cpu_cores'] * deploy_envs[env]['instances'] for env in env_names]\n",
    "memory_gb = [deploy_envs[env]['memory_gb'] * deploy_envs[env]['instances'] for env in env_names]\n",
    "storage_gb = [deploy_envs[env]['storage_gb'] * deploy_envs[env]['instances'] for env in env_names]\n",
    "\n",
    "x = np.arange(len(env_names))\n",
    "width = 0.25\n",
    "\n",
    "# Normalize for comparison\n",
    "max_cpu = max(cpu_cores)\n",
    "max_memory = max(memory_gb)\n",
    "max_storage = max(storage_gb)\n",
    "\n",
    "axes[0, 1].bar(x - width, [c/max_cpu for c in cpu_cores], width, label='CPU Cores', alpha=0.8)\n",
    "axes[0, 1].bar(x, [m/max_memory for m in memory_gb], width, label='Memory (GB)', alpha=0.8)\n",
    "axes[0, 1].bar(x + width, [s/max_storage for s in storage_gb], width, label='Storage (GB)', alpha=0.8)\n",
    "\n",
    "axes[0, 1].set_xlabel('Environment')\n",
    "axes[0, 1].set_ylabel('Normalized Resource Allocation')\n",
    "axes[0, 1].set_title('Resource Allocation by Environment')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(env_names, rotation=45, ha='right')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Performance vs complexity trade-offs\n",
    "complexity_scores = [arch_patterns[arch]['deployment_complexity'] for arch in arch_names]\n",
    "scalability_scores = [arch_patterns[arch]['scalability'] for arch in arch_names]\n",
    "dev_speed_scores = [arch_patterns[arch]['development_speed'] for arch in arch_names]\n",
    "\n",
    "# Create bubble chart\n",
    "bubble_sizes = [speed * 300 for speed in dev_speed_scores]\n",
    "scatter = axes[0, 2].scatter(complexity_scores, scalability_scores, s=bubble_sizes, \n",
    "                           c=range(len(arch_names)), cmap='viridis', alpha=0.7, edgecolors='black')\n",
    "\n",
    "for i, arch_name in enumerate(arch_names):\n",
    "    axes[0, 2].annotate(arch_name.replace(' ', '\\n'), \n",
    "                       (complexity_scores[i], scalability_scores[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[0, 2].set_xlabel('Deployment Complexity')\n",
    "axes[0, 2].set_ylabel('Scalability')\n",
    "axes[0, 2].set_title('Performance vs Complexity\\n(Bubble size = Development speed)')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Latency distribution comparison\n",
    "percentiles = ['p50', 'p95', 'p99']\n",
    "latency_data = perf_metrics['Request Latency (ms)']\n",
    "\n",
    "x = np.arange(len(arch_names))\n",
    "width = 0.25\n",
    "colors_latency = ['lightblue', 'orange', 'red']\n",
    "\n",
    "for i, percentile in enumerate(percentiles):\n",
    "    values = latency_data[percentile]\n",
    "    axes[1, 0].bar(x + i * width, values, width, label=percentile, \n",
    "                  color=colors_latency[i], alpha=0.8)\n",
    "\n",
    "axes[1, 0].set_xlabel('Architecture Pattern')\n",
    "axes[1, 0].set_ylabel('Latency (ms)')\n",
    "axes[1, 0].set_title('Latency Distribution by Architecture')\n",
    "axes[1, 0].set_xticks(x + width)\n",
    "axes[1, 0].set_xticklabels([name.replace(' ', '\\n') for name in arch_names], rotation=0)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].set_yscale('log')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Cost vs performance analysis\n",
    "throughput = perf_metrics['Throughput (req/s)']\n",
    "cost_efficiency = perf_metrics['Cost Efficiency']\n",
    "resource_util = perf_metrics['Resource Utilization (%)']\n",
    "\n",
    "scatter = axes[1, 1].scatter(cost_efficiency, throughput, s=[r*5 for r in resource_util], \n",
    "                           c=range(len(arch_names)), cmap='RdYlGn', alpha=0.7, edgecolors='black')\n",
    "\n",
    "for i, arch_name in enumerate(arch_names):\n",
    "    axes[1, 1].annotate(arch_name.replace(' ', '\\n'), \n",
    "                       (cost_efficiency[i], throughput[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1, 1].set_xlabel('Cost Efficiency')\n",
    "axes[1, 1].set_ylabel('Throughput (req/s)')\n",
    "axes[1, 1].set_title('Cost vs Performance\\n(Bubble size = Resource utilization)')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Deployment timeline\n",
    "deployment_phases = ['Planning', 'Development', 'Testing', 'Staging', 'Production', 'Monitoring']\n",
    "phase_durations = [2, 8, 4, 2, 1, 1]  # weeks\n",
    "cumulative_time = np.cumsum([0] + phase_durations[:-1])\n",
    "\n",
    "# Create Gantt chart\n",
    "colors_gantt = plt.cm.Set3(np.linspace(0, 1, len(deployment_phases)))\n",
    "for i, (phase, duration, start) in enumerate(zip(deployment_phases, phase_durations, cumulative_time)):\n",
    "    axes[1, 2].barh(i, duration, left=start, color=colors_gantt[i], alpha=0.7, edgecolor='black')\n",
    "    axes[1, 2].text(start + duration/2, i, f'{duration}w', ha='center', va='center', fontweight='bold')\n",
    "\n",
    "axes[1, 2].set_yticks(range(len(deployment_phases)))\n",
    "axes[1, 2].set_yticklabels(deployment_phases)\n",
    "axes[1, 2].set_xlabel('Timeline (weeks)')\n",
    "axes[1, 2].set_title('Production Deployment Timeline')\n",
    "axes[1, 2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"🏗️ Production Architecture Insights:\")\n",
    "print(\"   ✅ Serverless provides best scalability and cost efficiency\")\n",
    "print(\"   ✅ Microservices offer good fault tolerance and maintainability\")\n",
    "print(\"   ✅ Container orchestration balances complexity and performance\")\n",
    "print(\"   ⚠️  Hybrid architectures require careful coordination\")\n",
    "print(\"   ⚠️  Higher scalability often comes with increased complexity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Scaling and Performance {#scaling-performance}\n",
    "\n",
    "Strategies for scaling optimization workloads and managing performance in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_scaling_strategies():\n",
    "    \"\"\"Simulate different scaling strategies for optimization workloads.\"\"\"\n",
    "    \n",
    "    # Scaling strategies\n",
    "    scaling_strategies = {\n",
    "        'Horizontal Scaling': {\n",
    "            'cost_per_unit': 1.0,\n",
    "            'setup_complexity': 0.7,\n",
    "            'max_scale_factor': 100,\n",
    "            'fault_tolerance': 0.9,\n",
    "            'coordination_overhead': 0.3\n",
    "        },\n",
    "        'Vertical Scaling': {\n",
    "            'cost_per_unit': 1.5,\n",
    "            'setup_complexity': 0.3,\n",
    "            'max_scale_factor': 10,\n",
    "            'fault_tolerance': 0.4,\n",
    "            'coordination_overhead': 0.1\n",
    "        },\n",
    "        'Auto-scaling': {\n",
    "            'cost_per_unit': 0.8,\n",
    "            'setup_complexity': 0.8,\n",
    "            'max_scale_factor': 50,\n",
    "            'fault_tolerance': 0.8,\n",
    "            'coordination_overhead': 0.2\n",
    "        },\n",
    "        'Edge Computing': {\n",
    "            'cost_per_unit': 1.2,\n",
    "            'setup_complexity': 0.9,\n",
    "            'max_scale_factor': 1000,\n",
    "            'fault_tolerance': 0.7,\n",
    "            'coordination_overhead': 0.6\n",
    "        },\n",
    "        'Hybrid (Cloud + Edge)': {\n",
    "            'cost_per_unit': 1.1,\n",
    "            'setup_complexity': 0.95,\n",
    "            'max_scale_factor': 200,\n",
    "            'fault_tolerance': 0.85,\n",
    "            'coordination_overhead': 0.5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Performance scaling characteristics\n",
    "    load_levels = np.array([1, 10, 50, 100, 500, 1000, 5000])  # Concurrent requests\n",
    "    \n",
    "    # Response time scaling (ms)\n",
    "    response_times = {\n",
    "        'Single Instance': load_levels * 2 + 50,\n",
    "        'Load Balanced': np.minimum(load_levels * 0.5 + 30, 200),\n",
    "        'Auto-scaled': np.minimum(load_levels * 0.3 + 25, 100),\n",
    "        'Optimized Cache': np.minimum(load_levels * 0.1 + 15, 50)\n",
    "    }\n",
    "    \n",
    "    # Cost scaling\n",
    "    cost_scaling = {\n",
    "        'Fixed Infrastructure': np.full_like(load_levels, 1000, dtype=float),\n",
    "        'Pay-per-use': load_levels * 2,\n",
    "        'Reserved Capacity': np.minimum(load_levels * 0.8 + 200, 800),\n",
    "        'Spot Instances': load_levels * 0.6\n",
    "    }\n",
    "    \n",
    "    return scaling_strategies, load_levels, response_times, cost_scaling\n",
    "\n",
    "scaling_strats, load_levels, response_times, cost_scaling = simulate_scaling_strategies()\n",
    "\n",
    "# Visualize scaling and performance analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Scaling and Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Scaling strategy comparison\n",
    "strategy_names = list(scaling_strats.keys())\n",
    "metrics = ['Cost Efficiency', 'Setup Simplicity', 'Max Scale', 'Fault Tolerance']\n",
    "\n",
    "# Create radar chart\n",
    "angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)\n",
    "angles = np.concatenate((angles, [angles[0]]))\n",
    "\n",
    "ax_radar = plt.subplot(2, 3, 1, projection='polar')\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(strategy_names)))\n",
    "for i, strategy in enumerate(strategy_names):\n",
    "    strategy_data = scaling_strats[strategy]\n",
    "    values = [\n",
    "        1.0 / strategy_data['cost_per_unit'],  # Invert cost for efficiency\n",
    "        1.0 - strategy_data['setup_complexity'],  # Invert complexity for simplicity\n",
    "        strategy_data['max_scale_factor'] / 1000,  # Normalize scale factor\n",
    "        strategy_data['fault_tolerance']\n",
    "    ]\n",
    "    values += [values[0]]  # Complete the circle\n",
    "    \n",
    "    ax_radar.plot(angles, values, 'o-', linewidth=2, \n",
    "                 label=strategy.replace(' ', '\\n'), color=colors[i])\n",
    "    ax_radar.fill(angles, values, alpha=0.1, color=colors[i])\n",
    "\n",
    "ax_radar.set_xticks(angles[:-1])\n",
    "ax_radar.set_xticklabels(metrics)\n",
    "ax_radar.set_ylim(0, 1)\n",
    "ax_radar.set_title('Scaling Strategy Comparison')\n",
    "ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "\n",
    "# Plot 2: Response time vs load\n",
    "for strategy, times in response_times.items():\n",
    "    axes[0, 1].loglog(load_levels, times, 'o-', linewidth=2, markersize=6, label=strategy)\n",
    "\n",
    "axes[0, 1].set_xlabel('Concurrent Load (requests)')\n",
    "axes[0, 1].set_ylabel('Response Time (ms)')\n",
    "axes[0, 1].set_title('Response Time Scaling')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Cost vs load analysis\n",
    "for pricing_model, costs in cost_scaling.items():\n",
    "    axes[0, 2].loglog(load_levels, costs, 'o-', linewidth=2, markersize=6, label=pricing_model)\n",
    "\n",
    "axes[0, 2].set_xlabel('Load Level (requests)')\n",
    "axes[0, 2].set_ylabel('Cost ($)')\n",
    "axes[0, 2].set_title('Cost Scaling Models')\n",
    "axes[0, 2].legend()\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Auto-scaling behavior simulation\n",
    "time_hours = np.arange(0, 24, 0.5)\n",
    "# Simulate daily traffic pattern\n",
    "base_load = 100\n",
    "daily_pattern = base_load * (1 + 0.5 * np.sin(2 * np.pi * (time_hours - 6) / 24))\n",
    "traffic_spikes = np.random.random(len(time_hours)) < 0.1  # 10% chance of spike\n",
    "daily_pattern[traffic_spikes] *= 3\n",
    "\n",
    "# Auto-scaling response (with lag)\n",
    "instances = np.ones_like(time_hours)\n",
    "for i in range(1, len(time_hours)):\n",
    "    target_instances = max(1, int(daily_pattern[i] / 50))  # Scale at 50 req/instance\n",
    "    # Gradual scaling with lag\n",
    "    instances[i] = instances[i-1] + 0.3 * (target_instances - instances[i-1])\n",
    "\n",
    "ax_twin = axes[1, 0].twinx()\n",
    "axes[1, 0].plot(time_hours, daily_pattern, 'b-', linewidth=2, label='Traffic Load')\n",
    "ax_twin.plot(time_hours, instances, 'r-', linewidth=2, label='Instance Count')\n",
    "\n",
    "axes[1, 0].set_xlabel('Time (hours)')\n",
    "axes[1, 0].set_ylabel('Request Load', color='blue')\n",
    "ax_twin.set_ylabel('Instance Count', color='red')\n",
    "axes[1, 0].set_title('Auto-scaling Behavior Over 24h')\n",
    "axes[1, 0].legend(loc='upper left')\n",
    "ax_twin.legend(loc='upper right')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Resource utilization optimization\n",
    "optimization_techniques = ['Baseline', 'Connection\\nPooling', 'Request\\nBatching', \n",
    "                          'Caching', 'Load\\nBalancing', 'All\\nOptimizations']\n",
    "cpu_utilization = [85, 70, 60, 55, 45, 35]\n",
    "memory_utilization = [80, 75, 65, 50, 60, 40]\n",
    "throughput_improvement = [1.0, 1.2, 1.5, 1.8, 2.0, 3.0]\n",
    "\n",
    "x = np.arange(len(optimization_techniques))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[1, 1].bar(x - width/2, cpu_utilization, width, label='CPU %', alpha=0.8)\n",
    "bars2 = axes[1, 1].bar(x + width/2, memory_utilization, width, label='Memory %', alpha=0.8)\n",
    "\n",
    "# Overlay throughput improvement\n",
    "ax_twin2 = axes[1, 1].twinx()\n",
    "ax_twin2.plot(x, throughput_improvement, 'ro-', linewidth=3, markersize=8, label='Throughput Gain')\n",
    "\n",
    "axes[1, 1].set_xlabel('Optimization Technique')\n",
    "axes[1, 1].set_ylabel('Resource Utilization (%)')\n",
    "ax_twin2.set_ylabel('Throughput Multiplier', color='red')\n",
    "axes[1, 1].set_title('Performance Optimization Impact')\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(optimization_techniques, rotation=45, ha='right')\n",
    "axes[1, 1].legend(loc='upper left')\n",
    "ax_twin2.legend(loc='upper right')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Performance bottleneck analysis\n",
    "bottlenecks = ['CPU', 'Memory', 'I/O', 'Network', 'Database', 'External APIs']\n",
    "frequency = [0.3, 0.25, 0.2, 0.15, 0.35, 0.4]  # How often each is a bottleneck\n",
    "impact_severity = [0.7, 0.8, 0.9, 0.6, 0.85, 0.95]  # Impact when it is a bottleneck\n",
    "detection_difficulty = [0.2, 0.3, 0.6, 0.5, 0.4, 0.8]  # How hard to detect\n",
    "\n",
    "# Create bubble chart\n",
    "bubble_sizes = [f * i * 1000 for f, i in zip(frequency, impact_severity)]\n",
    "scatter = axes[1, 2].scatter(detection_difficulty, impact_severity, s=bubble_sizes, \n",
    "                           c=frequency, cmap='Reds', alpha=0.7, edgecolors='black')\n",
    "\n",
    "for i, bottleneck in enumerate(bottlenecks):\n",
    "    axes[1, 2].annotate(bottleneck, (detection_difficulty[i], impact_severity[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1, 2].set_xlabel('Detection Difficulty')\n",
    "axes[1, 2].set_ylabel('Impact Severity')\n",
    "axes[1, 2].set_title('Performance Bottleneck Analysis\\n(Bubble size = Frequency × Impact)')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(scatter, ax=axes[1, 2], label='Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📈 Scaling and Performance Insights:\")\n",
    "print(\"   ✅ Auto-scaling provides best cost-performance balance\")\n",
    "print(\"   ✅ Caching significantly reduces resource utilization\")\n",
    "print(\"   ✅ External API dependencies are major bottlenecks\")\n",
    "print(\"   ✅ Load balancing improves fault tolerance\")\n",
    "print(\"   ⚠️  Edge computing requires complex coordination\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Monitoring and Observability {#monitoring-observability}\n",
    "\n",
    "Comprehensive monitoring strategies for production optimization systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_monitoring_system():\n",
    "    \"\"\"Simulate a comprehensive monitoring and observability system.\"\"\"\n",
    "    \n",
    "    # Monitoring metrics categories\n",
    "    metric_categories = {\n",
    "        'Infrastructure': {\n",
    "            'metrics': ['CPU Usage', 'Memory Usage', 'Disk I/O', 'Network I/O'],\n",
    "            'collection_frequency': 'every 15s',\n",
    "            'retention_period': '30 days',\n",
    "            'alerting_threshold': 80\n",
    "        },\n",
    "        'Application': {\n",
    "            'metrics': ['Request Rate', 'Response Time', 'Error Rate', 'Queue Depth'],\n",
    "            'collection_frequency': 'every 5s',\n",
    "            'retention_period': '90 days',\n",
    "            'alerting_threshold': 95\n",
    "        },\n",
    "        'Business': {\n",
    "            'metrics': ['Optimization Success Rate', 'Model Accuracy', 'User Satisfaction'],\n",
    "            'collection_frequency': 'every 1m',\n",
    "            'retention_period': '1 year',\n",
    "            'alerting_threshold': 90\n",
    "        },\n",
    "        'Security': {\n",
    "            'metrics': ['Failed Logins', 'API Rate Limits', 'Anomalous Patterns'],\n",
    "            'collection_frequency': 'real-time',\n",
    "            'retention_period': '2 years',\n",
    "            'alerting_threshold': 99\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Alert severity levels\n",
    "    alert_levels = {\n",
    "        'Critical': {\n",
    "            'response_time_minutes': 5,\n",
    "            'escalation_levels': 3,\n",
    "            'notification_channels': ['SMS', 'Phone', 'Slack', 'Email'],\n",
    "            'auto_remediation': True\n",
    "        },\n",
    "        'High': {\n",
    "            'response_time_minutes': 15,\n",
    "            'escalation_levels': 2,\n",
    "            'notification_channels': ['Slack', 'Email'],\n",
    "            'auto_remediation': False\n",
    "        },\n",
    "        'Medium': {\n",
    "            'response_time_minutes': 60,\n",
    "            'escalation_levels': 1,\n",
    "            'notification_channels': ['Email'],\n",
    "            'auto_remediation': False\n",
    "        },\n",
    "        'Low': {\n",
    "            'response_time_minutes': 240,\n",
    "            'escalation_levels': 1,\n",
    "            'notification_channels': ['Dashboard'],\n",
    "            'auto_remediation': False\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Generate sample monitoring data\n",
    "    time_points = np.arange(0, 24, 0.1)  # 24 hours in 6-minute intervals\n",
    "    \n",
    "    # Simulate different metrics over time\n",
    "    monitoring_data = {\n",
    "        'CPU Usage (%)': 45 + 20 * np.sin(2 * np.pi * time_points / 24) + 5 * np.random.normal(0, 1, len(time_points)),\n",
    "        'Memory Usage (%)': 60 + 15 * np.sin(2 * np.pi * (time_points - 3) / 24) + 3 * np.random.normal(0, 1, len(time_points)),\n",
    "        'Response Time (ms)': 120 + 50 * np.sin(2 * np.pi * (time_points - 6) / 24) + 10 * np.random.normal(0, 1, len(time_points)),\n",
    "        'Error Rate (%)': np.maximum(0, 2 + 3 * np.sin(2 * np.pi * time_points / 12) + 2 * np.random.normal(0, 1, len(time_points))),\n",
    "        'Throughput (req/s)': 1000 + 500 * np.sin(2 * np.pi * (time_points - 9) / 24) + 50 * np.random.normal(0, 1, len(time_points))\n",
    "    }\n",
    "    \n",
    "    # Ensure realistic bounds\n",
    "    monitoring_data['CPU Usage (%)'] = np.clip(monitoring_data['CPU Usage (%)'], 0, 100)\n",
    "    monitoring_data['Memory Usage (%)'] = np.clip(monitoring_data['Memory Usage (%)'], 0, 100)\n",
    "    monitoring_data['Response Time (ms)'] = np.maximum(monitoring_data['Response Time (ms)'], 50)\n",
    "    monitoring_data['Error Rate (%)'] = np.clip(monitoring_data['Error Rate (%)'], 0, 10)\n",
    "    monitoring_data['Throughput (req/s)'] = np.maximum(monitoring_data['Throughput (req/s)'], 100)\n",
    "    \n",
    "    return metric_categories, alert_levels, time_points, monitoring_data\n",
    "\n",
    "metric_cats, alert_levels, time_points, monitoring_data = simulate_monitoring_system()\n",
    "\n",
    "# Visualize monitoring and observability\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "fig.suptitle('Monitoring and Observability Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Real-time metrics dashboard\n",
    "metric_names = list(monitoring_data.keys())\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(metric_names)))\n",
    "\n",
    "for i, (metric, data) in enumerate(monitoring_data.items()):\n",
    "    if 'Usage' in metric:\n",
    "        axes[0, 0].plot(time_points, data, label=metric, linewidth=2, color=colors[i])\n",
    "        \n",
    "        # Add alert threshold lines\n",
    "        if 'CPU' in metric:\n",
    "            axes[0, 0].axhline(y=80, color='red', linestyle='--', alpha=0.7)\n",
    "        elif 'Memory' in metric:\n",
    "            axes[0, 0].axhline(y=85, color='orange', linestyle='--', alpha=0.7)\n",
    "\n",
    "axes[0, 0].set_xlabel('Time (hours)')\n",
    "axes[0, 0].set_ylabel('Usage (%)')\n",
    "axes[0, 0].set_title('Resource Usage Monitoring')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_ylim(0, 100)\n",
    "\n",
    "# Plot 2: Performance metrics\n",
    "ax_twin = axes[0, 1].twinx()\n",
    "axes[0, 1].plot(time_points, monitoring_data['Response Time (ms)'], 'b-', linewidth=2, label='Response Time')\n",
    "ax_twin.plot(time_points, monitoring_data['Throughput (req/s)'], 'g-', linewidth=2, label='Throughput')\n",
    "\n",
    "axes[0, 1].axhline(y=200, color='red', linestyle='--', alpha=0.7, label='SLA Threshold')\n",
    "\n",
    "axes[0, 1].set_xlabel('Time (hours)')\n",
    "axes[0, 1].set_ylabel('Response Time (ms)', color='blue')\n",
    "ax_twin.set_ylabel('Throughput (req/s)', color='green')\n",
    "axes[0, 1].set_title('Performance Metrics')\n",
    "axes[0, 1].legend(loc='upper left')\n",
    "ax_twin.legend(loc='upper right')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error rate and alerts\n",
    "error_data = monitoring_data['Error Rate (%)']\n",
    "alert_threshold = 5.0\n",
    "alert_points = error_data > alert_threshold\n",
    "\n",
    "axes[1, 0].plot(time_points, error_data, 'r-', linewidth=2, label='Error Rate')\n",
    "axes[1, 0].scatter(time_points[alert_points], error_data[alert_points], \n",
    "                  color='red', s=50, marker='x', label='Alerts Triggered')\n",
    "axes[1, 0].axhline(y=alert_threshold, color='orange', linestyle='--', \n",
    "                  alpha=0.7, label='Alert Threshold')\n",
    "\n",
    "axes[1, 0].set_xlabel('Time (hours)')\n",
    "axes[1, 0].set_ylabel('Error Rate (%)')\n",
    "axes[1, 0].set_title('Error Rate Monitoring with Alerts')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_ylim(0, max(error_data) * 1.1)\n",
    "\n",
    "# Plot 4: Alert distribution by severity\n",
    "alert_severities = list(alert_levels.keys())\n",
    "alert_counts = [15, 8, 25, 45]  # Sample alert counts\n",
    "response_times = [alert_levels[sev]['response_time_minutes'] for sev in alert_severities]\n",
    "\n",
    "# Create combined bar and line plot\n",
    "bars = axes[1, 1].bar(alert_severities, alert_counts, alpha=0.7, \n",
    "                     color=['red', 'orange', 'yellow', 'lightblue'])\n",
    "\n",
    "ax_twin3 = axes[1, 1].twinx()\n",
    "ax_twin3.plot(alert_severities, response_times, 'ko-', linewidth=3, markersize=8)\n",
    "\n",
    "axes[1, 1].set_xlabel('Alert Severity')\n",
    "axes[1, 1].set_ylabel('Alert Count')\n",
    "ax_twin3.set_ylabel('Response Time (minutes)', color='black')\n",
    "axes[1, 1].set_title('Alert Distribution and Response Times')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, alert_counts):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                   str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 5: SLA compliance tracking\n",
    "sla_metrics = ['Availability', 'Response Time', 'Error Rate', 'Throughput']\n",
    "sla_targets = [99.9, 200, 1.0, 1000]  # Target values\n",
    "actual_performance = [99.85, 180, 1.2, 1050]  # Actual values\n",
    "compliance_status = ['✅', '✅', '❌', '✅']\n",
    "\n",
    "# Normalize for comparison\n",
    "normalized_targets = [100] * len(sla_metrics)\n",
    "normalized_actual = []\n",
    "for i, (target, actual) in enumerate(zip(sla_targets, actual_performance)):\n",
    "    if 'Error Rate' in sla_metrics[i]:\n",
    "        # For error rate, lower is better\n",
    "        normalized_actual.append(100 * target / actual if actual > 0 else 100)\n",
    "    else:\n",
    "        # For others, higher is better\n",
    "        normalized_actual.append(100 * actual / target)\n",
    "\n",
    "x = np.arange(len(sla_metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[2, 0].bar(x - width/2, normalized_targets, width, \n",
    "                      label='SLA Target', alpha=0.8, color='lightblue')\n",
    "bars2 = axes[2, 0].bar(x + width/2, normalized_actual, width, \n",
    "                      label='Actual Performance', alpha=0.8, color='lightgreen')\n",
    "\n",
    "# Add compliance status as text\n",
    "for i, status in enumerate(compliance_status):\n",
    "    axes[2, 0].text(i, max(normalized_targets[i], normalized_actual[i]) + 5, \n",
    "                   status, ha='center', va='bottom', fontsize=16)\n",
    "\n",
    "axes[2, 0].set_xlabel('SLA Metrics')\n",
    "axes[2, 0].set_ylabel('Performance (% of target)')\n",
    "axes[2, 0].set_title('SLA Compliance Dashboard')\n",
    "axes[2, 0].set_xticks(x)\n",
    "axes[2, 0].set_xticklabels(sla_metrics, rotation=45, ha='right')\n",
    "axes[2, 0].legend()\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "axes[2, 0].axhline(y=100, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Plot 6: Monitoring tool comparison\n",
    "monitoring_tools = {\n",
    "    'Prometheus': {'cost': 0.2, 'complexity': 0.6, 'features': 0.8, 'scalability': 0.9},\n",
    "    'DataDog': {'cost': 0.8, 'complexity': 0.3, 'features': 0.95, 'scalability': 0.8},\n",
    "    'New Relic': {'cost': 0.7, 'complexity': 0.4, 'features': 0.9, 'scalability': 0.7},\n",
    "    'CloudWatch': {'cost': 0.5, 'complexity': 0.5, 'features': 0.7, 'scalability': 0.8},\n",
    "    'Grafana': {'cost': 0.3, 'complexity': 0.7, 'features': 0.75, 'scalability': 0.6}\n",
    "}\n",
    "\n",
    "tool_names = list(monitoring_tools.keys())\n",
    "feature_scores = [monitoring_tools[tool]['features'] for tool in tool_names]\n",
    "cost_scores = [1 - monitoring_tools[tool]['cost'] for tool in tool_names]  # Invert cost for efficiency\n",
    "complexity_scores = [1 - monitoring_tools[tool]['complexity'] for tool in tool_names]  # Invert for ease\n",
    "\n",
    "# Create bubble chart\n",
    "bubble_sizes = [monitoring_tools[tool]['scalability'] * 300 for tool in tool_names]\n",
    "scatter = axes[2, 1].scatter(cost_scores, feature_scores, s=bubble_sizes, \n",
    "                           c=complexity_scores, cmap='RdYlGn', alpha=0.7, edgecolors='black')\n",
    "\n",
    "for i, tool in enumerate(tool_names):\n",
    "    axes[2, 1].annotate(tool, (cost_scores[i], feature_scores[i]), \n",
    "                       xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[2, 1].set_xlabel('Cost Efficiency')\n",
    "axes[2, 1].set_ylabel('Feature Richness')\n",
    "axes[2, 1].set_title('Monitoring Tool Comparison\\n(Bubble size = Scalability, Color = Ease of use)')\n",
    "axes[2, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.colorbar(scatter, ax=axes[2, 1], label='Ease of Use')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"📊 Monitoring and Observability Insights:\")\n",
    "print(\"   ✅ Real-time monitoring prevents cascading failures\")\n",
    "print(\"   ✅ Multi-level alerting ensures appropriate response\")\n",
    "print(\"   ✅ SLA tracking maintains service quality\")\n",
    "print(\"   ✅ Automated remediation reduces MTTR\")\n",
    "print(\"   ⚠️  Alert fatigue can reduce effectiveness\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial covered essential aspects of production deployment for SciRS2-Optim:\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "**Production Architecture:**\n",
    "- Serverless provides excellent scalability and cost efficiency\n",
    "- Microservices offer good fault tolerance and maintainability\n",
    "- Container orchestration balances complexity and performance\n",
    "- Architecture choice depends on scale and requirements\n",
    "\n",
    "**Scaling and Performance:**\n",
    "- Auto-scaling provides optimal cost-performance balance\n",
    "- Caching significantly reduces resource utilization\n",
    "- Load balancing improves fault tolerance\n",
    "- External dependencies often become bottlenecks\n",
    "\n",
    "**Monitoring and Observability:**\n",
    "- Real-time monitoring prevents cascading failures\n",
    "- Multi-level alerting ensures appropriate responses\n",
    "- SLA tracking maintains service quality\n",
    "- Comprehensive metrics across all system layers\n",
    "\n",
    "### Best Practices:\n",
    "1. **Design for failure** - Assume components will fail\n",
    "2. **Monitor everything** - Infrastructure, application, and business metrics\n",
    "3. **Automate responses** - Reduce manual intervention where possible\n",
    "4. **Plan capacity** - Understand scaling characteristics\n",
    "5. **Test at scale** - Validate performance under realistic loads\n",
    "6. **Gradual rollouts** - Use blue-green or canary deployments\n",
    "\n",
    "### Deployment Checklist:\n",
    "- [ ] Architecture pattern selected and validated\n",
    "- [ ] Monitoring and alerting configured\n",
    "- [ ] Auto-scaling policies defined\n",
    "- [ ] Security measures implemented\n",
    "- [ ] Disaster recovery plan established\n",
    "- [ ] Performance benchmarks documented\n",
    "- [ ] SLA targets defined and tracked\n",
    "\n",
    "### Next Steps:\n",
    "- Implement monitoring for your specific use case\n",
    "- Set up automated testing and deployment pipelines\n",
    "- Create runbooks for common issues\n",
    "- Establish performance baselines\n",
    "- Plan for capacity growth\n",
    "\n",
    "Ready for production! Continue with custom optimizer development tutorial! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}