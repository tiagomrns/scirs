//! Enhanced Serialization and Workflow Demo
//!
//! This example demonstrates the new advanced serialization features implemented in scirs2-cluster:
//! 1. Unified clustering workflow management with state persistence
//! 2. Enhanced dendrogram export with JSON format
//! 3. Bidirectional compatibility with scikit-learn and SciPy
//!
//! Run with: cargo run --example enhanced_serialization_demo

use ndarray::{Array1, Array2};
use scirs2_cluster::{
    hierarchy::linkage,
    hierarchy::{LinkageMethod, Metric},
    preprocess::standardize,
    serialization::{
        export_to_sklearn_json, import_sklearn_kmeans, compatibility,
        AlgorithmState, ClusteringWorkflow, ClusteringWorkflowManager, HierarchicalModel,
        KMeansModel, SerializableModel, TrainingStep, WorkflowConfig,
    },
    vq::kmeans,
};
use std::collections::HashMap;
use tempfile::TempDir;

#[allow(dead_code)]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("üöÄ Enhanced Serialization and Workflow Demo");
    println!("===========================================\n");

    // Create sample dataset
    let data = create_sample_data()?;
    println!(
        "üìä Created sample dataset with {} samples and {} features\n",
        data.nrows(),
        data.ncols()
    );

    // Demo 1: Unified Workflow Management
    demo_unified_workflow(&data)?;

    // Demo 2: Enhanced Dendrogram JSON Export
    demo_dendrogram_json_export(&data)?;

    // Demo 3: Scikit-learn/SciPy Compatibility
    demo_sklearn_scipy_compatibility(&data)?;

    println!("‚úÖ All enhanced serialization features demonstrated successfully!");
    Ok(())
}

/// Create sample clustering data with clear cluster structure
#[allow(dead_code)]
fn create_sample_data() -> Result<Array2<f64>, Box<dyn std::error::Error>> {
    // Create three distinct clusters
    let mut data = Vec::new();

    // Cluster 1: Around (0, 0)
    for i in 0..20 {
        data.push(0.0 + (i as f64 * 0.1 - 1.0));
        data.push(0.0 + ((i % 3) as f64 * 0.1 - 0.1));
    }

    // Cluster 2: Around (5, 5)
    for i in 0..20 {
        data.push(5.0 + (i as f64 * 0.1 - 1.0));
        data.push(5.0 + ((i % 3) as f64 * 0.1 - 0.1));
    }

    // Cluster 3: Around (-3, 4)
    for i in 0..20 {
        data.push(-3.0 + (i as f64 * 0.1 - 1.0));
        data.push(4.0 + ((i % 3) as f64 * 0.1 - 0.1));
    }

    let array = Array2::from_shape_vec((60, 2), data)?;
    let standardized = standardize(array.view(), true)?;
    Ok(standardized)
}

/// Demonstrate unified clustering workflow management
#[allow(dead_code)]
fn demo_unified_workflow(data: &Array2<f64>) -> Result<(), Box<dyn std::error::Error>> {
    println!("üîÑ Demo 1: Unified Clustering Workflow Management");
    println!("=================================================");

    // Create temporary directory for workflow storage
    let temp_dir = TempDir::new()?;
    let manager = ClusteringWorkflowManager::new(temp_dir.path(), temp_dir.path());

    // Create a new K-means workflow
    let mut workflow = ClusteringWorkflow::new(
        "kmeans_demo".to_string(),
        "K-means clustering demo workflow".to_string(),
        "k-means".to_string(),
    );

    println!("üìù Created workflow: {}", workflow.name);
    println!("   ID: {}", workflow.id);

    // Configure workflow
    workflow.config.auto_save_interval = 5;
    workflow.config.max_history_length = 50;
    workflow.config.hyperparameters.insert(
        "n_clusters".to_string(),
        serde_json::Value::Number(serde_json::Number::from(3)),
    );

    // Simulate K-means training with state updates
    let mut current_centroids = initialize_centroids(data, 3)?;

    for iteration in 0..10 {
        // Update algorithm state
        let converged = iteration >= 7; // Simulate convergence
        let inertia = 100.0 - iteration as f64 * 10.0; // Simulate decreasing inertia

        workflow.update_state(AlgorithmState::KMeans {
            centroids: current_centroids.clone(),
            iteration,
            inertia,
            converged,
            labels: None,
        });

        // Add training step to history
        let mut metrics = HashMap::new();
        metrics.insert("inertia".to_string(), inertia);
        metrics.insert("iteration".to_string(), iteration as f64);

        let training_step = TrainingStep {
            step: iteration,
            timestamp: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)?
                .as_secs(),
            metrics,
            converged,
            memory_usage: Some(1024 * 1024), // 1MB simulated
            step_duration_ms: (50 + iteration * 5) as u64, // Simulate varying step times
        };

        workflow.add_training_step(training_step);

        if converged {
            break;
        }
    }

    // Run actual K-means and save final model
    let (final_centroids, labels) = kmeans(data.view(), 3, None, None, None, None)?;
    let labels_usize = labels.mapv(|x| x as usize);
    let kmeans_model = KMeansModel::new(final_centroids, 3, 10, 42.5, Some(labels_usize));
    workflow.set_model(&kmeans_model)?;

    println!("üéØ K-means training completed:");
    println!("   - Iterations: {}", workflow.current_iteration());
    println!("   - Converged: {}", workflow.is_completed());
    println!("   - History length: {}", workflow.training_history.len());

    // Save workflow
    let workflow_path = manager.save_workflow(&workflow)?;
    println!("üíæ Workflow saved to: {:?}", workflow_path);

    // Demonstrate loading and resuming
    let loaded_workflow = manager.load_workflow("kmeans_demo")?;
    println!("üìÇ Workflow loaded successfully");

    // Check that the model was preserved
    let loaded_model: Option<KMeansModel> = loaded_workflow.get_model()?;
    if let Some(model) = loaded_model {
        println!(
            "‚úÖ Model recovered: {} clusters, {} iterations",
            model.n_clusters, model.n_iter
        );
    }

    // List all workflows
    let workflows = manager.list_workflows()?;
    println!("üìã Available workflows: {:?}", workflows);

    println!();
    Ok(())
}

/// Demonstrate enhanced dendrogram JSON export
#[allow(dead_code)]
fn demo_dendrogram_json_export(data: &Array2<f64>) -> Result<(), Box<dyn std::error::Error>> {
    println!("üå≥ Demo 2: Enhanced Dendrogram JSON Export");
    println!("==========================================");

    // Perform hierarchical clustering
    let linkage_matrix = linkage(data.view(), LinkageMethod::Ward, Metric::Euclidean)?;
    println!(
        "üîó Generated linkage matrix: {} merges",
        linkage_matrix.nrows()
    );

    // Create hierarchical model with labels
    let labels = (0..data.nrows())
        .map(|i| format!("Sample_{}", i))
        .collect::<Vec<String>>();

    let hier_model = HierarchicalModel::new(
        linkage_matrix,
        data.nrows(),
        "ward".to_string(),
        Some(labels),
    );

    // Export to traditional Newick format
    let newick_format = hier_model.to_newick()?;
    println!(
        "üìÑ Newick format (first 100 chars): {}...",
        &newick_format[..newick_format.len().min(100)]
    );

    // Export to new JSON format
    let json_dendrogram = hier_model.to_json_dendrogram()?;
    println!("üéØ JSON dendrogram export successful!");

    // Parse and display structure information
    let json_data: serde_json::Value = serde_json::from_str(&json_dendrogram)?;
    println!(
        "   - Format: {}",
        json_data["type"].as_str().unwrap_or("unknown")
    );
    println!(
        "   - Samples: {}",
        json_data["n_samples"].as_u64().unwrap_or(0)
    );
    println!(
        "   - Method: {}",
        json_data["method"].as_str().unwrap_or("unknown")
    );
    println!(
        "   - Total nodes: {}",
        json_data["metadata"]["total_nodes"].as_u64().unwrap_or(0)
    );

    // Save to temporary file for demonstration
    let temp_dir = TempDir::new()?;
    let json_path = temp_dir.path().join("dendrogram.json");
    std::fs::write(&json_path, &json_dendrogram)?;
    println!("üíæ JSON dendrogram saved to: {:?}", json_path);

    println!();
    Ok(())
}

/// Demonstrate scikit-learn and SciPy compatibility
#[allow(dead_code)]
fn demo_sklearn_scipy_compatibility(data: &Array2<f64>) -> Result<(), Box<dyn std::error::Error>> {
    println!("üêç Demo 3: Scikit-learn/SciPy Compatibility");
    println!("===========================================");

    // Create K-means model
    let (centroids, labels) = kmeans(data.view(), 3, None, None, None, None)?;
    let labels_usize = labels.mapv(|x| x as usize);
    let kmeans_model = KMeansModel::new(centroids.clone(), 3, 15, 38.2, Some(labels_usize));

    println!("ü§ñ Created K-means model:");
    println!("   - Clusters: {}", kmeans_model.n_clusters);
    println!("   - Iterations: {}", kmeans_model.n_iter);
    println!("   - Inertia: {:.2}", kmeans_model.inertia);

    let temp_dir = TempDir::new()?;

    // Export to scikit-learn compatible format
    let sklearn_path = temp_dir.path().join("sklearn_kmeans.json");
    export_to_sklearn_json(&kmeans_model, &sklearn_path)?;
    println!("üì§ Exported to scikit-learn format: {:?}", sklearn_path);

    // Create test scikit-learn compatible JSON for import demo
    let sklearn_json = create_sklearn_test_data(&centroids);
    let sklearn_test_path = temp_dir.path().join("sklearn_test.json");
    std::fs::write(&sklearn_test_path, &sklearn_json)?;

    // Import from scikit-learn format
    let imported_model = import_sklearn_kmeans(&sklearn_test_path)?;
    println!("üì• Imported from scikit-learn format:");
    println!("   - Clusters: {}", imported_model.n_clusters);
    println!("   - Centroids shape: {:?}", imported_model.centroids.dim());

    // Verify model consistency
    let originalshape = kmeans_model.centroids.dim();
    let importedshape = imported_model.centroids.dim();

    if originalshape == importedshape {
        println!("‚úÖ Model import/export consistency verified!");
    } else {
        println!(
            "‚ö†Ô∏è  Shape mismatch: {:?} vs {:?}",
            originalshape, importedshape
        );
    }

    // Demonstrate enhanced metadata export
    use scirs2_cluster::serialization::AdvancedExport;
    println!("\nüìã Model Metadata:");
    let metadata = kmeans_model.get_metadata();
    println!("   - Model type: {}", metadata.model_type);
    println!("   - Features: {:?}", metadata.n_features);
    println!("   - Created: {}", metadata.created_at_readable);

    if let Some(algo_config) = &metadata.algorithm_config {
        println!("   - Algorithm: {}", algo_config.algorithm);
        if let Some(distance_metric) = &algo_config.distance_metric {
            println!("   - Distance metric: {}", distance_metric);
        }
    }

    println!();
    Ok(())
}

/// Initialize random centroids for K-means
#[allow(dead_code)]
fn initialize_centroids(
    data: &Array2<f64>,
    k: usize,
) -> Result<Array2<f64>, Box<dyn std::error::Error>> {
    use ndarray::Array;

    let n_features = data.ncols();
    let mut centroids = Array::zeros((k, n_features));

    // Simple initialization: take first k points
    for i in 0..k {
        let idx = i % data.nrows();
        for j in 0..n_features {
            centroids[[i, j]] = data[[idx, j]];
        }
    }

    Ok(centroids)
}

/// Create test scikit-learn compatible JSON data
#[allow(dead_code)]
fn create_sklearn_test_data(centroids: &Array2<f64>) -> String {
    use serde_json::json;

    let centroids_vec: Vec<Vec<f64>> = centroids
        .rows()
        .into_iter()
        .map(|row| row.iter().cloned().collect())
        .collect();

    let sklearn_data = json!({
        "cluster_centers_": centroids_vec,
        "n_clusters": centroids.nrows(),
        "n_iter_": 12,
        "inertia_": 45.7,
        "model_type": "KMeans",
        "sklearn_version": "1.0.0",
        "scirs2_compatible": true
    });

    serde_json::to_string_pretty(&sklearn_data).unwrap()
}
