use ndarray::{Array, IxDyn};
use scirs2_neural::layers::Layer;
use scirs2_neural::models::{ViTConfig, VisionTransformer};

#[allow(dead_code)]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("Vision Transformer (ViT) Example");
    // Create a ViT-Base model for image classification
    let image_size = (224, 224);
    let patch_size = (16, 16);
    let in_channels = 3; // RGB images
    let num_classes = 1000; // ImageNet classes
    println!("Creating ViT-Base model with image size {:?}, patch size {:?}, {} input channels, and {} output classes", 
             image_size, patch_size, in_channels, num_classes);
    // Create model
    let model =
        VisionTransformer::<f32>::vit_base(image_size, patch_size, in_channels, num_classes)?;
    // Create dummy input (batch_size=1, channels=3, height=224, width=224)
    let input = Array::from_shape_fn(IxDyn(&[1, in_channels, image_size.0, image_size.1]), |_| {
        rand::random::<f32>()
    });
    println!("Input shape: {:?}", input.shape());
    // Forward pass
    let output = model.forward(&input)?;
    println!("Output shape: {:?}", output.shape());
    println!("Output contains logits for {} classes", output.shape()[1]);
    // Create a custom ViT configuration for smaller images
    println!("\nCreating a custom ViT model for smaller images...");
    let custom_config = ViTConfig {
        image_size: (32, 32), // CIFAR-10 image size
        patch_size: (4, 4),   // 4x4 patches
        in_channels: 3,       // RGB images
        num_classes: 10,      // CIFAR-10 classes
        embed_dim: 192,       // Smaller embedding dimension
        num_layers: 4,        // Fewer transformer layers
        num_heads: 3,         // Fewer attention heads
        mlp_dim: 768,         // Smaller MLP dimension
        dropout_rate: 0.1,
        attention_dropout_rate: 0.1,
    };
    let custom_model = VisionTransformer::<f32>::new(custom_config)?;
    // Create dummy input for CIFAR-10 (batch_size=1, channels=3, height=32, width=32)
    let small_input = Array::from_shape_fn(IxDyn(&[1, 3, 32, 32]), |_| rand::random::<f32>());
    println!("Custom input shape: {:?}", small_input.shape());
    let custom_output = custom_model.forward(&small_input)?;
    println!("Custom output shape: {:?}", custom_output.shape());
    println!(
        "Custom model produces logits for {} classes",
        custom_output.shape()[1]
    );
    println!("\nVision Transformer example completed successfully!");
    Ok(())
}
