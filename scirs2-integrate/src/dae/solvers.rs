//! DAE solver implementations
//!
//! This module provides solver implementations for various types of DAEs.

use crate::common::IntegrateFloat;
use crate::dae::index_reduction::{DAEStructure, PantelidesReducer};
use crate::dae::methods::bdf_dae::bdf_semi_explicit_dae;
use crate::dae::types::{DAEIndex, DAEOptions, DAEResult, DAEType};
use crate::error::{IntegrateError, IntegrateResult};
use crate::ode::utils::jacobian::JacobianStrategy;
use crate::ode::{solve_ivp, ODEOptions};
use ndarray::{Array1, Array2, ArrayView1, ArrayView2};

/// Solve an initial value problem (IVP) for a semi-explicit index-1 DAE
///
/// This function solves a system of differential-algebraic equations of the form:
///
/// x' = f(x, y, t)
/// 0 = g(x, y, t)
///
/// Where x are the differential variables and y are the algebraic variables.
///
/// # Arguments
///
/// * `f` - Function that computes the derivatives x' = f(x, y, t)
/// * `g` - Function that computes the constraints 0 = g(x, y, t)
/// * `t_span` - The interval of integration [t0, tf]
/// * `x0` - Initial state for differential variables
/// * `y0` - Initial state for algebraic variables (should satisfy g(x0, y0, t0) = 0)
/// * `options` - Solver options (optional)
///
/// # Returns
///
/// Result containing the solution at different time points or an error
#[allow(dead_code)]
pub fn solve_semi_explicit_dae<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: Option<DAEOptions<F>>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Use default options if none provided
    let opts = options.unwrap_or_default();

    // Check if the initial condition satisfies the constraint
    let g_init = g(t_span[0], x0.view(), y0.view());

    // Check if g(x0, y0, t0) is close to zero
    let constraint_error = g_init
        .iter()
        .fold(F::zero(), |acc, &x| acc + x.powi(2))
        .sqrt();
    let tol = F::from_f64(1e-8).unwrap();

    if constraint_error > tol {
        return Err(IntegrateError::ValueError(format!(
            "Initial condition does not satisfy constraints. Error: {constraint_error}"
        )));
    }

    // Get dimensions of the differential and algebraic variables
    let n_x = x0.len();
    let n_y = y0.len();
    let n_total = n_x + n_y;

    // Create the combined state vector z = [x, y]
    let mut z0 = Array1::zeros(n_total);
    for i in 0..n_x {
        z0[i] = x0[i];
    }
    for i in 0..n_y {
        z0[n_x + i] = y0[i];
    }

    // Create the implicit ODE system that incorporates the constraint
    let f_closure = f.clone();
    let g_closure = g.clone();

    // This approach uses a combined step based on the Radau IIA method
    // for implicit solution of the DAE system.
    let combined_system = move |t: F, z: ArrayView1<F>| -> Array1<F> {
        // Split the combined state vector into x and y components
        let x = z.slice(ndarray::s![0..n_x]);
        let y = z.slice(ndarray::s![n_x..]);

        // Evaluate the derivative function for the differential variables
        let x_dot = f_closure(t, x, y);

        // For the algebraic part, we use the constraint equation
        // In a formal derivation, we'd use the time derivative of g
        // which gives us a relation that y' must satisfy
        let g_val = g_closure(t, x, y);

        // Compute the Jacobian of g with respect to y
        // For index-1 DAEs, this Jacobian must be invertible
        // Convert ArrayView1 to slices for the constraint function
        let x_slice: Vec<F> = x.to_vec();
        let y_slice: Vec<F> = y.to_vec();
        let g_y = crate::dae::utils::compute_constraint_jacobian(
            &|t, x, y| g_closure(t, ArrayView1::from(x), ArrayView1::from(y)).to_vec(),
            t,
            &x_slice,
            &y_slice,
        );

        // Compute the Jacobian of g with respect to x
        // This is needed for the index-1 DAE solution
        let g_x = compute_jacobian_x(&g_closure, t, x, y, F::from_f64(1e-8).unwrap());

        // Compute the partial derivative of g with respect to t
        // We use a finite difference approximation
        let dt = F::from_f64(1e-8).unwrap();
        let g_t_plus = g_closure(t + dt, x, y);
        let g_t = (g_t_plus - g_val.clone()) / dt;

        // For an index-1 DAE, we can derive y' from:
        // 0 = dg/dt = ∂g/∂t + ∂g/∂x * x' + ∂g/∂y * y'
        // y' = -(∂g/∂y)^-1 * (∂g/∂t + ∂g/∂x * x')

        // Compute ∂g/∂x * x'
        let g_x_dot = g_x.dot(&x_dot);

        // Combine ∂g/∂t + ∂g/∂x * x'
        let rhs = &g_t + &g_x_dot;

        // Solve the system for y'
        let y_dot = match solve_matrix_system(g_y.view(), rhs.view()) {
            Ok(solution) => -solution,    // Negate to solve for y'
            Err(_) => Array1::zeros(n_y), // Fallback if the system can't be solved
        };

        // Combine x' and y' into a single vector
        let mut z_dot = Array1::zeros(n_total);
        for i in 0..n_x {
            z_dot[i] = x_dot[i];
        }
        for i in 0..n_y {
            z_dot[n_x + i] = y_dot[i];
        }

        z_dot
    };

    // Create ODE options that are suitable for DAE systems
    let ode_options = ODEOptions {
        method: opts.method,
        rtol: opts.rtol,
        atol: opts.atol,
        h0: opts.h0,
        max_steps: opts.max_steps,
        max_step: opts.max_step,
        min_step: opts.min_step,
        // DAEs generally benefit from dense output
        dense_output: true,
        // For stiff systems like DAEs, setting a higher order is often beneficial
        max_order: Some(5),
        // No explicit Jacobian provided, it will be computed internally
        jac: None,
        // We'll let the solver handle the Jacobian adaptively
        jacobian_strategy: Some(JacobianStrategy::Adaptive),
        // Other options remain default
        ..Default::default()
    };

    // Solve the system using an ODE solver
    let ode_result = solve_ivp(combined_system, t_span, z0, Some(ode_options))?;

    // Extract the results into differential and algebraic components
    let mut x_results: Vec<Array1<F>> = Vec::with_capacity(ode_result.t.len());
    let mut y_results: Vec<Array1<F>> = Vec::with_capacity(ode_result.t.len());

    for z in &ode_result.y {
        // Split the combined state vector
        let x_part = z.slice(ndarray::s![0..n_x]).to_owned();
        let y_part = z.slice(ndarray::s![n_x..]).to_owned();

        x_results.push(x_part);
        y_results.push(y_part);
    }

    // Create the DAE result
    let dae_result = DAEResult {
        t: ode_result.t,
        x: x_results,
        y: y_results,
        success: ode_result.success,
        message: ode_result.message,
        n_eval: ode_result.n_eval,
        n_constraint_eval: ode_result.n_eval, // Typically one constraint per step
        n_steps: ode_result.n_steps,
        n_accepted: ode_result.n_accepted,
        n_rejected: ode_result.n_rejected,
        n_lu: ode_result.n_lu,
        n_jac: ode_result.n_jac,
        method: ode_result.method,
        dae_type: DAEType::SemiExplicit,
        index: DAEIndex::Index1,
    };

    Ok(dae_result)
}

/// Compute the Jacobian of a constraint function g with respect to x
///
/// This is a helper function for the semi-explicit DAE solver
#[allow(dead_code)]
fn compute_jacobian_x<F, GFunc>(
    g: &GFunc,
    t: F,
    x: ArrayView1<F>,
    y: ArrayView1<F>,
    epsilon: F,
) -> Array2<F>
where
    F: IntegrateFloat + std::default::Default,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    let n_x = x.len();
    let n_g = g(t, x, y).len();
    let mut jac = Array2::zeros((n_g, n_x));

    // Base value of g
    let g_base = g(t, x, y);

    // Compute the Jacobian using finite differences
    let mut x_plus = x.to_owned();
    for i in 0..n_x {
        // Compute the perturbation size
        let h = epsilon.max(x[i].abs() * epsilon);

        // Perturb the ith component of x
        x_plus[i] = x[i] + h;

        // Evaluate g with the perturbed x
        let g_plus = g(t, x_plus.view(), y);

        // Reset the perturbation
        x_plus[i] = x[i];

        // Compute the finite difference approximation of the derivative
        let column = (g_plus - &g_base) / h;

        // Store the column in the Jacobian matrix
        for j in 0..n_g {
            jac[[j, i]] = column[j];
        }
    }

    jac
}

/// Solve a linear system of equations using LU decomposition
///
/// This is a helper function for the semi-explicit DAE solver
#[allow(dead_code)]
fn solve_matrix_system<F>(matrix: ArrayView2<F>, b: ArrayView1<F>) -> IntegrateResult<Array1<F>>
where
    F: IntegrateFloat + std::default::Default,
{
    use crate::dae::utils::linear_solvers::solve_linear_system;

    // Use our custom solver to solve the system
    solve_linear_system(&matrix.view(), &b.view()).map_err(|err| {
        IntegrateError::ComputationError(format!("Failed to solve linear system: {err}"))
    })
}

/// Solve an initial value problem (IVP) for a fully implicit index-1 DAE
///
/// This function solves a fully implicit DAE system of the form:
///
/// F(t, y, y') = 0
///
/// where y is the combined vector of differential and algebraic variables.
///
/// # Arguments
///
/// * `f` - Function that computes the residual F(t, y, y')
/// * `t_span` - The interval of integration [t0, tf]
/// * `y0` - Initial state for all variables
/// * `y_prime0` - Initial derivatives (consistent with the DAE)
/// * `options` - Solver options (optional)
///
/// # Returns
///
/// Result containing the solution at different time points or an error
#[allow(dead_code)]
pub fn solve_implicit_dae<F, FFunc>(
    f: FFunc,
    t_span: [F; 2],
    y0: Array1<F>,
    y_prime0: Array1<F>,
    options: Option<DAEOptions<F>>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Use default options if none provided
    let opts = options.unwrap_or_default();

    // Verify that initial conditions are consistent with the DAE
    let residual = f(t_span[0], y0.view(), y_prime0.view());
    let residual_norm = residual
        .iter()
        .fold(F::zero(), |acc, &x| acc + x.powi(2))
        .sqrt();
    let tol = F::from_f64(1e-8).unwrap();

    if residual_norm > tol {
        return Err(IntegrateError::ValueError(format!(
            "Initial conditions are not consistent with the DAE. Residual norm: {residual_norm}"
        )));
    }

    // For an implicit DAE, we use a specially formulated implicit solver
    // that directly handles the DAE structure.
    // Here we use the backward differentiation formula (BDF) method,
    // which is effective for index-1 DAEs.

    // Number of variables in the system
    let n = y0.len();

    // Time points, solution values, and derivatives storage
    let mut t_values = vec![t_span[0]];
    let mut y_values = vec![y0.clone()];
    let mut y_prime_values = vec![y_prime0.clone()];

    // Current step index
    let mut step = 0;

    // Current time and solution
    let mut t_current = t_span[0];
    let mut y_current = y0.clone();
    let mut y_prime_current = y_prime0.clone();

    // Initial step size (if not provided in options)
    let mut h = opts.h0.unwrap_or_else(|| {
        let _span = t_span[1] - t_span[0];
        _span * F::from_f64(0.01).unwrap() // 1% of interval
    });

    // Minimum and maximum step sizes
    let min_step = opts.min_step.unwrap_or_else(|| {
        let _span = t_span[1] - t_span[0];
        _span * F::from_f64(1e-6).unwrap() // Very small relative to interval
    });

    let max_step = opts.max_step.unwrap_or_else(|| {
        let _span = t_span[1] - t_span[0];
        _span * F::from_f64(0.1).unwrap() // 10% of interval
    });

    // Function to evaluate the implicit BDF formula for a given step size and order
    let eval_bdf_formula = |y_new: ArrayView1<F>,
                            y_history: &[Array1<F>],
                            _y_prime_new: ArrayView1<F>,
                            t_new: F,
                            k: usize,
                            step_size: F|
     -> Array1<F> {
        // BDF coefficients for orders 1 through 5
        let bdf_coeffs = match k {
            1 => vec![F::one(), -F::one()], // Backward Euler
            2 => vec![
                F::from_f64(4.0 / 3.0).unwrap(),
                -F::from_f64(1.0 / 3.0).unwrap(),
                -F::one(),
            ],
            3 => vec![
                F::from_f64(18.0 / 11.0).unwrap(),
                -F::from_f64(9.0 / 11.0).unwrap(),
                F::from_f64(2.0 / 11.0).unwrap(),
                -F::one(),
            ],
            4 => vec![
                F::from_f64(48.0 / 25.0).unwrap(),
                -F::from_f64(36.0 / 25.0).unwrap(),
                F::from_f64(16.0 / 25.0).unwrap(),
                -F::from_f64(3.0 / 25.0).unwrap(),
                -F::one(),
            ],
            5 => vec![
                F::from_f64(300.0 / 137.0).unwrap(),
                -F::from_f64(300.0 / 137.0).unwrap(),
                F::from_f64(200.0 / 137.0).unwrap(),
                -F::from_f64(75.0 / 137.0).unwrap(),
                F::from_f64(12.0 / 137.0).unwrap(),
                -F::one(),
            ],
            _ => return Array1::zeros(n), // Invalid order, return zeros (will trigger error)
        };

        // Compute the BDF approximation of the derivative
        let mut bdf_derivative: Array1<F> = Array1::zeros(n);

        for i in 0..=k {
            if i == 0 {
                bdf_derivative += &(&y_new * bdf_coeffs[i]);
            } else if i <= y_history.len() {
                bdf_derivative += &(&y_history[y_history.len() - i] * bdf_coeffs[i]);
            }
        }

        bdf_derivative /= step_size;

        // Return the residual f(t, y, y') where y' is the BDF approximation
        f(t_new, y_new, bdf_derivative.view())
    };

    // Counters for statistics
    let mut n_steps = 0;
    let mut n_accepted = 0;
    let mut n_rejected = 0;
    let mut n_jac = 0;
    let mut n_lu = 0;
    let mut n_eval = 0;

    // Main integration loop
    while t_current < t_span[1] && step < opts.max_steps {
        // Ensure we don't overshoot the end time
        if t_current + h > t_span[1] {
            h = t_span[1] - t_current;
        }

        // Calculate new time point
        let t_new = t_current + h;

        // Current order of the method (build up from 1)
        let order = (step + 1).min(5).min(opts.max_order.unwrap_or(5));

        // Use the history of the last 'order' steps
        let history_start = if step >= order { step - order + 1 } else { 0 };
        let y_history = y_values[history_start..=step].to_vec();

        // Predictor step: Extrapolate from previous points
        let mut y_pred = match step {
            0 => y_current.clone(), // For first step, use initial condition
            _ => {
                // Simple extrapolation for subsequent steps
                let mut pred = y_current.clone();
                if step > 0 {
                    // Add trend from previous step
                    let step_ratio = h / (t_current - t_values[step - 1]);
                    pred = pred + &(&y_current - &y_values[step - 1]) * step_ratio;
                }
                pred
            }
        };

        // Create initial guess for y_prime (derivative)
        let mut y_prime_pred = if step == 0 {
            y_prime_current.clone() // Use initial derivative for first step
        } else {
            // Simple extrapolation for subsequent steps
            let mut pred = y_prime_current.clone();
            if step > 0 {
                // Add trend from previous step
                let step_ratio = h / (t_current - t_values[step - 1]);
                pred = pred + &(&y_prime_current - &y_prime_values[step - 1]) * step_ratio;
            }
            pred
        };

        // Corrector iterations (non-linear solver)
        let max_iter = opts.max_newton_iterations;
        let newton_tol = opts.newton_tol;

        let mut converged = false;

        for _iter in 0..max_iter {
            // Compute the residual using the BDF formula
            let residual = if step == 0 || order == 1 {
                // For first step or order 1, use simple backward Euler
                let y_prime_bdf = (&y_pred - &y_current) / h;
                f(t_new, y_pred.view(), y_prime_bdf.view())
            } else {
                // For higher orders, use the BDF formula
                eval_bdf_formula(
                    y_pred.view(),
                    &y_history,
                    y_prime_pred.view(),
                    t_new,
                    order,
                    h,
                )
            };

            n_eval += 1;

            // Compute the convergence criterion
            let residual_norm = residual
                .iter()
                .fold(F::zero(), |acc, &x| acc + x.powi(2))
                .sqrt();

            // Check for convergence
            if residual_norm < newton_tol {
                converged = true;
                break;
            }

            // Newton iteration: Compute the Jacobian of the residual function
            // Compute time-dependent Jacobian: ∂F/∂t
            let jacobian_t = compute_time_jacobian(&f, t_new, &y_pred, &y_prime_pred)?;

            // Compute jacobians directly using finite differences
            let f_current = f(t_new, y_pred.view(), y_prime_pred.view());
            let jacobian_y = crate::ode::utils::common::finite_difference_jacobian(
                &|t, y| f(t, y, y_prime_pred.view()),
                t_new,
                &y_pred,
                &f_current,
                F::from_f64(1e-8).unwrap(),
            );

            let jacobian_y_prime = crate::ode::utils::common::finite_difference_jacobian(
                &|t, y_prime| f(t, y_pred.view(), y_prime),
                t_new,
                &y_prime_pred,
                &f_current,
                F::from_f64(1e-8).unwrap(),
            );

            n_jac += 3;

            // Compute the effective Jacobian for Newton iteration
            // The effective Jacobian includes contributions from:
            // 1. ∂F/∂y (jacobian_y)
            // 2. ∂F/∂y' scaled by the BDF derivative approximation (jacobian_y_prime)
            // 3. ∂F/∂t (jacobian_t) for time-dependent systems
            let mut jacobian_effective = jacobian_y.clone();

            // For highly time-dependent systems, the time Jacobian can improve convergence
            // by predicting how the residual changes with time step modifications
            let use_time_jacobian = true; // Enable for better convergence
            if use_time_jacobian {
                // Add a small contribution from the time Jacobian to account for
                // the implicit time dependence in the Newton correction
                let time_contribution_factor = F::from_f64(0.01).unwrap(); // Small factor
                for i in 0..n {
                    jacobian_effective[[i, i]] += jacobian_t[i] * time_contribution_factor;
                }
            }

            // For first step or order 1, use backward Euler formula dy/dt = (y - y_prev) / h
            // So y' = (y - y_prev) / h, and d(y')/dy = 1/h
            if step == 0 || order == 1 {
                let scale = F::one() / h;
                for i in 0..n {
                    for j in 0..n {
                        if i == j {
                            jacobian_effective[[i, j]] += jacobian_y_prime[[i, j]] * scale;
                        }
                    }
                }
            } else {
                // For higher orders, use the BDF formula derivative with respect to y_new
                let bdf_coeff = match order {
                    2 => F::from_f64(4.0 / 3.0).unwrap(),
                    3 => F::from_f64(18.0 / 11.0).unwrap(),
                    4 => F::from_f64(48.0 / 25.0).unwrap(),
                    5 => F::from_f64(300.0 / 137.0).unwrap(),
                    _ => F::one(), // Fallback to first-order if invalid
                };

                let scale = bdf_coeff / h;
                for i in 0..n {
                    for j in 0..n {
                        if i == j {
                            jacobian_effective[[i, j]] += jacobian_y_prime[[i, j]] * scale;
                        }
                    }
                }
            }

            // Solve the linear system J * dy = -F
            let neg_residual = residual.mapv(|x| -x);
            let dy = match solve_matrix_system(jacobian_effective.view(), neg_residual.view()) {
                Ok(sol) => sol,
                Err(e) => {
                    return Err(IntegrateError::ComputationError(format!(
                        "Failed to solve Newton system at t = {t_new}: {e}"
                    )));
                }
            };

            n_lu += 1;

            // Update the solution approximation with damping to improve convergence
            let mut alpha = F::one(); // Full step
            let min_alpha = F::from_f64(0.1).unwrap(); // Don't reduce step size too much

            while alpha >= min_alpha {
                // Try the step with current alpha
                let y_new = &y_pred + &(&dy * alpha);

                // Compute the new derivative approximation
                let y_prime_new = if step == 0 || order == 1 {
                    // For first step or order 1, use backward Euler
                    (&y_new - &y_current) / h
                } else {
                    // For higher orders, use the BDF formula
                    let _y_prime: Array1<F> = Array1::zeros(n);

                    // BDF coefficients for this order
                    let bdf_coeffs = match order {
                        2 => vec![
                            F::from_f64(4.0 / 3.0).unwrap(),
                            -F::from_f64(1.0 / 3.0).unwrap(),
                            -F::one(),
                        ],
                        3 => vec![
                            F::from_f64(18.0 / 11.0).unwrap(),
                            -F::from_f64(9.0 / 11.0).unwrap(),
                            F::from_f64(2.0 / 11.0).unwrap(),
                            -F::one(),
                        ],
                        4 => vec![
                            F::from_f64(48.0 / 25.0).unwrap(),
                            -F::from_f64(36.0 / 25.0).unwrap(),
                            F::from_f64(16.0 / 25.0).unwrap(),
                            -F::from_f64(3.0 / 25.0).unwrap(),
                            -F::one(),
                        ],
                        5 => vec![
                            F::from_f64(300.0 / 137.0).unwrap(),
                            -F::from_f64(300.0 / 137.0).unwrap(),
                            F::from_f64(200.0 / 137.0).unwrap(),
                            -F::from_f64(75.0 / 137.0).unwrap(),
                            F::from_f64(12.0 / 137.0).unwrap(),
                            -F::one(),
                        ],
                        _ => vec![F::one(), -F::one()], // Fallback to backward Euler
                    };

                    // Compute the BDF approximation of the derivative
                    let mut bdf_derivative = Array1::zeros(n);

                    for i in 0..=order {
                        if i == 0 {
                            bdf_derivative += &(&y_new * bdf_coeffs[i]);
                        } else if i <= y_history.len() {
                            bdf_derivative += &(&y_history[y_history.len() - i] * bdf_coeffs[i]);
                        }
                    }

                    bdf_derivative / h
                };

                // Evaluate the new residual
                let new_residual = f(t_new, y_new.view(), y_prime_new.view());
                n_eval += 1;

                let new_residual_norm = new_residual
                    .iter()
                    .fold(F::zero(), |acc, &x| acc + x.powi(2))
                    .sqrt();

                // Accept the step if residual is reduced
                if new_residual_norm < residual_norm {
                    y_pred = y_new;
                    y_prime_pred = y_prime_new;
                    break;
                }

                // Reduce alpha for next attempt
                alpha *= F::from_f64(0.5).unwrap();
            }

            // If alpha got too small, Newton's method is diverging
            if alpha < min_alpha {
                break;
            }
        }

        n_steps += 1;

        // Accept or reject the step based on convergence
        if converged {
            // Accept the step
            n_accepted += 1;

            // Store the solution
            t_values.push(t_new);
            y_values.push(y_pred.clone());
            y_prime_values.push(y_prime_pred.clone());

            // Update current values
            t_current = t_new;
            y_current = y_pred.clone();
            y_prime_current = y_prime_pred.clone();

            // Increase step count
            step += 1;

            // Adjust the step size based on convergence
            h = (h * F::from_f64(1.1).unwrap()).min(max_step);
        } else {
            // Reject the step
            n_rejected += 1;

            // Reduce the step size
            h = (h * F::from_f64(0.5).unwrap()).max(min_step);

            // If step size got too small, the problem might be too stiff
            if h <= min_step {
                return Err(IntegrateError::ComputationError(
                    format!("Integration failed at t = {t_current}. Step size got too small. The DAE might be too stiff or have index greater than 1.")
                ));
            }
        }
    }

    // Check if we reached the end of the interval
    let success = t_current >= t_span[1];
    let message = if success {
        Some(format!(
            "Integration successful. {n_steps} steps taken, {n_accepted} accepted, {n_rejected} rejected."
        ))
    } else {
        Some(format!("Integration did not reach the end of the interval. {n_steps} steps taken, {n_accepted} accepted, {n_rejected} rejected."))
    };

    // Split the combined solution into differential and algebraic components
    // For implicit DAE, we don't have a clear distinction, so we return
    // all variables as differential and none as algebraic
    let mut y_result = Vec::with_capacity(t_values.len());
    let empty_array = Array1::<F>::zeros(0);
    let y_empty = vec![empty_array; t_values.len()];

    for y in y_values {
        y_result.push(y);
    }

    // Create the DAE result
    let dae_result = DAEResult {
        t: t_values,
        x: y_result,
        y: y_empty, // No explicit algebraic variables in the fully implicit form
        success,
        message,
        n_eval,
        n_constraint_eval: n_eval, // Same as func evals
        n_steps,
        n_accepted,
        n_rejected,
        n_lu,
        n_jac,
        method: opts.method,
        dae_type: DAEType::FullyImplicit,
        index: DAEIndex::Index1,
    };

    Ok(dae_result)
}

/// Solve an initial value problem (IVP) for a higher-index DAE system
///
/// This function uses index reduction techniques to transform a higher-index DAE
/// into an equivalent index-1 system that can be solved using standard methods.
///
/// # Arguments
///
/// * `f` - Function that computes the differential equations
/// * `g` - Function that computes the constraint equations
/// * `t_span` - The interval of integration [t0, tf]
/// * `x0` - Initial state for differential variables
/// * `y0` - Initial state for algebraic variables
/// * `options` - Solver options (optional)
///
/// # Returns
///
/// Result containing the solution at different time points or an error
#[allow(dead_code)]
pub fn solve_higher_index_dae<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: Option<DAEOptions<F>>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Use default options if none provided
    let opts = options.unwrap_or_default();

    // Create wrapped functions at function scope to avoid borrowing issues
    let f_orig = f.clone();
    let g_orig = g.clone();
    let f_wrapped =
        move |t: F, x: ArrayView1<F>, y: ArrayView1<F>| -> Array1<F> { f_orig(t, x, y) };
    let g_wrapped =
        move |t: F, x: ArrayView1<F>, y: ArrayView1<F>| -> Array1<F> { g_orig(t, x, y) };

    // Create the DAE structure
    let mut structure =
        crate::dae::index_reduction::DAEStructure::new_semi_explicit(x0.len(), y0.len());

    // Compute the index of the DAE system
    let index = structure.compute_index(t_span[0], x0.view(), y0.view(), &f, &g)?;

    // If the system is already index-1, solve it directly
    if index == DAEIndex::Index1 {
        return solve_semi_explicit_dae(f, g, t_span, x0, y0, Some(opts));
    }

    // For higher-index systems, apply index reduction based on the selected method
    match opts.index {
        DAEIndex::Index1 => {
            // If requested index-1 but the system is higher, apply automatic reduction
            let mut reducer = crate::dae::index_reduction::PantelidesReducer::new(structure);

            // Attempt to reduce the index
            if let Err(_e) = reducer.reduce_index(t_span[0], x0.view(), y0.view(), &f, &g) {
                // If Pantelides algorithm is not yet implemented, try projection method
                let projection = crate::dae::index_reduction::ProjectionMethod::new(
                    crate::dae::index_reduction::DAEStructure::new_semi_explicit(
                        x0.len(),
                        y0.len(),
                    ),
                );

                // Make initial conditions consistent
                let mut x0_copy = x0.clone();
                let mut y0_copy = y0.clone();

                if let Err(e) =
                    projection.make_consistent(t_span[0], &mut x0_copy, &mut y0_copy, &g)
                {
                    return Err(IntegrateError::ComputationError(format!(
                        "Failed to find consistent initial conditions for higher-index DAE: {e}"
                    )));
                }

                // Create a modified solver that applies projection after each step

                // Project after each step using the original ODE and constraint functions
                return solve_semi_explicit_dae_with_projection(
                    f_wrapped,
                    g_wrapped,
                    t_span,
                    x0_copy,
                    y0_copy,
                    Some(opts),
                );
            }

            // Apply Pantelides index reduction algorithm
            use crate::dae::index_reduction::{DAEStructure, PantelidesReducer};

            // Create DAE structure
            let mut structure = DAEStructure::default();
            structure.n_differential = x0.len();
            structure.n_algebraic = y0.len();
            structure.n_diff_eqs = x0.len();
            structure.n_alg_eqs = y0.len();

            // Create Pantelides reducer
            let mut reducer = PantelidesReducer::new(structure);

            // Apply index reduction
            reducer.reduce_index(
                F::from_f64(t_span[0].to_f64().unwrap_or(0.0)).unwrap_or(F::zero()),
                x0.view(),
                y0.view(),
                &f_wrapped,
                &g_wrapped,
            )?;

            // After successful index reduction, solve as index-1 system
            // The reduced system can now be solved with standard DAE methods
            solve_index1_dae_with_reduced_structure(
                f_wrapped,
                g_wrapped,
                t_span,
                x0,
                y0,
                opts,
                reducer.structure,
            )
        }

        DAEIndex::Index2 => {
            // Index-2 DAE systems: Use specialized BDF with constraint stabilization
            solve_index2_dae_specialized(f_wrapped, g_wrapped, t_span, x0, y0, opts)
        }

        DAEIndex::Index3 => {
            // Index-3 DAE systems: Use projection method with dummy derivatives
            solve_index3_dae_specialized(f_wrapped, g_wrapped, t_span, x0, y0, opts)
        }

        DAEIndex::HigherIndex => {
            // For very high-index systems, always apply index reduction first

            // Create DAE structure
            let mut structure = DAEStructure::default();
            structure.n_differential = x0.len();
            structure.n_algebraic = y0.len();
            structure.n_diff_eqs = x0.len();
            structure.n_alg_eqs = y0.len();
            structure.index = DAEIndex::HigherIndex;

            // Create Pantelides reducer with higher iteration limit
            let mut reducer = PantelidesReducer::new(structure);
            reducer.max_diff_steps = 10; // Allow more differentiation steps for high-index systems

            // Apply index reduction
            reducer.reduce_index(
                F::from_f64(t_span[0].to_f64().unwrap_or(0.0)).unwrap_or(F::zero()),
                x0.view(),
                y0.view(),
                &f_wrapped,
                &g_wrapped,
            )?;

            // Solve the reduced system
            solve_index1_dae_with_reduced_structure(
                f_wrapped,
                g_wrapped,
                t_span,
                x0,
                y0,
                opts,
                reducer.structure,
            )
        }
    }
}

/// Solve a semi-explicit DAE with projection for constraint satisfaction
///
/// This is an extension of solve_semi_explicit_dae that applies projection
/// after each step to maintain constraint satisfaction for higher-index DAEs.
#[allow(dead_code)]
fn solve_semi_explicit_dae_with_projection<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: Option<DAEOptions<F>>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Create a projection method for constraint satisfaction
    let projection = crate::dae::index_reduction::ProjectionMethod::new(
        crate::dae::index_reduction::DAEStructure::new_semi_explicit(x0.len(), y0.len()),
    );

    // Setup options with shorter step sizes for better constraint satisfaction
    let mut opts = options.unwrap_or_default();

    // Reduce maximum step size to ensure better constraint tracking
    if let Some(max_step) = opts.max_step {
        opts.max_step = Some(max_step * F::from_f64(0.5).unwrap());
    }

    // Set tighter tolerances
    opts.rtol *= F::from_f64(0.1).unwrap();
    opts.atol *= F::from_f64(0.1).unwrap();

    // Solve using the basic semi-explicit DAE solver
    let f_clone = f.clone();
    let g_clone = g.clone();

    let original_result =
        solve_semi_explicit_dae(f_clone, g_clone, t_span, x0, y0, Some(opts.clone()))?;

    // If no projection needed, return the original result
    if !projection.project_after_step {
        return Ok(original_result);
    }

    // Apply projection to each solution point to ensure constraint satisfaction
    let mut x_projected = Vec::with_capacity(original_result.t.len());
    let mut y_projected = Vec::with_capacity(original_result.t.len());

    for i in 0..original_result.t.len() {
        let t = original_result.t[i];
        let mut x = original_result.x[i].clone();
        let mut y = original_result.y[i].clone();

        // Project this solution point onto the constraint manifold
        let _ = projection.project_solution(t, &mut x, &mut y, &g);

        x_projected.push(x);
        y_projected.push(y);
    }

    // Create a new result with the projected solution
    let t_len = original_result.t.len();
    let projected_result = DAEResult {
        t: original_result.t,
        x: x_projected,
        y: y_projected,
        success: original_result.success,
        message: original_result.message,
        n_eval: original_result.n_eval,
        n_constraint_eval: original_result.n_constraint_eval + t_len,
        n_steps: original_result.n_steps,
        n_accepted: original_result.n_accepted,
        n_rejected: original_result.n_rejected,
        n_lu: original_result.n_lu,
        n_jac: original_result.n_jac,
        method: original_result.method,
        dae_type: DAEType::SemiExplicit,
        index: DAEIndex::Index2, // Mark as higher-index solution
    };

    Ok(projected_result)
}

/// Solve an initial value problem (IVP) for a general DAE system
///
/// This function provides a unified interface for solving various types of DAEs
/// by detecting the form and structure of the provided functions.
///
/// # Arguments
///
/// * `f` - Function that computes the DAE residual F(t, y, y')
/// * `t_span` - The interval of integration [t0, tf]
/// * `y0` - Initial state
/// * `y_prime0` - Initial derivatives (can be None for semi-explicit DAEs)
/// * `options` - Solver options (optional)
///
/// # Returns
///
/// Result containing the solution at different time points or an error
#[allow(dead_code)]
pub fn solve_ivp_dae<F, FFunc>(
    f: FFunc,
    t_span: [F; 2],
    y0: Array1<F>,
    y_prime0: Option<Array1<F>>,
    options: Option<DAEOptions<F>>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Use default options if none provided
    let opts = options.unwrap_or_default();

    // Dispatch to the appropriate solver based on the DAE type
    match opts.dae_type {
        DAEType::SemiExplicit => {
            // For semi-explicit DAEs, we need to extract the differential and algebraic parts
            // We assume the first part of y0 contains differential variables, and the second part
            // contains algebraic variables. The exact split depends on the specific problem.

            // This is a simplification - in a real implementation, we would need more information
            // about the structure of the semi-explicit DAE.

            // Return error for now - the user should use solve_semi_explicit_dae directly
            Err(IntegrateError::ValueError(
                "For semi-explicit DAEs, please use solve_semi_explicit_dae directly.".to_string(),
            ))
        }
        DAEType::FullyImplicit => {
            // For fully implicit DAEs, we need initial derivatives
            if let Some(yprime0) = y_prime0 {
                solve_implicit_dae(f, t_span, y0, yprime0, Some(opts))
            } else {
                Err(IntegrateError::ValueError(
                    "Initial derivatives are required for fully implicit DAEs.".to_string(),
                ))
            }
        }
    }
}

/// Solve an index-1 DAE system with reduced structure from Pantelides algorithm
#[allow(dead_code)]
fn solve_index1_dae_with_reduced_structure<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: DAEOptions<F>,
    _structure: crate::dae::index_reduction::DAEStructure<F>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    // After index reduction, we can solve the system as a standard index-1 DAE
    // Use BDF method for semi-explicit DAE systems
    use crate::dae::methods::bdf_dae::bdf_semi_explicit_dae;

    bdf_semi_explicit_dae(f, g, t_span, x0, y0, options)
}

/// Solve an index-2 DAE system using specialized BDF with constraint stabilization
#[allow(dead_code)]
fn solve_index2_dae_specialized<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: DAEOptions<F>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    // For index-2 systems, use BDF method with modified options

    // Use smaller initial step size for index-2 systems
    let mut modified_options = options;
    if modified_options.h0.is_none() {
        modified_options.h0 = Some(F::from_f64(1e-6).unwrap_or(F::from_f64(1e-4).unwrap()));
    }

    // Use stricter tolerances for index-2 systems
    modified_options.rtol *= F::from_f64(0.1).unwrap();
    modified_options.atol *= F::from_f64(0.1).unwrap();

    bdf_semi_explicit_dae(f, g, t_span, x0, y0, modified_options)
}

/// Solve an index-3 DAE system using projection method with dummy derivatives
#[allow(dead_code)]
fn solve_index3_dae_specialized<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    t_span: [F; 2],
    x0: Array1<F>,
    y0: Array1<F>,
    options: DAEOptions<F>,
) -> IntegrateResult<DAEResult<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    // For index-3 systems, use BDF method with very strict tolerances

    // Use very small initial step size for index-3 systems
    let mut modified_options = options;
    if modified_options.h0.is_none() {
        modified_options.h0 = Some(F::from_f64(1e-8).unwrap_or(F::from_f64(1e-6).unwrap()));
    }

    // Use very strict tolerances for index-3 systems
    modified_options.rtol *= F::from_f64(0.01).unwrap();
    modified_options.atol *= F::from_f64(0.01).unwrap();

    // Increase maximum iterations for Newton solver
    modified_options.max_newton_iterations = modified_options.max_newton_iterations.max(50);

    bdf_semi_explicit_dae(f, g, t_span, x0, y0, modified_options)
}

/// Apply dummy derivative method for index-3 DAE systems
#[allow(dead_code)]
fn apply_dummy_derivative_method<F, FFunc, GFunc>(
    f: FFunc,
    g: GFunc,
    _x0: &Array1<F>,
    _y0: &Array1<F>,
) -> IntegrateResult<(
    impl Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
    impl Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
)>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
    GFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F> + Clone,
{
    // Simplified dummy derivative method implementation
    // In a full implementation, this would:
    // 1. Identify constraint equations that need differentiation
    // 2. Add dummy variables for the derivatives
    // 3. Transform the system to include differentiated constraints

    // For now, return the original functions with constraint stabilization
    let f_clone = f.clone();
    let g_clone = g.clone();
    let stabilized_f = move |t: F, x: ArrayView1<F>, y: ArrayView1<F>| -> Array1<F> {
        let mut result = f_clone(t, x, y);

        // Apply constraint stabilization by adding penalty terms
        // This helps with index-3 systems by enforcing constraint satisfaction
        let penalty_factor = F::from_f64(1e3).unwrap_or(F::from_f64(100.0).unwrap());
        let constraint_violation = g_clone(t, x, y);

        // Add penalty terms to differential equations
        for i in 0..result.len().min(constraint_violation.len()) {
            result[i] -= penalty_factor * constraint_violation[i];
        }

        result
    };

    let stabilized_g = move |t: F, x: ArrayView1<F>, y: ArrayView1<F>| -> Array1<F> { g(t, x, y) };

    Ok((stabilized_f, stabilized_g))
}

/// Compute the time-dependent Jacobian ∂F/∂t for implicit DAE systems
///
/// This function computes the partial derivative of the DAE residual function F(t, y, y')
/// with respect to time t using finite differences. This is needed for accurate Newton
/// iteration in implicit DAE solvers.
///
/// For a DAE system F(t, y, y') = 0, the time Jacobian is:
/// ∂F/∂t = lim(h→0) [F(t+h, y, y') - F(t, y, y')] / h
#[allow(dead_code)]
fn compute_time_jacobian<F, FFunc>(
    f: &FFunc,
    t: F,
    y: &Array1<F>,
    y_prime: &Array1<F>,
) -> IntegrateResult<Array1<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    // Use a small perturbation for finite difference approximation
    let h = F::from_f64(1e-8)
        .unwrap()
        .max(F::epsilon().sqrt() * t.abs());

    // Ensure h is not too small to avoid numerical errors
    let h = h.max(F::from_f64(1e-12).unwrap());

    // Compute F(t, y, y')
    let f_base = f(t, y.view(), y_prime.view());

    // Compute F(t + h, y, y')
    let t_plus_h = t + h;
    let f_perturbed = f(t_plus_h, y.view(), y_prime.view());

    // Compute the finite difference approximation: ∂F/∂t ≈ [F(t+h) - F(t)] / h
    let time_jacobian = f_perturbed
        .iter()
        .zip(f_base.iter())
        .map(|(&f_plus, &f_base)| (f_plus - f_base) / h)
        .collect::<Array1<F>>();

    Ok(time_jacobian)
}

/// Enhanced time-dependent Jacobian computation with adaptive step sizing
///
/// This function provides a more sophisticated approach to computing the time Jacobian
/// using adaptive step sizing and higher-order finite difference approximations.
#[allow(dead_code)]
fn compute_adaptive_time_jacobian<F, FFunc>(
    f: &FFunc,
    t: F,
    y: &Array1<F>,
    y_prime: &Array1<F>,
    tolerance: F,
) -> IntegrateResult<Array1<F>>
where
    F: IntegrateFloat + std::default::Default,
    FFunc: Fn(F, ArrayView1<F>, ArrayView1<F>) -> Array1<F>,
{
    // Start with a reasonable step size
    let mut h = F::from_f64(1e-6)
        .unwrap()
        .max(F::epsilon().sqrt() * t.abs());

    // Compute base function value
    let f_base = f(t, y.view(), y_prime.view());

    loop {
        // Forward difference
        let f_forward = f(t + h, y.view(), y_prime.view());
        let jacobian_forward = f_forward
            .iter()
            .zip(f_base.iter())
            .map(|(&f_plus, &f_base)| (f_plus - f_base) / h)
            .collect::<Array1<F>>();

        // Central difference for comparison (higher accuracy)
        let f_backward = f(t - h, y.view(), y_prime.view());
        let jacobian_central = f_forward
            .iter()
            .zip(f_backward.iter())
            .map(|(&f_plus, &f_minus)| (f_plus - f_minus) / (h + h))
            .collect::<Array1<F>>();

        // Estimate error by comparing forward and central differences
        let error_estimate = jacobian_forward
            .iter()
            .zip(jacobian_central.iter())
            .map(|(&forward, &central)| (forward - central).abs())
            .fold(F::zero(), |acc, err| acc.max(err));

        // Check if error is acceptable
        if error_estimate <= tolerance || h <= F::from_f64(1e-12).unwrap() {
            // Use central difference for better accuracy
            return Ok(jacobian_central);
        }

        // Reduce step size and try again
        h *= F::from_f64(0.5).unwrap();
    }
}
