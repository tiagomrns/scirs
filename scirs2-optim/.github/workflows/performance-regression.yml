name: Performance Regression Detection

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master ]
  schedule:
    # Run comprehensive performance regression tests twice daily
    - cron: '0 2,14 * * *'

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  performance-baseline:
    name: Performance Baseline Establishment
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libblas-dev liblapack-dev gfortran
          # Install performance monitoring tools
          sudo apt-get install -y linux-tools-common linux-tools-generic perf-tools-unstable
          
      - name: Install performance tools
        run: |
          cargo install cargo-criterion
          cargo install flamegraph
          cargo install cargo-profile
          
      - name: Create performance baseline
        run: |
          # Run baseline performance tests
          mkdir -p performance_baselines
          cargo run --release --example comprehensive_benchmarking_example \
            --features "simd,parallel,gpu" \
            -- --baseline --output performance_baselines/
          
      - name: Store baseline artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance-baseline-${{ github.sha }}
          path: performance_baselines/
          retention-days: 30

  regression-detection:
    name: Regression Detection
    runs-on: ubuntu-latest
    needs: performance-baseline
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libblas-dev liblapack-dev gfortran
          
      - name: Download baseline
        uses: actions/download-artifact@v4
        with:
          name: performance-baseline-${{ github.sha }}
          path: performance_baselines/
          
      - name: Download historical baselines
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: historical-baselines
          path: historical_baselines/
          
      - name: Run regression analysis
        run: |
          # Run comprehensive regression testing
          cargo run --release --example comprehensive_ci_cd_integration \
            --features "simd,parallel,gpu" \
            -- --regression-analysis \
               --baseline-dir performance_baselines/ \
               --historical-dir historical_baselines/ \
               --threshold 5.0 \
               --output regression_report.json
          
      - name: Analyze memory regression
        run: |
          # Run memory regression analysis
          cargo run --release --example comprehensive_memory_profiler \
            -- --regression-analysis \
               --baseline-dir performance_baselines/ \
               --memory-threshold 10.0 \
               --output memory_regression_report.json
          
      - name: Generate performance report
        run: |
          # Generate comprehensive performance report
          python scripts/generate_performance_report.py \
            regression_report.json \
            memory_regression_report.json \
            > performance_report.md
          
      - name: Check for regressions
        id: regression_check
        run: |
          # Check if any regressions were detected
          if grep -q "REGRESSION_DETECTED" regression_report.json; then
            echo "regression_detected=true" >> $GITHUB_OUTPUT
            echo "Performance regression detected!"
          else
            echo "regression_detected=false" >> $GITHUB_OUTPUT
            echo "No performance regressions detected."
          fi
          
      - name: Upload regression results
        uses: actions/upload-artifact@v4
        with:
          name: regression-analysis-${{ github.sha }}
          path: |
            regression_report.json
            memory_regression_report.json
            performance_report.md
            
      - name: Comment on PR if regression detected
        if: github.event_name == 'pull_request' && steps.regression_check.outputs.regression_detected == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('performance_report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## âš ï¸ Performance Regression Detected\n\n${report}\n\n**Action Required:** Please review and optimize the performance impact before merging.`
            });
            
      - name: Fail build on regression
        if: steps.regression_check.outputs.regression_detected == 'true'
        run: |
          echo "Performance regression detected. Failing build."
          exit 1

  continuous-profiling:
    name: Continuous Performance Profiling
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/master'
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        
      - name: Install profiling tools
        run: |
          sudo apt-get update
          sudo apt-get install -y libblas-dev liblapack-dev gfortran
          cargo install flamegraph
          cargo install cargo-profile
          
      - name: Run comprehensive profiling
        run: |
          # Profile all major optimizers
          mkdir -p profiling_results
          
          for optimizer in sgd adam adamw lamb lars lion lookahead sam lbfgs; do
            echo "Profiling $optimizer optimizer..."
            cargo flamegraph --output profiling_results/${optimizer}_flamegraph.svg \
              --example ${optimizer}_example
          done
          
      - name: Run memory profiling
        run: |
          # Profile memory usage patterns
          cargo run --release --example comprehensive_memory_profiler \
            -- --continuous-profiling \
               --output profiling_results/memory_profile.json
          
      - name: Generate profiling dashboard
        run: |
          # Generate interactive profiling dashboard
          python scripts/generate_profiling_dashboard.py \
            profiling_results/ \
            > profiling_dashboard.html
          
      - name: Upload profiling results
        uses: actions/upload-artifact@v4
        with:
          name: continuous-profiling-${{ github.sha }}
          path: |
            profiling_results/
            profiling_dashboard.html
            
      - name: Update performance tracking
        run: |
          # Update long-term performance tracking
          python scripts/update_performance_tracking.py \
            profiling_results/ \
            --database performance_tracking.db
            
  benchmark-comparison:
    name: Cross-Framework Benchmark Comparison
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Rust
        uses: dtolnay/rust-toolchain@stable
        
      - name: Setup Python for PyTorch/TensorFlow comparison
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'
          
      - name: Install Python dependencies
        run: |
          pip install torch torchvision tensorflow numpy scipy matplotlib
          
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libblas-dev liblapack-dev gfortran
          
      - name: Run cross-framework benchmarks
        run: |
          # Run comprehensive cross-framework comparison
          mkdir -p benchmark_comparison
          
          # Run Rust optimizer benchmarks
          cargo run --release --example comprehensive_benchmarking_example \
            -- --cross-framework --output benchmark_comparison/rust_results.json
          
          # Run PyTorch comparison
          python src/benchmarking/python_templates/pytorch_benchmark.py \
            --output benchmark_comparison/pytorch_results.json
          
          # Run TensorFlow comparison
          python src/benchmarking/python_templates/tensorflow_benchmark.py \
            --output benchmark_comparison/tensorflow_results.json
          
      - name: Generate comparison report
        run: |
          # Generate comprehensive comparison report
          python scripts/generate_benchmark_comparison.py \
            benchmark_comparison/ \
            > benchmark_comparison_report.md
          
      - name: Upload comparison results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-comparison-${{ github.sha }}
          path: |
            benchmark_comparison/
            benchmark_comparison_report.md

  performance-alerts:
    name: Performance Alert System
    runs-on: ubuntu-latest
    needs: [regression-detection, continuous-profiling]
    if: failure() || (github.ref == 'refs/heads/master' && github.event_name == 'schedule')
    
    steps:
      - name: Setup notification
        run: |
          # Send performance alerts via webhook or email
          echo "Performance monitoring alert triggered"
          
      - name: Download regression results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: regression-analysis-${{ github.sha }}
          path: regression_results/
          
      - name: Download profiling results
        continue-on-error: true
        uses: actions/download-artifact@v4
        with:
          name: continuous-profiling-${{ github.sha }}
          path: profiling_results/
          
      - name: Generate alert summary
        run: |
          # Generate alert summary
          python scripts/generate_alert_summary.py \
            regression_results/ \
            profiling_results/ \
            > alert_summary.md
          
      - name: Post to Slack/Discord (if configured)
        if: env.SLACK_WEBHOOK != ''
        run: |
          # Post alert to Slack channel (webhook URL should be in secrets)
          curl -X POST -H 'Content-type: application/json' \
            --data '{"text":"ðŸš¨ Performance Alert: Issues detected in scirs2-optim"}' \
            ${{ secrets.SLACK_WEBHOOK }}