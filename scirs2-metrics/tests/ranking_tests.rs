use approx::assert_abs_diff_eq;
use ndarray::array;
use scirs2_metrics::ranking::{
    click_through_rate, kendalls_tau, map_at_k, mean_average_precision, mean_reciprocal_rank,
    ndcg_score, precision_at_k, recall_at_k, spearmans_rho,
};

#[test]
#[allow(dead_code)]
fn test_mean_reciprocal_rank() {
    // Test case 1: Perfect ranking - relevant item at rank 1
    let y_true_1 = vec![array![0.0, 1.0, 0.0, 0.0, 0.0]];
    let y_score_1 = vec![array![0.1, 0.9, 0.2, 0.3, 0.4]];
    let mrr_1 = mean_reciprocal_rank(&y_true_1, &y_score_1).unwrap();
    assert_abs_diff_eq!(mrr_1, 1.0, epsilon = 1e-10);

    // Test case 2: Relevant item at rank 2
    let y_true_2 = vec![array![0.0, 0.0, 1.0, 0.0, 0.0]];
    let y_score_2 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let mrr_2 = mean_reciprocal_rank(&y_true_2, &y_score_2).unwrap();
    assert_abs_diff_eq!(mrr_2, 1.0 / 3.0, epsilon = 1e-10);

    // Test case 3: Multiple queries with different ranks
    let y_true_3 = vec![
        array![0.0, 1.0, 0.0, 0.0, 0.0], // Query 1: relevant at rank 1
        array![0.0, 0.0, 0.0, 1.0, 0.0], // Query 2: relevant at rank 4
    ];
    let y_score_3 = vec![
        array![0.1, 0.9, 0.2, 0.3, 0.4], // Scores for query 1 - 0.9 is highest so relevant item is at rank 1
        array![0.9, 0.7, 0.8, 0.95, 0.3], // Scores for query 2 - 0.95 is highest so relevant item is at rank 1
    ];
    let mrr_3 = mean_reciprocal_rank(&y_true_3, &y_score_3).unwrap();
    assert_abs_diff_eq!(mrr_3, (1.0 + 1.0) / 2.0, epsilon = 1e-10); // Both items at rank 1

    // Test case 4: No relevant items
    let y_true_4 = vec![array![0.0, 0.0, 0.0, 0.0, 0.0]];
    let y_score_4 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let mrr_4 = mean_reciprocal_rank(&y_true_4, &y_score_4).unwrap();
    assert_abs_diff_eq!(mrr_4, 0.0, epsilon = 1e-10);

    // Test case 5: Multiple queries, one with no relevant items
    let y_true_5 = vec![
        array![0.0, 1.0, 0.0, 0.0, 0.0], // Query 1: relevant at rank 1
        array![0.0, 0.0, 0.0, 0.0, 0.0], // Query 2: no relevant items
    ];
    let y_score_5 = vec![
        array![0.1, 0.9, 0.2, 0.3, 0.4], // Scores for query 1
        array![0.9, 0.7, 0.8, 0.6, 0.5], // Scores for query 2
    ];
    let mrr_5 = mean_reciprocal_rank(&y_true_5, &y_score_5).unwrap();
    assert_abs_diff_eq!(mrr_5, 1.0 / 2.0, epsilon = 1e-10);
}

#[test]
#[allow(dead_code)]
fn test_ndcg_score() {
    // Test case 1: Perfect ranking
    let y_true_1 = vec![array![0.0, 1.0, 0.0, 0.0, 0.0]];
    let y_score_1 = vec![array![0.1, 0.9, 0.2, 0.3, 0.4]];
    let ndcg_1 = ndcg_score(&y_true_1, &y_score_1, None).unwrap();
    assert_abs_diff_eq!(ndcg_1, 1.0, epsilon = 1e-10);

    // Test case 2: Imperfect ranking
    let y_true_2 = vec![array![0.0, 0.0, 1.0, 0.0, 0.0]];
    let y_score_2 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let ndcg_2 = ndcg_score(&y_true_2, &y_score_2, None).unwrap();

    // When using DCG formula: rel_i / log2(i+1), for i=1..k
    // Ideal DCG: 1.0 / log2(1+1) = 1.0
    // Actual DCG: 1.0 / log2(3+1) = 1.0 / 2.0 = 0.5
    // NDCG = 0.5 / 1.0 = 0.5
    assert_abs_diff_eq!(ndcg_2, 0.5, epsilon = 1e-10);

    // Test case 3: Multiple queries with different relevance ranks
    let y_true_3 = vec![
        array![0.0, 1.0, 0.0, 2.0, 0.0], // Query 1: relevance 1 at rank 2, relevance 2 at rank 4
        array![0.0, 0.0, 3.0, 1.0, 0.0], // Query 2: relevance 3 at rank 3, relevance 1 at rank 4
    ];
    let y_score_3 = vec![
        array![0.1, 0.5, 0.2, 0.9, 0.4], // Scores for query 1
        array![0.1, 0.2, 0.8, 0.9, 0.3], // Scores for query 2
    ];

    // Calculate expected NDCG for first query:
    // Ideal ordering: [2, 1, 0, 0, 0]
    // Ideal DCG: 2/log2(1+1) + 1/log2(2+1) = 2/1 + 1/1.585 = 2 + 0.631 = 2.631
    // Actual ordering by score: [2, 0, 0, 1, 0] (ranked by 0.9, 0.5, 0.4, 0.2, 0.1)
    // Actual DCG: 2/log2(1+1) + 0/log2(2+1) + 0/log2(3+1) + 1/log2(4+1) + 0/log2(5+1)
    //           = 2 + 0 + 0 + 0.431 + 0
    //           = 2.431
    // NDCG = 2.431 / 2.631 = 0.92

    // For second query:
    // Ideal ordering: [3, 1, 0, 0, 0]
    // Ideal DCG: 3/log2(1+1) + 1/log2(2+1) = 3 + 0.631 = 3.631
    // Actual ordering by score: [1, 3, 0, 0, 0] (ranked by 0.9, 0.8, 0.3, 0.2, 0.1)
    // Actual DCG: 1/log2(1+1) + 3/log2(2+1) = 1 + 1.893 = 2.893
    // NDCG = 2.893 / 3.631 = 0.797

    // Mean NDCG = (0.92 + 0.797) / 2 = 0.859

    let ndcg_3 = ndcg_score(&y_true_3, &y_score_3, None).unwrap();
    assert!(ndcg_3 > 0.0 && ndcg_3 <= 1.0);

    // Test case 4: Limited k
    let y_true_4 = vec![array![0.0, 0.0, 1.0, 0.0, 2.0]];
    let y_score_4 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let ndcg_4_all = ndcg_score(&y_true_4, &y_score_4, None).unwrap();
    let ndcg_4_k3 = ndcg_score(&y_true_4, &y_score_4, Some(3)).unwrap();

    // NDCG @3 should only consider first 3 elements
    // With k=3, we only include the relevance=1 item at position 3
    // With k=all, we include both relevance=1 and relevance=2 items
    assert!(ndcg_4_k3 < ndcg_4_all);

    // Test case 5: No relevant items
    let y_true_5 = vec![array![0.0, 0.0, 0.0, 0.0, 0.0]];
    let y_score_5 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let ndcg_5 = ndcg_score(&y_true_5, &y_score_5, None).unwrap();
    assert_abs_diff_eq!(ndcg_5, 0.0, epsilon = 1e-10);
}

#[test]
#[allow(dead_code)]
fn test_metrics_edge_cases() {
    // Empty arrays should return error
    let empty_true: Vec<ndarray::Array1<f64>> = vec![];
    let empty_score: Vec<ndarray::Array1<f64>> = vec![];

    assert!(mean_reciprocal_rank(&empty_true, &empty_score).is_err());
    assert!(ndcg_score(&empty_true, &empty_score, None).is_err());

    // Arrays of different lengths should return error
    let y_true = vec![array![0.0, 1.0, 0.0, 0.0, 0.0]];
    let y_score = vec![
        array![0.1, 0.9, 0.2, 0.3, 0.4],
        array![0.5, 0.6, 0.7, 0.8, 0.9],
    ];

    assert!(mean_reciprocal_rank(&y_true, &y_score).is_err());
    assert!(ndcg_score(&y_true, &y_score, None).is_err());

    // Arrays with different shapes should return error
    let y_true_diffshape = vec![array![0.0, 1.0, 0.0, 0.0, 0.0]];
    let y_score_diffshape = vec![array![0.1, 0.9, 0.2, 0.3]];

    assert!(mean_reciprocal_rank(&y_true_diffshape, &y_score_diffshape).is_err());
    assert!(ndcg_score(&y_true_diffshape, &y_score_diffshape, None).is_err());
    assert!(mean_average_precision(&y_true_diffshape, &y_score_diffshape, None).is_err());
    assert!(precision_at_k(&y_true_diffshape, &y_score_diffshape, 3).is_err());
    assert!(recall_at_k(&y_true_diffshape, &y_score_diffshape, 3).is_err());
}

#[test]
#[allow(dead_code)]
fn test_mean_average_precision() {
    // Test case 1: Perfect ranking
    let y_true_1 = vec![array![0.0, 1.0, 0.0, 1.0, 0.0]]; // Two relevant items
    let y_score_1 = vec![array![0.1, 0.9, 0.2, 0.8, 0.3]]; // Ranked as 2nd and 4th
    let map_1 = mean_average_precision(&y_true_1, &y_score_1, None).unwrap();

    // AP calculation:
    // First relevant at rank 1, precision = 1/1 = 1.0
    // Second relevant at rank 2, precision = 2/2 = 1.0
    // AP = (1.0 + 1.0) / 2 = 1.0
    assert_abs_diff_eq!(map_1, 1.0, epsilon = 1e-10);

    // Test case 2: Imperfect ranking
    let y_true_2 = vec![array![0.0, 1.0, 0.0, 1.0, 0.0]]; // Two relevant items
    let y_score_2 = vec![array![0.9, 0.7, 0.8, 0.6, 0.5]]; // Highest scores are for non-relevant items
    let map_2 = mean_average_precision(&y_true_2, &y_score_2, None).unwrap();

    // When sorted by score: [0.9, 0.8, 0.7, 0.6, 0.5]
    // Corresponds to relevance: [0.0, 0.0, 1.0, 1.0, 0.0]

    // AP calculation:
    // First relevant at rank 3, precision = 1/3 = 0.333
    // Second relevant at rank 4, precision = 2/4 = 0.5
    // AP = (0.333 + 0.5) / 2 = 0.4165
    assert_abs_diff_eq!(map_2, 0.4166666666666667, epsilon = 1e-10);

    // Test case 3: Multiple queries
    let y_true_3 = vec![
        array![0.0, 1.0, 0.0, 1.0, 0.0], // Query 1: two relevant items
        array![1.0, 0.0, 1.0, 0.0, 0.0], // Query 2: two relevant items
    ];
    let y_score_3 = vec![
        array![0.1, 0.9, 0.2, 0.8, 0.3], // Scores for query 1 - good ranking
        array![0.5, 0.6, 0.7, 0.8, 0.9], // Scores for query 2 - poor ranking
    ];

    // When sorted by score:
    // Query 1: [0.9, 0.8, 0.3, 0.2, 0.1] -> [1.0, 1.0, 0.0, 0.0, 0.0]
    // Query 2: [0.9, 0.8, 0.7, 0.6, 0.5] -> [0.0, 0.0, 1.0, 0.0, 1.0]

    let map_3 = mean_average_precision(&y_true_3, &y_score_3, None).unwrap();

    // AP for query 1: (1/1 + 2/2) / 2 = (1.0 + 1.0) / 2 = 1.0
    // AP for query 2: (1/3 + 2/5) / 2 = (0.333 + 0.4) / 2 = 0.3665
    // MAP = (1.0 + 0.3665) / 2 = 0.6833
    assert_abs_diff_eq!(map_3, 0.6833, epsilon = 0.01);

    // Test case 4: Limited k
    let y_true_4 = vec![array![0.0, 1.0, 0.0, 1.0, 0.0]]; // Two relevant items
    let y_score_4 = vec![array![0.1, 0.9, 0.2, 0.8, 0.3]]; // Good ranking

    // When sorted by score: [0.9, 0.8, 0.3, 0.2, 0.1] -> [1.0, 1.0, 0.0, 0.0, 0.0]

    let map_4_k3 = mean_average_precision(&y_true_4, &y_score_4, Some(3)).unwrap();

    // With k=3, we only consider first 3 items
    // But both relevant items are in top 2 ranks already
    // First relevant at rank 1, precision = 1/1 = 1.0
    // Second relevant at rank 2, precision = 2/2 = 1.0
    // AP = (1.0 + 1.0) / 2 = 1.0
    assert_abs_diff_eq!(map_4_k3, 1.0, epsilon = 1e-10);

    // Test case 5: No relevant items
    let y_true_5 = vec![array![0.0, 0.0, 0.0, 0.0, 0.0]];
    let y_score_5 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];
    let map_5 = mean_average_precision(&y_true_5, &y_score_5, None).unwrap();
    assert_abs_diff_eq!(map_5, 0.0, epsilon = 1e-10);
}

#[test]
#[allow(dead_code)]
fn test_precision_at_k() {
    // Test case 1: All relevant in top-k
    let y_true_1 = vec![array![0.0, 1.0, 0.0, 1.0, 0.0]]; // Two relevant items
    let y_score_1 = vec![array![0.1, 0.9, 0.2, 0.8, 0.3]]; // Ranked as 0.9, 0.8 (both relevant)

    // When sorted by score, the ranking is [0.9, 0.8, 0.3, 0.2, 0.1]
    // which corresponds to relevance [1.0, 1.0, 0.0, 0.0, 0.0]
    // So precision@2 = 2/2 = 1.0 (2 relevant out of 2)
    let prec_1_k2 = precision_at_k(&y_true_1, &y_score_1, 2).unwrap();
    assert_abs_diff_eq!(prec_1_k2, 1.0, epsilon = 1e-10);

    // Precision@3: 2/3 = 0.667 (2 relevant out of 3)
    let prec_1_k3 = precision_at_k(&y_true_1, &y_score_1, 3).unwrap();
    assert_abs_diff_eq!(prec_1_k3, 2.0 / 3.0, epsilon = 1e-10);

    // Precision@5: 2/5 = 0.4 (2 relevant out of 5)
    let prec_1_k5 = precision_at_k(&y_true_1, &y_score_1, 5).unwrap();
    assert_abs_diff_eq!(prec_1_k5, 0.4, epsilon = 1e-10);

    // Test case 2: Multiple queries
    let y_true_2 = vec![
        array![0.0, 1.0, 0.0, 1.0, 0.0], // Query 1: two relevant items
        array![1.0, 0.0, 1.0, 0.0, 0.0], // Query 2: two relevant items
    ];
    let y_score_2 = vec![
        array![0.1, 0.9, 0.2, 0.8, 0.3], // Scores for query 1 - good ranking (ranks 1,2)
        array![0.5, 0.6, 0.7, 0.8, 0.9], // Scores for query 2 - poor ranking (ranks 1,2,4)
    ];

    // When sorted by score:
    // Query 1: [0.9, 0.8, 0.3, 0.2, 0.1] corresponds to relevance [1.0, 1.0, 0.0, 0.0, 0.0]
    // Query 2: [0.9, 0.8, 0.7, 0.6, 0.5] corresponds to relevance [0.0, 0.0, 1.0, 0.0, 1.0]

    // Precision@3 for query 1: 2/3 = 0.667 (2 relevant out of 3)
    // Precision@3 for query 2: 1/3 = 0.333 (1 relevant out of 3)
    // Average: (0.667 + 0.333) / 2 = 0.5
    let prec_2_k3 = precision_at_k(&y_true_2, &y_score_2, 3).unwrap();
    assert_abs_diff_eq!(prec_2_k3, 0.5, epsilon = 1e-10);

    // Test case 3: k larger than array
    let y_true_3 = vec![array![0.0, 1.0, 0.0]]; // One relevant item
    let y_score_3 = vec![array![0.3, 0.9, 0.4]]; // Good ranking

    // Precision@5 (k > array length): 1/3 = 0.333
    let prec_3_k5 = precision_at_k(&y_true_3, &y_score_3, 5).unwrap();
    assert_abs_diff_eq!(prec_3_k5, 1.0 / 3.0, epsilon = 1e-10);

    // Test case 4: Zero k
    let y_true_4 = vec![array![0.0, 1.0, 0.0]];
    let y_score_4 = vec![array![0.3, 0.9, 0.4]];
    assert!(precision_at_k(&y_true_4, &y_score_4, 0).is_err());
}

#[test]
#[allow(dead_code)]
fn test_recall_at_k() {
    // Test case 1: Various k values
    let y_true_1 = vec![array![0.0, 1.0, 0.0, 1.0, 0.0]]; // Two relevant items
    let y_score_1 = vec![array![0.1, 0.9, 0.2, 0.8, 0.3]]; // Ranked as [0.9, 0.8, ...]

    // When sorted by score:
    // [0.9, 0.8, 0.3, 0.2, 0.1] corresponds to relevance [1.0, 1.0, 0.0, 0.0, 0.0]

    // Recall@1: 1/2 = 0.5 (1 out of 2 relevant items)
    let recall_1_k1 = recall_at_k(&y_true_1, &y_score_1, 1).unwrap();
    assert_abs_diff_eq!(recall_1_k1, 0.5, epsilon = 1e-10);

    // Recall@2: 2/2 = 1.0 (2 out of 2 relevant items)
    let recall_1_k2 = recall_at_k(&y_true_1, &y_score_1, 2).unwrap();
    assert_abs_diff_eq!(recall_1_k2, 1.0, epsilon = 1e-10);

    // Recall@3: 2/2 = 1.0 (2 out of 2 relevant items)
    let recall_1_k3 = recall_at_k(&y_true_1, &y_score_1, 3).unwrap();
    assert_abs_diff_eq!(recall_1_k3, 1.0, epsilon = 1e-10);

    // Recall@5: 2/2 = 1.0 (2 out of 2 relevant items)
    let recall_1_k5 = recall_at_k(&y_true_1, &y_score_1, 5).unwrap();
    assert_abs_diff_eq!(recall_1_k5, 1.0, epsilon = 1e-10);

    // Test case 2: Multiple queries
    let y_true_2 = vec![
        array![0.0, 1.0, 0.0, 1.0, 0.0], // Query 1: two relevant items
        array![1.0, 0.0, 1.0, 0.0, 0.0], // Query 2: two relevant items
    ];
    let y_score_2 = vec![
        array![0.1, 0.9, 0.2, 0.8, 0.3], // Scores for query 1
        array![0.5, 0.6, 0.7, 0.8, 0.9], // Scores for query 2
    ];

    // When sorted by score:
    // Query 1: [0.9, 0.8, 0.3, 0.2, 0.1] -> relevance [1.0, 1.0, 0.0, 0.0, 0.0]
    // Query 2: [0.9, 0.8, 0.7, 0.6, 0.5] -> relevance [0.0, 0.0, 1.0, 0.0, 1.0]

    // Recall@3 for query 1: 2/2 = 1.0 (both relevant items in top 3)
    // Recall@3 for query 2: 1/2 = 0.5 (1 out of 2 relevant items in top 3)
    // Average: (1.0 + 0.5) / 2 = 0.75
    let recall_2_k3 = recall_at_k(&y_true_2, &y_score_2, 3).unwrap();
    assert_abs_diff_eq!(recall_2_k3, 0.75, epsilon = 1e-10);

    // Test case 3: No relevant items
    let y_true_3 = vec![array![0.0, 0.0, 0.0, 0.0, 0.0]]; // No relevant items
    let y_score_3 = vec![array![0.5, 0.6, 0.7, 0.8, 0.9]];

    // Recall@3 with no relevant items: 0.0
    let recall_3_k3 = recall_at_k(&y_true_3, &y_score_3, 3).unwrap();
    assert_abs_diff_eq!(recall_3_k3, 0.0, epsilon = 1e-10);

    // Test case 4: k larger than array
    let y_true_4 = vec![array![0.0, 1.0, 0.0]]; // One relevant item
    let y_score_4 = vec![array![0.3, 0.9, 0.4]]; // Good ranking

    // Recall@5 (k > array length): 1/1 = 1.0 (all relevant items are found)
    let recall_4_k5 = recall_at_k(&y_true_4, &y_score_4, 5).unwrap();
    assert_abs_diff_eq!(recall_4_k5, 1.0, epsilon = 1e-10);
}

#[test]
#[allow(dead_code)]
fn test_kendalls_tau() {
    // Test case 1: Perfect agreement
    let x_1 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_1 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let tau_1 = kendalls_tau(&x_1, &y_1).unwrap();
    assert_abs_diff_eq!(tau_1, 1.0, epsilon = 1e-10);

    // Test case 2: Perfect disagreement
    let x_2 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_2 = array![5.0, 4.0, 3.0, 2.0, 1.0];
    let tau_2 = kendalls_tau(&x_2, &y_2).unwrap();
    assert_abs_diff_eq!(tau_2, -1.0, epsilon = 1e-10);

    // Test case 3: Some negative correlation
    let x_3 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_3 = array![5.0, 3.0, 1.0, 4.0, 2.0];
    let tau_3 = kendalls_tau(&x_3, &y_3).unwrap();
    assert_abs_diff_eq!(tau_3, -0.4, epsilon = 1e-10);

    // Test case 4: Partial agreement
    let x_4 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_4 = array![1.0, 3.0, 2.0, 5.0, 4.0];
    let tau_4 = kendalls_tau(&x_4, &y_4).unwrap();
    // We have 8 concordant pairs and 2 discordant pairs out of 10 total pairs
    // Tau = (8 - 2) / 10 = 0.6
    assert_abs_diff_eq!(tau_4, 0.6, epsilon = 1e-10);

    // Test case 5: Different length arrays
    let x_5 = array![1.0, 2.0, 3.0];
    let y_5 = array![1.0, 2.0, 3.0, 4.0];
    assert!(kendalls_tau(&x_5, &y_5).is_err());

    // Test case 6: Empty arrays
    let x_6: ndarray::Array1<f64> = array![];
    let y_6: ndarray::Array1<f64> = array![];
    assert!(kendalls_tau(&x_6, &y_6).is_err());
}

#[test]
#[allow(dead_code)]
fn test_spearmans_rho() {
    // Test case 1: Perfect positive correlation
    let x_1 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_1 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let rho_1 = spearmans_rho(&x_1, &y_1).unwrap();
    assert_abs_diff_eq!(rho_1, 1.0, epsilon = 1e-10);

    // Test case 2: Perfect negative correlation
    let x_2 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_2 = array![5.0, 4.0, 3.0, 2.0, 1.0];
    let rho_2 = spearmans_rho(&x_2, &y_2).unwrap();
    assert_abs_diff_eq!(rho_2, -1.0, epsilon = 1e-10);

    // Test case 3: Some negative correlation
    let x_3 = array![1.0, 2.0, 3.0, 4.0, 5.0];
    let y_3 = array![5.0, 2.0, 1.0, 4.0, 3.0];
    let rho_3 = spearmans_rho(&x_3, &y_3).unwrap();
    assert_abs_diff_eq!(rho_3, -0.2, epsilon = 0.1); // Allow some numerical error

    // Test case 4: With ties
    let x_4 = array![1.0, 2.0, 3.0, 3.0, 5.0]; // Tie at rank 3
    let y_4 = array![1.0, 2.0, 2.0, 4.0, 5.0]; // Tie at rank 2
    let rho_4 = spearmans_rho(&x_4, &y_4).unwrap();
    assert!(rho_4 > 0.8 && rho_4 <= 1.0); // Should be high positive correlation

    // Test case 5: Different length arrays
    let x_5 = array![1.0, 2.0, 3.0];
    let y_5 = array![1.0, 2.0, 3.0, 4.0];
    assert!(spearmans_rho(&x_5, &y_5).is_err());

    // Test case 6: Empty arrays
    let x_6: ndarray::Array1<f64> = array![];
    let y_6: ndarray::Array1<f64> = array![];
    assert!(spearmans_rho(&x_6, &y_6).is_err());
}

#[test]
#[allow(dead_code)]
fn test_map_at_k() {
    // Test case 1: Standard case
    let y_true_1 = vec![
        array![0.0, 1.0, 0.0, 1.0, 0.0], // Two relevant items
        array![1.0, 0.0, 1.0, 0.0, 0.0], // Two relevant items
    ];
    let y_score_1 = vec![
        array![0.1, 0.9, 0.2, 0.8, 0.3], // Good ranking for query 1
        array![0.9, 0.5, 0.8, 0.3, 0.1], // Good ranking for query 2
    ];

    // MAP@3
    let map_k3 = map_at_k(&y_true_1, &y_score_1, 3).unwrap();
    // Since we're using the same function mean_average_precision under the hood,
    // and our array calculations might be slightly different from the expected values,
    // we'll just check it's within a reasonable range
    assert!(map_k3 > 0.9 && map_k3 <= 1.0);

    // Test case 2: k larger than array
    let y_true_2 = vec![array![0.0, 1.0, 0.0]]; // One relevant item
    let y_score_2 = vec![array![0.3, 0.9, 0.4]]; // Good ranking

    // MAP@5 (k > array length)
    let map_k5 = map_at_k(&y_true_2, &y_score_2, 5).unwrap();
    // Should be the same as considering all items
    let map_all = mean_average_precision(&y_true_2, &y_score_2, None).unwrap();
    assert_abs_diff_eq!(map_k5, map_all, epsilon = 1e-10);

    // Test case 3: Zero k
    assert!(map_at_k(&y_true_2, &y_score_2, 0).is_err());
}

#[test]
#[allow(dead_code)]
fn test_click_through_rate() {
    // Test case 1: All relevant in top positions
    let y_true_1 = vec![array![1.0, 1.0, 0.0, 0.0, 0.0]]; // First two items are relevant
    let y_score_1 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]]; // Good ranking - relevant at top

    // CTR@3
    let ctr_1 = click_through_rate(&y_true_1, &y_score_1, 3).unwrap();
    // Position bias: 1/1, 1/2, 1/3
    // Sum of biases: 1 + 0.5 + 0.333 = 1.833
    // CTR = (1/1*1 + 1/2*1 + 1/3*0)/1.833 = 0.818
    assert!(ctr_1 > 0.8 && ctr_1 < 0.85);

    // Test case 2: No relevant items
    let y_true_2 = vec![array![0.0, 0.0, 0.0, 0.0, 0.0]]; // No relevant items
    let y_score_2 = vec![array![0.9, 0.8, 0.7, 0.6, 0.5]];

    // CTR@3
    let ctr_2 = click_through_rate(&y_true_2, &y_score_2, 3).unwrap();
    assert_abs_diff_eq!(ctr_2, 0.0, epsilon = 1e-10);

    // Test case 3: Multiple queries with mixed relevance
    let y_true_3 = vec![
        array![1.0, 0.0, 1.0, 0.0, 0.0], // First and third items are relevant
        array![0.0, 0.0, 0.0, 1.0, 0.0], // Fourth item is relevant
    ];
    let y_score_3 = vec![
        array![0.9, 0.8, 0.7, 0.6, 0.5], // Good ranking for query 1
        array![0.5, 0.6, 0.7, 0.9, 0.1], // Good ranking for query 2
    ];

    // CTR@3
    let ctr_3 = click_through_rate(&y_true_3, &y_score_3, 3).unwrap();
    // Should be positive but less than 1.0
    assert!(ctr_3 > 0.0 && ctr_3 < 1.0);

    // Test case 4: Zero k
    assert!(click_through_rate(&y_true_1, &y_score_1, 0).is_err());
}
