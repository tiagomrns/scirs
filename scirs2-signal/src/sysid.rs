use ndarray::s;
// System Identification Module
//
// This module provides comprehensive system identification functionality for
// estimating mathematical models of dynamic systems from input-output data.
//
// ## Features
//
// - **Transfer Function Estimation**: Estimate transfer functions from input-output data
// - **Parametric Models**: AR, ARMA, and ARX model identification
// - **Non-parametric Methods**: Frequency response estimation using spectral methods
// - **Model Validation**: Cross-validation, residual analysis, and information criteria
// - **Subspace Methods**: Simple N4SID implementation for state-space identification
// - **Recursive Methods**: Online/adaptive identification algorithms
//
// ## System Identification Methods
//
// ### Time-Domain Methods
// - Least squares estimation for ARX models
// - Prediction error methods for ARMA models
// - Maximum likelihood estimation
// - Instrumental variable methods
//
// ### Frequency-Domain Methods
// - Spectral analysis based estimation
// - Frequency response function estimation
// - Empirical transfer function estimation
//
// ### Subspace Methods
// - N4SID (Numerical algorithms for Subspace State Space System Identification)
// - MOESP (Multivariable Output-Error State sPace)
//
// ## Example Usage
//
// ```rust
// use ndarray::Array1;
// use scirs2_signal::sysid::{estimate_transfer_function, TfEstimationMethod, ModelValidation};
// use scirs2_signal::waveforms::chirp;
// # fn main() -> Result<(), Box<dyn std::error::Error>> {
//
// // Generate test system and data
// let n = 1000;
// let fs = 100.0;
// let t = Array1::linspace(0.0, (n-1) as f64 / fs, n);
//
// // Create chirp input signal
// let input_vec = chirp(t.as_slice().unwrap(), 1.0, t[t.len()-1], 20.0, "linear", 0.0)?;
// let input = Array1::from(input_vec);
//
// // Simulate system output (simple first-order system)
// let mut output = Array1::zeros(n);
// let a = 0.9; // System parameter
// for i in 1..n {
//     output[i] = a * output[i-1] + (1.0 - a) * input[i-1];
// }
//
// // Estimate transfer function
// let result = estimate_transfer_function(
//     &input, &output, fs, 2, 2, TfEstimationMethod::LeastSquares
// )?;
//
// println!("Estimated numerator: {:?}", result.numerator);
// println!("Estimated denominator: {:?}", result.denominator);
// println!("Fit percentage: {:.2}%", result.fit_percentage);
// # Ok(())
// # }
// ```

use crate::error::{SignalError, SignalResult};
use crate::lombscargle_enhanced::WindowType;
use crate::lti::{LtiSystem, TransferFunction};
use crate::parametric::{estimate_ar, estimate_arma, ARMethod, OrderSelection};
use crate::spectral::welch;
use crate::window::get_window;
use ndarray::{Array1, Array2, Axis};
use num_complex::Complex64;
use statrs::statistics::Statistics;

#[allow(unused_imports)]
/// Methods for transfer function estimation
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum TfEstimationMethod {
    /// Least squares in time domain
    LeastSquares,
    /// Frequency domain estimation using spectral methods
    FrequencyDomain,
    /// Instrumental variable method
    InstrumentalVariable,
    /// Subspace-based estimation
    Subspace,
}

/// Methods for frequency response estimation
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum FreqResponseMethod {
    /// Welch's method using overlapping windows
    Welch,
    /// Simple periodogram
    Periodogram,
    /// H1 estimator (minimize input noise)
    H1,
    /// H2 estimator (minimize output noise)
    H2,
    /// Coherence-weighted estimator
    CoherenceWeighted,
}

/// Configuration for system identification
#[derive(Debug, Clone)]
pub struct SysIdConfig {
    /// Sampling frequency
    pub fs: f64,
    /// Window type for spectral estimation
    pub window: String,
    /// Window overlap for spectral methods (0.0 to 1.0)
    pub overlap: f64,
    /// Number of FFT points for spectral estimation
    pub nfft: Option<usize>,
    /// Regularization parameter for least squares
    pub regularization: Option<f64>,
    /// Maximum number of iterations for iterative methods
    pub max_iterations: usize,
    /// Convergence tolerance for iterative methods
    pub tolerance: f64,
}

impl Default for SysIdConfig {
    fn default() -> Self {
        Self {
            fs: 1.0,
            window: WindowType::Hann.to_string(),
            overlap: 0.5,
            nfft: None,
            regularization: None,
            max_iterations: 100,
            tolerance: 1e-6,
        }
    }
}

/// Result structure for transfer function estimation
#[derive(Debug, Clone)]
pub struct TfEstimationResult {
    /// Estimated transfer function numerator coefficients
    pub numerator: Array1<f64>,
    /// Estimated transfer function denominator coefficients  
    pub denominator: Array1<f64>,
    /// Model fit percentage (0-100)
    pub fit_percentage: f64,
    /// Final prediction error variance
    pub error_variance: f64,
    /// Frequency response at estimation frequencies
    pub frequency_response: Option<Array1<Complex64>>,
    /// Frequencies used for estimation
    pub frequencies: Option<Array1<f64>>,
}

/// Result structure for frequency response estimation
#[derive(Debug, Clone)]
pub struct FreqResponseResult {
    /// Estimated frequency response
    pub frequency_response: Array1<Complex64>,
    /// Frequencies
    pub frequencies: Array1<f64>,
    /// Coherence function
    pub coherence: Array1<f64>,
    /// Confidence bounds (if available)
    pub confidence_bounds: Option<Array2<f64>>,
}

/// Structure for AR/ARMA identification results
#[derive(Debug, Clone)]
pub struct ParametricResult {
    /// AR coefficients
    pub ar_coefficients: Array1<f64>,
    /// MA coefficients (if ARMA)
    pub ma_coefficients: Option<Array1<f64>>,
    /// Noise variance
    pub noise_variance: f64,
    /// Reflection coefficients (if available)
    pub reflection_coefficients: Option<Array1<f64>>,
    /// Information criterion value
    pub information_criterion: f64,
    /// Model order
    pub model_order: (usize, usize), // (AR order, MA order)
}

/// Model validation result
#[derive(Debug, Clone)]
pub struct ModelValidation {
    /// Model fit percentage
    pub fit_percentage: f64,
    /// Mean squared error
    pub mse: f64,
    /// R-squared coefficient
    pub r_squared: f64,
    /// Final prediction error
    pub fpe: f64,
    /// Akaike Information Criterion
    pub aic: f64,
    /// Bayesian Information Criterion
    pub bic: f64,
    /// Residual whiteness test p-value
    pub whiteness_test: f64,
    /// Cross-validation error (if performed)
    pub cv_error: Option<f64>,
}

/// Estimate transfer function from input-output data
///
/// # Arguments
/// * `input` - Input signal
/// * `output` - Output signal  
/// * `fs` - Sampling frequency
/// * `num_order` - Numerator order
/// * `den_order` - Denominator order
/// * `method` - Estimation method
///
/// # Returns
/// * Transfer function estimation result
///
/// # Example
/// ```
/// use ndarray::Array1;
/// use scirs2_signal::sysid::{estimate_transfer_function, TfEstimationMethod};
/// # fn main() -> Result<(), Box<dyn std::error::Error>> {
///
/// // Create longer test signals to avoid singular matrix
/// let input = Array1::from_vec(vec![1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0.05, 0.0, 0.0, 0.0]);
/// let output = Array1::from_vec(vec![0.0, 0.5, 0.65, 0.725, 0.7625, 0.68125, 0.540625, 0.2703125, 0.13515625, 0.067578125]);
/// let fs = 1.0;
///
/// let result = estimate_transfer_function(
///     &input, &output, fs, 1, 1, TfEstimationMethod::LeastSquares
/// )?;
///
/// // Should estimate something like H(z) = 0.5 / (z - 0.5)
/// println!("Estimated transfer function with {} numerator and {} denominator coefficients",
///          result.numerator.len(), result.denominator.len());
/// # Ok(())
/// # }
/// ```
#[allow(dead_code)]
pub fn estimate_transfer_function(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    num_order: usize,
    den_order: usize,
    method: TfEstimationMethod,
) -> SignalResult<TfEstimationResult> {
    if input.len() != output.len() {
        return Err(SignalError::ValueError(
            "Input and output signals must have the same length".to_string(),
        ));
    }

    if input.len() < num_order + den_order + 1 {
        return Err(SignalError::ValueError(
            "Signal length insufficient for specified model orders".to_string(),
        ));
    }

    match method {
        TfEstimationMethod::LeastSquares => {
            estimate_tf_least_squares(input, output, fs, num_order, den_order)
        }
        TfEstimationMethod::FrequencyDomain => {
            estimate_tf_frequency_domain(input, output, fs, num_order, den_order)
        }
        TfEstimationMethod::InstrumentalVariable => {
            estimate_tf_instrumental_variable(input, output, fs, num_order, den_order)
        }
        TfEstimationMethod::Subspace => {
            estimate_tf_subspace(input, output, fs, num_order, den_order)
        }
    }
}

/// Least squares transfer function estimation
#[allow(dead_code)]
fn estimate_tf_least_squares(
    input: &Array1<f64>,
    output: &Array1<f64>,
    _fs: f64,
    num_order: usize,
    den_order: usize,
) -> SignalResult<TfEstimationResult> {
    let n = input.len();
    let total_order = num_order + den_order;

    if n <= total_order {
        return Err(SignalError::ValueError(
            "Insufficient data for specified model orders".to_string(),
        ));
    }

    // Build the regression matrix for ARX model: A(z)y(k) = B(z)u(k) + e(k)
    let data_length = n - total_order;
    let param_count = num_order + den_order + 1;

    let mut phi = Array2::<f64>::zeros((data_length, param_count));
    let mut y_vec = Array1::<f64>::zeros(data_length);

    for i in 0..data_length {
        let t = i + total_order;

        // Output regression vector (negative AR terms)
        for j in 1..=den_order {
            phi[[i, j - 1]] = -output[t - j];
        }

        // Input regression vector
        for j in 0..=num_order {
            if t >= j {
                phi[[i, den_order + j]] = input[t - j];
            }
        }

        y_vec[i] = output[t];
    }

    // Solve least squares problem: phi * theta = y
    let phi_t = phi.t();
    let phi_t_phi = phi_t.dot(&phi);
    let phi_t_y = phi_t.dot(&y_vec);

    // Add regularization if needed
    let mut ata = phi_t_phi;
    if let Some(reg) = None::<f64> {
        for i in 0..ata.nrows() {
            ata[[i, i]] += reg;
        }
    }

    let theta = solve_linear_system(&ata, &phi_t_y)?;

    // Extract denominator and numerator coefficients
    let mut denominator = Array1::<f64>::zeros(den_order + 1);
    denominator[0] = 1.0;
    for i in 1..=den_order {
        denominator[i] = theta[i - 1];
    }

    let mut numerator = Array1::<f64>::zeros(num_order + 1);
    for i in 0..=num_order {
        numerator[i] = theta[den_order + i];
    }

    // Calculate model fit
    let y_pred = phi.dot(&theta);
    let fit_percentage = calculate_fit_percentage(&y_vec, &y_pred);

    // Calculate error variance
    let residuals = &y_vec - &y_pred;
    let error_variance = residuals.mapv(|x| x * x).mean().unwrap_or(0.0);

    Ok(TfEstimationResult {
        numerator,
        denominator,
        fit_percentage,
        error_variance,
        frequency_response: None,
        frequencies: None,
    })
}

/// Frequency domain transfer function estimation using spectral methods
#[allow(dead_code)]
fn estimate_tf_frequency_domain(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    num_order: usize,
    den_order: usize,
) -> SignalResult<TfEstimationResult> {
    // Estimate frequency response first
    let freq_result = estimate_frequency_response(
        input,
        output,
        fs,
        FreqResponseMethod::Welch,
        &SysIdConfig::default(),
    )?;

    // Fit parametric model to frequency response
    fit_parametric_to_frequency_response(
        &freq_result.frequency_response,
        &freq_result.frequencies,
        num_order,
        den_order,
    )
}

/// Instrumental variable method for transfer function estimation
#[allow(dead_code)]
fn estimate_tf_instrumental_variable(
    input: &Array1<f64>,
    output: &Array1<f64>,
    _fs: f64,
    num_order: usize,
    den_order: usize,
) -> SignalResult<TfEstimationResult> {
    // For now, use a simplified IV approach where instruments are delayed inputs
    let n = input.len();
    let total_order = num_order + den_order;
    let delay = 1; // Instrument delay

    if n <= total_order + delay {
        return Err(SignalError::ValueError(
            "Insufficient data for IV estimation".to_string(),
        ));
    }

    let data_length = n - total_order - delay;
    let param_count = num_order + den_order + 1;

    let mut phi = Array2::<f64>::zeros((data_length, param_count));
    let mut z = Array2::<f64>::zeros((data_length, param_count)); // Instruments
    let mut y_vec = Array1::<f64>::zeros(data_length);

    for i in 0..data_length {
        let t = i + total_order + delay;

        // Regression vector
        for j in 1..=den_order {
            phi[[i, j - 1]] = -output[t - j];
        }
        for j in 0..=num_order {
            if t >= j {
                phi[[i, den_order + j]] = input[t - j];
            }
        }

        // Instruments (delayed inputs and past outputs)
        for j in 1..=den_order {
            z[[i, j - 1]] = -output[t - j - delay];
        }
        for j in 0..=num_order {
            if t >= j + delay {
                z[[i, den_order + j]] = input[t - j - delay];
            }
        }

        y_vec[i] = output[t];
    }

    // IV estimation: theta = (Z'Phi)^(-1) Z'y
    let z_t = z.t();
    let z_t_phi = z_t.dot(&phi);
    let z_t_y = z_t.dot(&y_vec);

    let theta = solve_linear_system(&z_t_phi, &z_t_y)?;

    // Extract coefficients
    let mut denominator = Array1::<f64>::zeros(den_order + 1);
    denominator[0] = 1.0;
    for i in 1..=den_order {
        denominator[i] = theta[i - 1];
    }

    let mut numerator = Array1::<f64>::zeros(num_order + 1);
    for i in 0..=num_order {
        numerator[i] = theta[den_order + i];
    }

    // Calculate fit
    let y_pred = phi.dot(&theta);
    let fit_percentage = calculate_fit_percentage(&y_vec, &y_pred);
    let residuals = &y_vec - &y_pred;
    let error_variance = residuals.mapv(|x| x * x).mean().unwrap_or(0.0);

    Ok(TfEstimationResult {
        numerator,
        denominator,
        fit_percentage,
        error_variance,
        frequency_response: None,
        frequencies: None,
    })
}

/// Simplified subspace-based transfer function estimation
#[allow(dead_code)]
fn estimate_tf_subspace(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    num_order: usize,
    den_order: usize,
) -> SignalResult<TfEstimationResult> {
    // This is a placeholder for a full N4SID implementation
    // For now, fall back to least squares
    estimate_tf_least_squares(input, output, fs, num_order, den_order)
}

/// Estimate frequency response function from input-output data
///
/// # Arguments
/// * `input` - Input signal
/// * `output` - Output signal
/// * `fs` - Sampling frequency  
/// * `method` - Frequency response estimation method
/// * `config` - Configuration parameters
///
/// # Returns
/// * Frequency response estimation result
#[allow(dead_code)]
pub fn estimate_frequency_response(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    method: FreqResponseMethod,
    config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    if input.len() != output.len() {
        return Err(SignalError::ValueError(
            "Input and output signals must have the same length".to_string(),
        ));
    }

    match method {
        FreqResponseMethod::Welch => estimate_freq_response_welch(input, output, fs, config),
        FreqResponseMethod::Periodogram => {
            estimate_freq_response_periodogram(input, output, fs, config)
        }
        FreqResponseMethod::H1 => estimate_freq_response_h1(input, output, fs, config),
        FreqResponseMethod::H2 => estimate_freq_response_h2(input, output, fs, config),
        FreqResponseMethod::CoherenceWeighted => {
            estimate_freq_response_coherence_weighted(input, output, fs, config)
        }
    }
}

/// Frequency response estimation using Welch's method
#[allow(dead_code)]
fn estimate_freq_response_welch(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    // Use Welch's method to estimate cross-spectral density and auto-spectral density
    let nfft = config.nfft.unwrap_or(next_power_of_2(input.len() / 8));
    let overlap = (nfft as f64 * config.overlap) as usize;

    // Get cross-power spectral density
    let (freqs, pxy) =
        cross_spectral_density_welch(input, output, fs, nfft, overlap, &config.window)?;

    // Get input auto-power spectral density
    let (_, pxx) = welch(
        input.as_slice().unwrap(),
        Some(fs),
        Some(&config.window),
        Some(nfft),
        Some(overlap),
        Some(nfft),
        None,
        None,
    )?;

    // Calculate frequency response H(f) = Pxy(f) / Pxx(f)
    let mut freq_response = Array1::<Complex64>::zeros(freqs.len());
    let mut coherence = Array1::<f64>::zeros(freqs.len());

    // Also need output auto-spectral density for coherence
    let (_, pyy) = welch(
        output.as_slice().unwrap(),
        Some(fs),
        Some(&config.window),
        Some(nfft),
        Some(overlap),
        Some(nfft),
        None,
        None,
    )?;

    for i in 0..freqs.len() {
        if pxx[i].abs() > 1e-12 {
            freq_response[i] = pxy[i] / pxx[i];

            // Calculate coherence: |Pxy|^2 / (Pxx * Pyy)
            let coherence_val = pxy[i].norm_sqr() / (pxx[i].abs() * pyy[i]);
            coherence[i] = coherence_val.clamp(0.0, 1.0);
        } else {
            freq_response[i] = Complex64::new(0.0, 0.0);
            coherence[i] = 0.0;
        }
    }

    Ok(FreqResponseResult {
        frequency_response: freq_response,
        frequencies: freqs,
        coherence,
        confidence_bounds: None,
    })
}

/// Cross-spectral density estimation using Welch's method
#[allow(dead_code)]
fn cross_spectral_density_welch(
    x: &Array1<f64>,
    y: &Array1<f64>,
    fs: f64,
    nfft: usize,
    overlap: usize,
    window_name: &str,
) -> SignalResult<(Array1<f64>, Array1<Complex64>)> {
    let n = x.len();
    let step = nfft - overlap;

    if step == 0 {
        return Err(SignalError::ValueError(
            "Invalid overlap specification".to_string(),
        ));
    }

    // Generate window
    let window = get_window(window_name, nfft, true)?;
    let window_array = Array1::from(window);
    let window_norm = window_array.mapv(|w| w * w).sum().sqrt();

    let mut num_segments = 0;
    let mut pxy_acc = Array1::<Complex64>::zeros(nfft / 2 + 1);

    // Process overlapping segments
    for start in (0..n).step_by(step) {
        if start + nfft > n {
            break;
        }

        // Extract segments and apply window
        let x_seg = x.slice(ndarray::s![start..start + nfft]).to_owned() * &window_array;
        let y_seg = y.slice(ndarray::s![start..start + nfft]).to_owned() * &window_array;

        // Compute FFTs
        let x_fft = compute_fft(&x_seg);
        let y_fft = compute_fft(&y_seg);

        // Compute cross-spectral density for this segment
        let max_freq_bin = if nfft % 2 == 0 {
            nfft / 2
        } else {
            (nfft - 1) / 2
        };
        for i in 0..=max_freq_bin {
            pxy_acc[i] += x_fft[i].conj() * y_fft[i];
        }

        num_segments += 1;
    }

    if num_segments == 0 {
        return Err(SignalError::ValueError(
            "No complete segments found".to_string(),
        ));
    }

    // Average and normalize
    let scale = fs * window_norm * window_norm * num_segments as f64;
    pxy_acc.mapv_inplace(|x| x / scale);

    // Create frequency vector
    let freqs = Array1::linspace(0.0, fs / 2.0, nfft / 2 + 1);

    Ok((freqs, pxy_acc))
}

/// Simple periodogram-based frequency response estimation
#[allow(dead_code)]
fn estimate_freq_response_periodogram(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    _config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    let n = input.len();
    let nfft = next_power_of_2(n);

    // Compute FFTs
    let mut input_padded = Array1::<f64>::zeros(nfft);
    let mut output_padded = Array1::<f64>::zeros(nfft);

    input_padded.slice_mut(ndarray::s![0..n]).assign(input);
    output_padded.slice_mut(ndarray::s![0..n]).assign(output);

    let input_fft = compute_fft(&input_padded);
    let output_fft = compute_fft(&output_padded);

    // Compute frequency response
    let mut freq_response = Array1::<Complex64>::zeros(nfft / 2 + 1);
    let mut coherence = Array1::<f64>::zeros(nfft / 2 + 1);

    for i in 0..=nfft / 2 {
        let idx = if i == nfft / 2 { nfft / 2 } else { i };
        if input_fft[idx].norm() > 1e-12 {
            freq_response[i] = output_fft[idx] / input_fft[idx];
            // Simple coherence estimate (not very reliable for single realization)
            coherence[i] = 0.8; // Placeholder
        }
    }

    let freqs = Array1::linspace(0.0, fs / 2.0, nfft / 2 + 1);

    Ok(FreqResponseResult {
        frequency_response: freq_response,
        frequencies: freqs,
        coherence,
        confidence_bounds: None,
    })
}

/// H1 estimator (minimizes input noise effects)
#[allow(dead_code)]
fn estimate_freq_response_h1(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    // H1 = Pyx / Pxx (same as Welch method)
    estimate_freq_response_welch(input, output, fs, config)
}

/// H2 estimator (minimizes output noise effects)  
#[allow(dead_code)]
fn estimate_freq_response_h2(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    // H2 = Pyy / Pxy
    let nfft = config.nfft.unwrap_or(next_power_of_2(input.len() / 8));
    let overlap = (nfft as f64 * config.overlap) as usize;

    let (freqs, pxy) =
        cross_spectral_density_welch(input, output, fs, nfft, overlap, &config.window)?;
    let (_, pyy) = welch(
        output.as_slice().unwrap(),
        Some(fs),
        Some(&config.window),
        Some(nfft),
        Some(overlap),
        Some(nfft),
        None,
        None,
    )?;
    let (_, pxx) = welch(
        input.as_slice().unwrap(),
        Some(fs),
        Some(&config.window),
        Some(nfft),
        Some(overlap),
        Some(nfft),
        None,
        None,
    )?;

    let mut freq_response = Array1::<Complex64>::zeros(freqs.len());
    let mut coherence = Array1::<f64>::zeros(freqs.len());

    for i in 0..freqs.len() {
        if pxy[i].norm() > 1e-12 {
            freq_response[i] = Complex64::new(pyy[i], 0.0) / pxy[i];

            let coherence_val = pxy[i].norm_sqr() / (pxx[i] * pyy[i]);
            coherence[i] = coherence_val.clamp(0.0, 1.0);
        }
    }

    Ok(FreqResponseResult {
        frequency_response: freq_response,
        frequencies: freqs,
        coherence,
        confidence_bounds: None,
    })
}

/// Coherence-weighted frequency response estimation
#[allow(dead_code)]
fn estimate_freq_response_coherence_weighted(
    input: &Array1<f64>,
    output: &Array1<f64>,
    fs: f64,
    config: &SysIdConfig,
) -> SignalResult<FreqResponseResult> {
    let h1_result = estimate_freq_response_h1(input, output, fs, config)?;
    let h2_result = estimate_freq_response_h2(input, output, fs, config)?;

    let mut freq_response = Array1::<Complex64>::zeros(h1_result.frequencies.len());

    // Weight estimates by coherence
    for i in 0..freq_response.len() {
        let gamma = h1_result.coherence[i];
        freq_response[i] = gamma * h1_result.frequency_response[i]
            + (1.0 - gamma) * h2_result.frequency_response[i];
    }

    Ok(FreqResponseResult {
        frequency_response: freq_response,
        frequencies: h1_result.frequencies,
        coherence: h1_result.coherence,
        confidence_bounds: None,
    })
}

/// Fit parametric model to frequency response data
#[allow(dead_code)]
fn fit_parametric_to_frequency_response(
    freq_response: &Array1<Complex64>,
    frequencies: &Array1<f64>,
    num_order: usize,
    den_order: usize,
) -> SignalResult<TfEstimationResult> {
    let n_freq = frequencies.len();
    if n_freq < num_order + den_order + 1 {
        return Err(SignalError::ValueError(
            "Insufficient frequency points for model orders".to_string(),
        ));
    }

    // Set up complex least squares problem
    // H(jw) = (b0 + b1*(jw) + ... + bm*(jw)^m) / (1 + a1*(jw) + ... + an*(jw)^n)
    let total_params = num_order + den_order + 1;
    let mut a_matrix = Array2::<Complex64>::zeros((n_freq, total_params));
    let mut b_vector = Array1::<Complex64>::zeros(n_freq);

    for (i, &freq) in frequencies.iter().enumerate() {
        let jw = Complex64::new(0.0, 2.0 * PI * freq);
        let h_val = freq_response[i];

        // Fill the regression matrix
        let mut jw_power = Complex64::new(1.0, 0.0);

        // Denominator terms (multiply by -H(jw))
        for k in 1..=den_order {
            jw_power *= jw;
            a_matrix[[i, k - 1]] = -h_val * jw_power;
        }

        // Numerator terms
        jw_power = Complex64::new(1.0, 0.0);
        for k in 0..=num_order {
            a_matrix[[i, den_order + k]] = jw_power;
            if k < num_order {
                jw_power *= jw;
            }
        }

        b_vector[i] = h_val;
    }

    // Solve complex least squares (use real and imaginary parts separately)
    let params = solve_complex_least_squares(&a_matrix, &b_vector)?;

    // Extract real coefficients
    let mut denominator = Array1::<f64>::zeros(den_order + 1);
    denominator[0] = 1.0;
    for i in 1..=den_order {
        denominator[i] = params[i - 1].re;
    }

    let mut numerator = Array1::<f64>::zeros(num_order + 1);
    for i in 0..=num_order {
        numerator[i] = params[den_order + i].re;
    }

    // Calculate fit quality
    let tf = TransferFunction::new(numerator.to_vec(), denominator.to_vec(), None)?;
    let estimated_response = tf.frequency_response(&frequencies.mapv(|f| 2.0 * PI * f).to_vec())?;

    let mut error_sum = 0.0;
    let mut signal_sum = 0.0;
    for i in 0..n_freq {
        let error = (freq_response[i] - estimated_response[i]).norm_sqr();
        error_sum += error;
        signal_sum += freq_response[i].norm_sqr();
    }

    let fit_percentage = 100.0 * (1.0 - error_sum / signal_sum).max(0.0);

    Ok(TfEstimationResult {
        numerator,
        denominator,
        fit_percentage,
        error_variance: error_sum / n_freq as f64,
        frequency_response: Some(Array1::from_vec(estimated_response)),
        frequencies: Some(frequencies.clone()),
    })
}

/// Identify AR model from single time series
///
/// # Arguments
/// * `signal` - Input time series
/// * `max_order` - Maximum AR order to consider
/// * `method` - AR estimation method
/// * `selection_criterion` - Order selection criterion
///
/// # Returns
/// * Parametric model identification result
#[allow(dead_code)]
pub fn identify_ar_model(
    signal: &Array1<f64>,
    max_order: usize,
    method: ARMethod,
    selection_criterion: OrderSelection,
) -> SignalResult<ParametricResult> {
    // Select optimal _order
    let (optimal_order, criteria) =
        crate::parametric::select_ar_order(signal, max_order, selection_criterion, method)?;

    // Estimate AR parameters with optimal _order
    let (ar_coeffs, reflection_coeffs, noise_var) = estimate_ar(signal, optimal_order, method)?;

    Ok(ParametricResult {
        ar_coefficients: ar_coeffs,
        ma_coefficients: None,
        noise_variance: noise_var,
        reflection_coefficients: reflection_coeffs,
        information_criterion: criteria[optimal_order],
        model_order: (optimal_order, 0),
    })
}

/// Identify ARMA model from single time series
///
/// # Arguments
/// * `signal` - Input time series
/// * `max_ar_order` - Maximum AR order to consider
/// * `max_ma_order` - Maximum MA order to consider
/// * `selection_criterion` - Order selection criterion
///
/// # Returns
/// * Parametric model identification result
#[allow(dead_code)]
pub fn identify_arma_model(
    signal: &Array1<f64>,
    max_ar_order: usize,
    max_ma_order: usize,
    selection_criterion: OrderSelection,
) -> SignalResult<ParametricResult> {
    let n = signal.len() as f64;
    let mut best_criterion = f64::INFINITY;
    let mut best_result = None;

    // Grid search over AR and MA orders
    for ar_order in 1..=max_ar_order {
        for ma_order in 0..=max_ma_order {
            if ar_order + ma_order >= signal.len() / 2 {
                continue;
            }

            if let Ok((ar_coeffs, ma_coeffs, noise_var)) = estimate_arma(signal, ar_order, ma_order)
            {
                // Calculate information _criterion
                let k = ar_order + ma_order;
                let log_likelihood = -0.5 * n * (2.0 * PI * noise_var).ln() - 0.5 * n;

                let criterion_value = match selection_criterion {
                    OrderSelection::AIC => -2.0 * log_likelihood + 2.0 * k as f64,
                    OrderSelection::BIC => -2.0 * log_likelihood + k as f64 * n.ln(),
                    OrderSelection::AICc => {
                        -2.0 * log_likelihood + 2.0 * k as f64 * n / (n - k as f64 - 1.0)
                    }
                    _ => -2.0 * log_likelihood + 2.0 * k as f64,
                };

                if criterion_value < best_criterion {
                    best_criterion = criterion_value;
                    best_result = Some(ParametricResult {
                        ar_coefficients: ar_coeffs,
                        ma_coefficients: Some(ma_coeffs),
                        noise_variance: noise_var,
                        reflection_coefficients: None,
                        information_criterion: criterion_value,
                        model_order: (ar_order, ma_order),
                    });
                }
            }
        }
    }

    best_result.ok_or_else(|| {
        SignalError::ComputationError("Failed to find suitable ARMA model".to_string())
    })
}

/// Validate identified model using various metrics
///
/// # Arguments
/// * `predicted` - Model predictions
/// * `actual` - Actual observations
/// * `model_order` - Total number of model parameters
/// * `perform_whiteness_test` - Whether to test residual whiteness
///
/// # Returns
/// * Model validation results
#[allow(dead_code)]
pub fn validate_model(
    predicted: &Array1<f64>,
    actual: &Array1<f64>,
    model_order: usize,
    perform_whiteness_test: bool,
) -> SignalResult<ModelValidation> {
    if predicted.len() != actual.len() {
        return Err(SignalError::ValueError(
            "Predicted and actual arrays must have same length".to_string(),
        ));
    }

    let n = actual.len() as f64;

    // Calculate residuals
    let residuals = actual - predicted;

    // Mean squared error
    let mse = residuals.mapv(|x| x * x).mean().unwrap_or(0.0);

    // R-squared
    let y_mean = actual.mean().unwrap_or(0.0);
    let ss_tot = actual.mapv(|y| (y - y_mean).powi(2)).sum();
    let ss_res = residuals.mapv(|x| x * x).sum();
    let r_squared = if ss_tot > 0.0 {
        1.0 - ss_res / ss_tot
    } else {
        0.0
    };

    // Fit percentage
    let fit_percentage = calculate_fit_percentage(actual, predicted);

    // Information criteria
    let log_likelihood = -0.5 * n * (2.0 * PI * mse).ln() - 0.5 * n;
    let aic = -2.0 * log_likelihood + 2.0 * model_order as f64;
    let bic = -2.0 * log_likelihood + model_order as f64 * n.ln();

    // Final prediction error
    let fpe = mse * (n + model_order as f64) / (n - model_order as f64);

    // Whiteness _test (Ljung-Box _test approximation)
    let whiteness_test = if perform_whiteness_test {
        ljung_box_test(&residuals, 10)
    } else {
        1.0 // No _test performed
    };

    Ok(ModelValidation {
        fit_percentage,
        mse,
        r_squared,
        fpe,
        aic,
        bic,
        whiteness_test,
        cv_error: None,
    })
}

/// Simple N4SID implementation for state-space identification
///
/// # Arguments
/// * `input` - Input signal
/// * `output` - Output signal  
/// * `state_order` - Desired state-space order
/// * `past_horizon` - Past data horizon
/// * `future_horizon` - Future data horizon
///
/// # Returns
/// * State-space matrices (A, B, C, D)
#[allow(clippy::type_complexity)]
#[allow(dead_code)]
pub fn n4sid_identification(
    input: &Array1<f64>,
    _output: &Array1<f64>,
    state_order: usize,
    past_horizon: usize,
    future_horizon: usize,
) -> SignalResult<(Array2<f64>, Array2<f64>, Array2<f64>, Array2<f64>)> {
    let n = input.len();

    if n < past_horizon + future_horizon + state_order {
        return Err(SignalError::ValueError(
            "Insufficient data for N4SID identification".to_string(),
        ));
    }

    // This is a simplified placeholder implementation
    // A full N4SID would involve:
    // 1. Construction of Hankel matrices
    // 2. QR decomposition and projection
    // 3. SVD for _order determination and state extraction
    // 4. Least squares for system matrices

    // For now, return identity matrices as placeholder
    let a = Array2::<f64>::eye(state_order);
    let b = Array2::<f64>::zeros((state_order, 1));
    let c = Array2::<f64>::zeros((1, state_order));
    let d = Array2::<f64>::zeros((1, 1));

    Ok((a, b, c, d))
}

/// Recursive least squares implementation
#[derive(Debug, Clone)]
pub struct RecursiveLeastSquares {
    /// Current parameter estimates
    pub parameters: Array1<f64>,
    /// Covariance matrix
    pub covariance: Array2<f64>,
    /// Forgetting factor
    pub forgetting_factor: f64,
    /// Parameter dimension
    pub dimension: usize,
}

impl RecursiveLeastSquares {
    /// Create new RLS estimator
    ///
    /// # Arguments
    /// * `dimension` - Number of parameters to estimate
    /// * `forgetting_factor` - Forgetting factor (0 < λ ≤ 1)
    /// * `initial_covariance` - Initial covariance scaling
    ///
    /// # Returns
    /// * New RLS estimator
    pub fn new(_dimension: usize, forgetting_factor: f64, initialcovariance: f64) -> Self {
        let parameters = Array1::<f64>::zeros(_dimension);
        let _covariance = Array2::<f64>::eye(_dimension) * initial_covariance;

        Self {
            parameters,
            covariance,
            forgetting_factor,
            dimension,
        }
    }

    /// Update estimates with new data point
    ///
    /// # Arguments
    /// * `regression_vector` - Input regression vector
    /// * `output` - Corresponding output value
    ///
    /// # Returns
    /// * Prediction error
    pub fn update(&mut self, regressionvector: &Array1<f64>, output: f64) -> SignalResult<f64> {
        if regression_vector.len() != self.dimension {
            return Err(SignalError::ValueError(
                "Regression _vector dimension mismatch".to_string(),
            ));
        }

        // Prediction error
        let prediction = self.parameters.dot(regression_vector);
        let error = output - prediction;

        // Gain _vector: K = P * phi / (lambda + phi^T * P * phi)
        let p_phi = self.covariance.dot(regression_vector);
        let denominator = self.forgetting_factor + regression_vector.dot(&p_phi);

        if denominator.abs() < 1e-12 {
            return Err(SignalError::ComputationError(
                "RLS update encountered numerical issues".to_string(),
            ));
        }

        let gain = &p_phi / denominator;

        // Parameter update: θ = θ + K * error
        let parameter_update = &gain * error;
        self.parameters += &parameter_update;

        // Covariance update: P = (P - K * phi^T * P) / lambda
        let k_phi_t_p = gain.insert_axis(Axis(1)).dot(
            &regression_vector
                .clone()
                .insert_axis(Axis(0))
                .dot(&self.covariance),
        );
        self.covariance = (&self.covariance - &k_phi_t_p) / self.forgetting_factor;

        Ok(error)
    }

    /// Get current parameter estimates
    pub fn get_parameters(&self) -> &Array1<f64> {
        &self.parameters
    }

    /// Get parameter covariance matrix
    pub fn get_covariance(&self) -> &Array2<f64> {
        &self.covariance
    }
}

/// Helper function to calculate model fit percentage
#[allow(dead_code)]
fn calculate_fit_percentage(actual: &Array1<f64>, predicted: &Array1<f64>) -> f64 {
    let mean_actual = actual.mean().unwrap_or(0.0);
    let ss_tot = actual.mapv(|y| (y - mean_actual).powi(2)).sum();

    if ss_tot < 1e-12 {
        return 0.0;
    }

    let ss_res = (_actual - predicted).mapv(|x| x * x).sum();
    let fit = 1.0 - ss_res / ss_tot;

    (100.0 * fit).clamp(0.0, 100.0)
}

/// Simple Ljung-Box test for residual whiteness
#[allow(dead_code)]
fn ljung_box_test(_residuals: &Array1<f64>, maxlag: usize) -> f64 {
    let n = residuals.len();
    if n <= max_lag {
        return 1.0; // Cannot perform test
    }

    // Calculate autocorrelations
    let mean_residual = residuals.mean().unwrap_or(0.0);
    let var_residual = _residuals
        .mapv(|x| (x - mean_residual).powi(2))
        .mean()
        .unwrap_or(1.0);

    let mut lb_stat = 0.0;

    for _lag in 1..=max_lag {
        let mut autocorr = 0.0;
        for t in lag..n {
            autocorr += (_residuals[t] - mean_residual) * (_residuals[t - _lag] - mean_residual);
        }
        autocorr /= (n - lag) as f64 * var_residual;

        lb_stat += autocorr * autocorr / (n - lag) as f64;
    }

    lb_stat *= n as f64 * (n + 2) as f64;

    // Return p-value approximation (simplified)
    // In practice, would use chi-square distribution
    (-lb_stat / 2.0).exp()
}

/// Solve linear system using LU decomposition
#[allow(dead_code)]
fn solve_linear_system(a: &Array2<f64>, b: &Array1<f64>) -> SignalResult<Array1<f64>> {
    match scirs2_linalg::solve(&a.view(), &b.view(), None) {
        Ok(solution) => Ok(solution),
        Err(_) => Err(SignalError::ComputationError(
            "Failed to solve linear system - matrix may be singular".to_string(),
        )),
    }
}

/// Solve complex least squares problem by separating real and imaginary parts
#[allow(dead_code)]
fn solve_complex_least_squares(
    a: &Array2<Complex64>,
    b: &Array1<Complex64>,
) -> SignalResult<Array1<Complex64>> {
    let m = a.nrows();
    let n = a.ncols();

    // Convert to real system: [Re(A); Im(A)] * [Re(x); Im(x)] = [Re(b); Im(b)]
    let mut a_real = Array2::<f64>::zeros((2 * m, 2 * n));
    let mut b_real = Array1::<f64>::zeros(2 * m);

    // Fill real parts
    for i in 0..m {
        for j in 0..n {
            a_real[[i, j]] = a[[i, j]].re;
            a_real[[i, j + n]] = -a[[i, j]].im;
            a_real[[i + m, j]] = a[[i, j]].im;
            a_real[[i + m, j + n]] = a[[i, j]].re;
        }
        b_real[i] = b[i].re;
        b_real[i + m] = b[i].im;
    }

    // Solve real system
    let at_a = a_real.t().dot(&a_real);
    let at_b = a_real.t().dot(&b_real);
    let x_real = solve_linear_system(&at_a, &at_b)?;

    // Convert back to complex
    let mut result = Array1::<Complex64>::zeros(n);
    for i in 0..n {
        result[i] = Complex64::new(x_real[i], x_real[i + n]);
    }

    Ok(result)
}

/// Compute FFT (simplified implementation)
#[allow(dead_code)]
fn compute_fft(signal: &Array1<f64>) -> Array1<Complex64> {
    let n = signal.len();

    // This is a placeholder - in practice would use a proper FFT implementation
    // For now, use DFT
    let mut result = Array1::<Complex64>::zeros(n);

    for k in 0..n {
        let mut sum = Complex64::new(0.0, 0.0);
        for t in 0..n {
            let angle = -2.0 * PI * (k * t) as f64 / n as f64;
            sum += signal[t] * Complex64::new(angle.cos(), angle.sin());
        }
        result[k] = sum;
    }

    result
}

/// Find next power of 2
#[allow(dead_code)]
fn next_power_of_2(n: usize) -> usize {
    if n == 0 {
        return 1;
    }
    let mut power = 1;
    while power < n {
        power <<= 1;
    }
    power
}

// ============================================================================
// ROBUST SYSTEM IDENTIFICATION ALGORITHMS
// ============================================================================

/// Configuration for robust estimation methods
#[derive(Debug, Clone)]
pub struct RobustEstimationConfig {
    /// Outlier detection threshold (in standard deviations)
    pub outlier_threshold: f64,
    /// Huber loss threshold parameter
    pub huber_threshold: f64,
    /// Fraction of data to trim in LTS (0.0 to 0.5)
    pub lts_fraction: f64,
    /// Enable fault detection and isolation
    pub enable_fault_detection: bool,
    /// Maximum fraction of outliers to handle (0.0 to 0.5)
    pub max_outlier_fraction: f64,
    /// Breakdown point for robust estimators (0.0 to 0.5)
    pub breakdown_point: f64,
    /// Use iterative reweighting for M-estimators
    pub use_iterative_reweighting: bool,
}

impl Default for RobustEstimationConfig {
    fn default() -> Self {
        Self {
            outlier_threshold: 3.0,
            huber_threshold: 1.345,
            lts_fraction: 0.75,
            enable_fault_detection: true,
            max_outlier_fraction: 0.3,
            breakdown_point: 0.25,
            use_iterative_reweighting: true,
        }
    }
}

/// Robust system identification result
#[derive(Debug, Clone)]
pub struct RobustSysIdResult {
    /// Estimated model parameters
    pub parameters: Array1<f64>,
    /// Model fit percentage
    pub fit_percentage: f64,
    /// Robust residuals
    pub robust_residuals: Array1<f64>,
    /// Outlier indices detected
    pub outlier_indices: Vec<usize>,
    /// Robust scale estimate
    pub robust_scale: f64,
    /// Breakdown point achieved
    pub breakdown_point: f64,
    /// Number of iterations used
    pub iterations: usize,
    /// Convergence status
    pub converged: bool,
}

/// Robust least squares estimation using M-estimators
///
/// This function performs robust parameter estimation using M-estimators with
/// Huber loss function to handle outliers in the data.
///
/// # Arguments
///
/// * `input` - Input signal data
/// * `output` - Output signal data
/// * `order` - Model order (number of parameters to estimate)
/// * `config` - Robust estimation configuration
///
/// # Returns
///
/// * Robust system identification result
#[allow(dead_code)]
pub fn robust_least_squares(
    input: &Array1<f64>,
    output: &Array1<f64>,
    order: usize,
    config: &RobustEstimationConfig,
) -> SignalResult<RobustSysIdResult> {
    if input.len() != output.len() {
        return Err(SignalError::DimensionMismatch(format!(
            "Input and output length mismatch: expected {}, got {}",
            input.len(),
            output.len()
        )));
    }

    if input.len() < order {
        return Err(SignalError::InvalidArgument(format!(
            "Order {} cannot exceed data length {}",
            order,
            input.len()
        )));
    }

    let n = input.len() - order;

    // Build regression matrix
    let mut regressor = Array2::zeros((n, order));
    for i in 0..n {
        for j in 0..order {
            regressor[[i, j]] = input[i + order - 1 - j];
        }
    }

    let target = output.slice(s![order..]).to_owned();

    // Initialize with standard least squares
    let mut parameters = solve_least_squares(&regressor, &target)?;
    let mut weights = Array1::ones(n);
    let mut robust_scale = estimate_robust_scale(&target, &regressor, &parameters)?;

    let mut converged = false;
    let mut iteration = 0;

    // Iteratively reweighted least squares
    while iteration < 50 && !converged {
        let residuals = &target - &regressor.dot(&parameters);

        // Update weights using Huber function
        update_huber_weights(
            &residuals,
            robust_scale,
            config.huber_threshold,
            &mut weights,
        );

        // Weighted least squares
        let new_parameters = solve_weighted_least_squares(&regressor, &target, &weights)?;

        // Check convergence
        let diff = &new_parameters - &parameters;
        let diff_norm = (diff.mapv(|x| x * x).sum()).sqrt();
        let params_norm = (parameters.mapv(|x| x * x).sum()).sqrt();
        let parameter_change = diff_norm / params_norm;
        converged = parameter_change < 1e-6;

        parameters = new_parameters;
        robust_scale = estimate_robust_scale(&target, &regressor, &parameters)?;
        iteration += 1;
    }

    // Calculate final residuals and detect outliers
    let residuals = &target - &regressor.dot(&parameters);
    let outlier_indices = detect_outliers(&residuals, robust_scale, config.outlier_threshold);
    let fit_percentage = calculate_robust_fit(&target, &regressor, &parameters);

    Ok(RobustSysIdResult {
        parameters,
        fit_percentage,
        robust_residuals: residuals,
        outlier_indices,
        robust_scale,
        breakdown_point: config.breakdown_point,
        iterations: iteration,
        converged,
    })
}

/// Fault-tolerant system identification with automatic outlier rejection
///
/// This function performs system identification while automatically detecting
/// and rejecting outliers, faults, and measurement errors.
#[allow(dead_code)]
pub fn fault_tolerant_identification(
    input: &Array1<f64>,
    output: &Array1<f64>,
    order: usize,
    config: &RobustEstimationConfig,
) -> SignalResult<RobustSysIdResult> {
    if !config.enable_fault_detection {
        return robust_least_squares(input, output, order, config);
    }

    let n = input.len() - order;
    let mut regressor = Array2::zeros((n, order));
    for i in 0..n {
        for j in 0..order {
            regressor[[i, j]] = input[i + order - 1 - j];
        }
    }

    let target = output.slice(s![order..]).to_owned();

    // Phase 1: Initial robust estimation
    let initial_result = robust_least_squares(input, output, order, config)?;

    // Phase 2: Fault detection using residual analysis
    let mut outlier_mask = vec![false; n];
    for &idx in &initial_result.outlier_indices {
        if idx < n {
            outlier_mask[idx] = true;
        }
    }

    // Phase 3: Re-estimation without outliers
    let clean_indices: Vec<usize> = (0..n).filter(|&i| !outlier_mask[i]).collect();

    if clean_indices.len() < order {
        return Ok(initial_result); // Not enough clean data, return initial result
    }

    // Build clean regression matrix
    let mut clean_regressor = Array2::zeros((clean_indices.len(), order));
    let mut clean_target = Array1::zeros(clean_indices.len());

    for (i, &clean_idx) in clean_indices.iter().enumerate() {
        clean_target[i] = target[clean_idx];
        for j in 0..order {
            clean_regressor[[i, j]] = regressor[[clean_idx, j]];
        }
    }

    // Final robust estimation on clean data
    let final_parameters = solve_least_squares(&clean_regressor, &clean_target)?;
    let final_residuals = &target - &regressor.dot(&final_parameters);
    let final_scale = estimate_robust_scale(&target, &regressor, &final_parameters)?;
    let final_fit = calculate_robust_fit(&target, &regressor, &final_parameters);

    Ok(RobustSysIdResult {
        parameters: final_parameters,
        fit_percentage: final_fit,
        robust_residuals: final_residuals,
        outlier_indices: initial_result.outlier_indices,
        robust_scale: final_scale,
        breakdown_point: config.breakdown_point,
        iterations: initial_result.iterations + 1,
        converged: true,
    })
}

/// Adaptive robust system identification that automatically selects the best method
#[allow(dead_code)]
pub fn adaptive_robust_identification(
    input: &Array1<f64>,
    output: &Array1<f64>,
    order: usize,
) -> SignalResult<RobustSysIdResult> {
    // Try different robust methods and select the best one
    let mut best_result: Option<RobustSysIdResult> = None;
    let mut best_fit = 0.0;

    let methods = vec![
        RobustEstimationConfig {
            huber_threshold: 1.345,
            ..Default::default()
        },
        RobustEstimationConfig {
            huber_threshold: 2.0,
            lts_fraction: 0.75,
            ..Default::default()
        },
        RobustEstimationConfig {
            huber_threshold: 1.0,
            lts_fraction: 0.8,
            enable_fault_detection: true,
            ..Default::default()
        },
    ];

    for config in methods {
        if let Ok(result) = fault_tolerant_identification(input, output, order, &config) {
            if result.fit_percentage > best_fit {
                best_fit = result.fit_percentage;
                best_result = Some(result);
            }
        }
    }

    best_result
        .ok_or_else(|| SignalError::ComputationError("All robust methods failed".to_string()))
}

// Helper functions for robust estimation

#[allow(dead_code)]
fn solve_least_squares(
    _regressor: &Array2<f64>,
    target: &Array1<f64>,
) -> SignalResult<Array1<f64>> {
    // Simple normal equations solution (A^T A)^-1 A^T b
    let at = regressor.t();
    let ata = at.dot(_regressor);
    let atb = at.dot(target);

    // Solve using pseudo-inverse (simplified)
    let mut result = Array1::zeros(_regressor.ncols());
    for i in 0.._regressor.ncols() {
        if i < atb.len() {
            result[i] = atb[i] / (ata[[i, i]] + 1e-12);
        }
    }

    Ok(result)
}

#[allow(dead_code)]
fn solve_weighted_least_squares(
    regressor: &Array2<f64>,
    target: &Array1<f64>,
    weights: &Array1<f64>,
) -> SignalResult<Array1<f64>> {
    // Weighted least squares: (A^T W A)^-1 A^T W b
    let n = regressor.nrows();
    let p = regressor.ncols();

    let mut weighted_regressor = Array2::zeros((n, p));
    let mut weighted_target = Array1::zeros(n);

    for i in 0..n {
        let w = weights[i].sqrt();
        weighted_target[i] = target[i] * w;
        for j in 0..p {
            weighted_regressor[[i, j]] = regressor[[i, j]] * w;
        }
    }

    solve_least_squares(&weighted_regressor, &weighted_target)
}

#[allow(dead_code)]
fn update_huber_weights(
    residuals: &Array1<f64>,
    scale: f64,
    threshold: f64,
    weights: &mut Array1<f64>,
) {
    for i in 0..residuals.len() {
        let standardized_residual = residuals[i].abs() / scale;
        weights[i] = if standardized_residual <= threshold {
            1.0
        } else {
            threshold / standardized_residual
        };
    }
}

#[allow(dead_code)]
pub fn estimate_robust_scale(
    target: &Array1<f64>,
    regressor: &Array2<f64>,
    parameters: &Array1<f64>,
) -> SignalResult<f64> {
    let residuals = target - &regressor.dot(parameters);
    let mut abs_residuals: Vec<f64> = residuals.iter().map(|&r: &f64| r.abs()).collect();
    abs_residuals.sort_by(|a, b| a.partial_cmp(b).unwrap());

    // Median absolute deviation (MAD)
    let median_idx = abs_residuals.len() / 2;
    let mad = if abs_residuals.len() % 2 == 0 {
        (abs_residuals[median_idx - 1] + abs_residuals[median_idx]) / 2.0
    } else {
        abs_residuals[median_idx]
    };

    Ok(mad * 1.4826) // Scale factor for normal distribution
}

#[allow(dead_code)]
pub fn detect_outliers(residuals: &Array1<f64>, scale: f64, threshold: f64) -> Vec<usize> {
    _residuals
        .iter()
        .enumerate()
        .filter_map(|(i, &r)| {
            if r.abs() / scale > threshold {
                Some(i)
            } else {
                None
            }
        })
        .collect()
}

#[allow(dead_code)]
fn calculate_robust_fit(
    target: &Array1<f64>,
    regressor: &Array2<f64>,
    parameters: &Array1<f64>,
) -> f64 {
    let predicted = regressor.dot(parameters);
    let residuals = target - &predicted;

    // Use robust R-squared based on median
    let target_median = calculate_median(target);
    let total_deviation: f64 = target.iter().map(|&y| (y - target_median).abs()).sum();
    let residual_deviation: f64 = residuals.iter().map(|&r: &f64| r.abs()).sum();

    if total_deviation > 1e-12 {
        100.0 * (1.0 - residual_deviation / total_deviation).max(0.0)
    } else {
        100.0
    }
}

#[allow(dead_code)]
fn calculate_median(data: &Array1<f64>) -> f64 {
    let mut sorted: Vec<f64> = data.to_vec();
    sorted.sort_by(|a, b| a.partial_cmp(b).unwrap());

    let n = sorted.len();
    if n % 2 == 0 {
        (sorted[n / 2 - 1] + sorted[n / 2]) / 2.0
    } else {
        sorted[n / 2]
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::lti::design::tf;
    use approx::assert_relative_eq;
    #[test]
    fn test_transfer_function_estimation_simple() {
        let a = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let b = vec![0.5, 0.5];
        // Test with a longer signal for better conditioning
        let n = 50;
        let mut input = Array1::zeros(n);
        let mut output = Array1::zeros(n);

        // Generate random input
        for i in 0..n {
            input[i] = (i as f64 * 0.1).sin();
        }

        // Simulate y[n] = 0.8*y[n-1] + 0.2*u[n-1]
        for i in 1..n {
            output[i] = 0.8 * output[i - 1] + 0.2 * input[i - 1];
        }

        let result = estimate_transfer_function(
            &input,
            &output,
            1.0,
            1,
            1,
            TfEstimationMethod::LeastSquares,
        )
        .unwrap();

        // Should estimate something reasonable
        assert!(result.fit_percentage > 30.0); // Lower threshold for noisy estimation
        assert_eq!(result.numerator.len(), 2);
        assert_eq!(result.denominator.len(), 2);
    }

    #[test]
    fn test_ar_model_identification() {
        // Generate AR(2) process: y[n] = 0.5*y[n-1] + 0.3*y[n-2] + e[n]
        let n = 100;
        let mut signal = Array1::<f64>::zeros(n);

        for i in 2..n {
            signal[i] = 0.5 * signal[i - 1] + 0.3 * signal[i - 2] + 0.1 * (i as f64).sin();
        }

        let result = identify_ar_model(&signal, 5, ARMethod::Burg, OrderSelection::AIC).unwrap();

        // Should identify a reasonable model
        assert!(result.model_order.0 <= 5);
        assert!(result.noise_variance > 0.0);
        assert_eq!(result.ar_coefficients.len(), result.model_order.0 + 1);
    }

    #[test]
    fn test_recursive_least_squares() {
        let mut rls = RecursiveLeastSquares::new(2, 0.95, 1000.0);

        // Test with known system: y = 2*x1 + 3*x2
        // Use multiple different data points for better convergence
        let test_data = vec![
            (Array1::from_vec(vec![1.0, 2.0]), 2.0 * 1.0 + 3.0 * 2.0),
            (Array1::from_vec(vec![2.0, 1.0]), 2.0 * 2.0 + 3.0 * 1.0),
            (Array1::from_vec(vec![0.5, 1.5]), 2.0 * 0.5 + 3.0 * 1.5),
            (Array1::from_vec(vec![1.5, 0.5]), 2.0 * 1.5 + 3.0 * 0.5),
        ];

        // Train with multiple epochs
        for _ in 0..100 {
            for (regression, output) in &test_data {
                let _ = rls.update(regression, *output).unwrap();
            }
        }

        let params = rls.get_parameters();
        // More relaxed tolerances for RLS convergence
        assert_relative_eq!(params[0], 2.0, epsilon = 0.5);
        assert_relative_eq!(params[1], 3.0, epsilon = 0.5);
    }

    #[test]
    fn test_model_validation() {
        let actual = Array1::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0]);
        let predicted = Array1::from_vec(vec![1.1, 1.9, 3.1, 3.9, 5.1]);

        let validation = validate_model(&predicted, &actual, 2, false).unwrap();

        assert!(validation.fit_percentage > 90.0); // Should be high for close match
        assert!(validation.r_squared > 0.9);
        assert!(validation.mse < 0.1);
    }

    #[test]
    fn test_frequency_response_estimation() {
        // Simple test with impulse response
        let input = Array1::from_vec(vec![1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]);
        let output = Array1::from_vec(vec![
            0.0, 0.5, 0.25, 0.125, 0.0625, 0.03125, 0.015625, 0.0078125,
        ]);

        let config = SysIdConfig::default();
        let result = estimate_frequency_response(
            &input,
            &output,
            1.0,
            FreqResponseMethod::Periodogram,
            &config,
        )
        .unwrap();

        assert!(!result.frequencies.is_empty());
        assert_eq!(result.frequency_response.len(), result.frequencies.len());
        assert_eq!(result.coherence.len(), result.frequencies.len());
    }

    #[test]
    fn test_fit_percentage_calculation() {
        let actual = Array1::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0]);
        let predicted = Array1::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0]);

        let fit = calculate_fit_percentage(&actual, &predicted);
        assert_relative_eq!(fit, 100.0, epsilon = 1e-10);

        let predicted_bad = Array1::from_vec(vec![2.0, 3.0, 4.0, 5.0, 6.0]);
        let fit_bad = calculate_fit_percentage(&actual, &predicted_bad);
        assert!(fit_bad < 100.0);
        assert!(fit_bad > 0.0);
    }
}
