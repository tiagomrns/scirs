//! Interactive Statistical Functions Tutorial
//!
//! This tutorial provides a comprehensive educational experience for statistical
//! functions with mathematical proofs, derivations, and numerical experiments.
//!
//! Run with: cargo run --example statistical_functions_interactive_tutorial

use ndarray::Array1;
use scirs2_special::*;
use std::io::{self, Write};

#[allow(dead_code)]
fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“Š Interactive Statistical Functions Learning Laboratory");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    show_welcome();

    loop {
        show_main_menu();
        let choice = get_user_input("Enter your choice (1-8, or 'q' to quit): ")?;

        if choice.to_lowercase() == "q" {
            println!("ğŸ“ Thank you for exploring statistical functions!");
            break;
        }

        match choice.parse::<u32>() {
            Ok(1) => mathematical_foundations_module()?,
            Ok(2) => logistic_function_deep_dive()?,
            Ok(3) => softmax_comprehensive_study()?,
            Ok(4) => numerical_stability_experiments()?,
            Ok(5) => machine_learning_applications()?,
            Ok(6) => interactive_proofs_section()?,
            Ok(7) => computational_experiments()?,
            Ok(8) => quiz_and_challenges()?,
            _ => println!("âŒ Invalid choice. Please try again.\n"),
        }

        pause();
    }

    Ok(())
}

#[allow(dead_code)]
fn show_welcome() {
    println!("Welcome to the comprehensive study of statistical functions!");
    println!("This tutorial combines rigorous mathematical theory with");
    println!("practical applications in machine learning and statistics.");
    println!();
    println!("ğŸ“– What You'll Learn:");
    println!("â€¢ Mathematical foundations and proofs");
    println!("â€¢ Numerical stability techniques");
    println!("â€¢ Machine learning applications");
    println!("â€¢ Interactive mathematical experiments");
    println!();
}

#[allow(dead_code)]
fn show_main_menu() {
    println!("ğŸ  MAIN MENU - Choose Your Learning Path:");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("1. ğŸ“ Mathematical Foundations & Theory");
    println!("2. ğŸ“ˆ Logistic Function Deep Dive");
    println!("3. ğŸ¯ Softmax Function Comprehensive Study");
    println!("4. âš–ï¸  Numerical Stability Experiments");
    println!("5. ğŸ¤– Machine Learning Applications");
    println!("6. ğŸ“‹ Interactive Mathematical Proofs");
    println!("7. ğŸ§ª Computational Experiments");
    println!("8. ğŸ† Quiz & Challenges");
    println!();
}

#[allow(dead_code)]
fn mathematical_foundations_module() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ MATHEMATICAL FOUNDATIONS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ” THE LOGISTIC FUNCTION");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Definition: Ïƒ(x) = 1 / (1 + e^(-x))");
    println!();

    println!("ğŸ“Š Key Properties with Proofs:");
    println!();

    println!("1. RANGE: Ïƒ(x) âˆˆ (0, 1) for all x âˆˆ â„");
    println!("   Proof: Since e^(-x) > 0, we have 1 + e^(-x) > 1");
    println!("   Therefore: 0 < 1/(1 + e^(-x)) < 1");
    println!();

    println!("2. SYMMETRY: Ïƒ(-x) = 1 - Ïƒ(x)");
    println!("   Proof: Ïƒ(-x) = 1/(1 + e^x) = e^(-x)/(e^(-x) + 1) = 1 - Ïƒ(x)");
    println!();

    println!("Let's verify these properties numerically:");

    // Demonstrate range property
    println!("Testing range property:");
    for x in [-10.0, -1.0, 0.0, 1.0, 10.0] {
        let sigma_x = logistic(x);
        println!("  Ïƒ({:4.1}) = {:8.6} âˆˆ (0,1) âœ“", x, sigma_x);
    }
    println!();

    // Demonstrate symmetry property
    println!("Testing symmetry property Ïƒ(-x) = 1 - Ïƒ(x):");
    for x in [0.5, 1.0, 2.0, 5.0] {
        let sigma_x = logistic(x);
        let sigma_neg_x = logistic(-x);
        let expected = 1.0 - sigma_x;
        let error = (sigma_neg_x - expected).abs();
        println!(
            "  x={:3.1}: Ïƒ(-x)={:8.6}, 1-Ïƒ(x)={:8.6}, error={:2.0e}",
            x, sigma_neg_x, expected, error
        );
    }

    Ok(())
}

#[allow(dead_code)]
fn logistic_function_deep_dive() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ˆ LOGISTIC FUNCTION DEEP DIVE");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ§® DERIVATIVE ANALYSIS");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("The derivative of Ïƒ(x) is: Ïƒ'(x) = Ïƒ(x)(1 - Ïƒ(x))");
    println!();

    println!("This has important implications:");
    println!("â€¢ Maximum derivative at x = 0: Ïƒ'(0) = 0.25");
    println!("â€¢ Derivative approaches 0 as |x| â†’ âˆ");
    println!("â€¢ Function is strictly increasing everywhere");
    println!();

    println!("Let's explore the derivative behavior:");
    let x_values = Array1::linspace(-5.0, 5.0, 11);

    println!("    x    â”‚   Ïƒ(x)   â”‚  Ïƒ'(x)   â”‚ Max at x=0");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    for &x in x_values.iter() {
        let sigma_x = logistic(x);
        let derivative = logistic_derivative(x);
        let marker = if (x - 0.0).abs() < 0.01 {
            " â† MAX"
        } else {
            ""
        };
        println!(
            "{:8.1} â”‚ {:8.6} â”‚ {:8.6} â”‚{}",
            x, sigma_x, derivative, marker
        );
    }

    println!();
    println!("ğŸ¯ INFLECTION POINT ANALYSIS");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("The second derivative Ïƒ''(x) = Ïƒ'(x)(1 - 2Ïƒ(x)) = 0 when Ïƒ(x) = 1/2");
    println!("This occurs at x = 0, which is the inflection point.");

    let inflection_x = 0.0;
    let sigma_at_inflection = logistic(inflection_x);
    println!(
        "At x = {}: Ïƒ(x) = {:6.4} = 1/2 âœ“",
        inflection_x, sigma_at_inflection
    );

    Ok(())
}

#[allow(dead_code)]
fn softmax_comprehensive_study() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¯ SOFTMAX FUNCTION COMPREHENSIVE STUDY");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ“– DEFINITION AND PROPERTIES");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("For vector x = (xâ‚, xâ‚‚, ..., xâ‚™):");
    println!("softmax(xáµ¢) = exp(xáµ¢) / Î£â±¼ exp(xâ±¼)");
    println!();

    println!("Key Properties:");
    println!("1. Probability Distribution: Î£áµ¢ softmax(xáµ¢) = 1");
    println!("2. Translation Invariance: softmax(x + c) = softmax(x)");
    println!("3. Maximum Preservation: preserves ordering");
    println!();

    println!("ğŸ§ª EXPERIMENTAL VERIFICATION");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    // Test probability distribution property
    let test_vector = Array1::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0]);
    let softmax_result = softmax(test_vector.view())?;
    let sum = softmax_result.sum();

    println!("Test Vector: {:?}", test_vector.to_vec());
    println!(
        "Softmax:     {:?}",
        softmax_result
            .iter()
            .map(|&x| format!("{:.4}", x))
            .collect::<Vec<_>>()
    );
    println!("Sum:         {:.10} (should be 1.0) âœ“", sum);
    println!();

    // Test translation invariance
    println!("ğŸ”„ TRANSLATION INVARIANCE TEST");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    let constant = 100.0; // Large constant to test numerical stability
    let translated_vector = test_vector.mapv(|x| x + constant);
    let softmax_translated = softmax(translated_vector.view())?;

    println!(
        "Original softmax:    {:?}",
        softmax_result
            .iter()
            .map(|&x| format!("{:.6}", x))
            .collect::<Vec<_>>()
    );
    println!(
        "Translated softmax:  {:?}",
        softmax_translated
            .iter()
            .map(|&x| format!("{:.6}", x))
            .collect::<Vec<_>>()
    );

    let max_difference = softmax_result
        .iter()
        .zip(softmax_translated.iter())
        .map(|(a, b)| (a - b).abs())
        .fold(0.0, f64::max);

    println!(
        "Maximum difference: {:.2e} (should be ~0) âœ“",
        max_difference
    );

    Ok(())
}

#[allow(dead_code)]
fn numerical_stability_experiments() -> Result<(), Box<dyn std::error::Error>> {
    println!("âš–ï¸ NUMERICAL STABILITY EXPERIMENTS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ”¬ LOGISTIC FUNCTION STABILITY");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Testing numerically stable implementation vs naive approach");
    println!();

    let extreme_values = vec![-50.0, -20.0, -10.0, 0.0, 10.0, 20.0, 50.0];

    println!("    x    â”‚ Stable Impl â”‚ Naive Impl  â”‚  Difference");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    for &x in &extreme_values {
        let stable_result = logistic(x);
        let naive_result = if x > 20.0 {
            1.0
        } else {
            1.0 / (1.0 + (-x).exp())
        };
        let difference = (stable_result - naive_result).abs();

        println!(
            "{:8.1} â”‚ {:11.8} â”‚ {:11.8} â”‚ {:11.2e}",
            x, stable_result, naive_result, difference
        );
    }

    println!();
    println!("ğŸŒŠ SOFTMAX OVERFLOW PREVENTION");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    // Test with values that would cause overflow in naive implementation
    let large_values = Array1::from_vec(vec![700.0, 800.0, 900.0]);
    println!("Testing with large values: {:?}", large_values.to_vec());

    match softmax(large_values.view()) {
        Ok(result) => {
            println!(
                "Stable softmax result: {:?}",
                result
                    .iter()
                    .map(|&x| format!("{:.6}", x))
                    .collect::<Vec<_>>()
            );
            println!("Sum: {:.10} âœ“", result.sum());
        }
        Err(e) => println!("Error: {}", e),
    }

    Ok(())
}

#[allow(dead_code)]
fn machine_learning_applications() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¤– MACHINE LEARNING APPLICATIONS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ¯ BINARY CLASSIFICATION EXAMPLE");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Logistic regression uses the logistic function as the link function:");
    println!("P(y=1|x) = Ïƒ(wÂ·x + b)");
    println!();

    // Simulate a simple dataset
    let features = vec![1.0, 2.0, 3.0, 4.0, 5.0];
    let weight = 0.5;
    let bias = -2.5;

    println!("Dataset simulation (weight={}, bias={}):", weight, bias);
    println!("Feature â”‚ Linear Comb â”‚ Probability â”‚ Prediction");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    for &x in &features {
        let linear_combination = weight * x + bias;
        let probability = logistic(linear_combination);
        let prediction = if probability > 0.5 {
            "Positive"
        } else {
            "Negative"
        };

        println!(
            "{:7.1} â”‚ {:11.2} â”‚ {:11.6} â”‚ {:>9}",
            x, linear_combination, probability, prediction
        );
    }

    println!();
    println!("ğŸ² MULTI-CLASS CLASSIFICATION EXAMPLE");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Softmax is used for multi-class classification output layer");
    println!();

    // Simulate network outputs (logits)
    let logits = Array1::from_vec(vec![2.0, 1.0, 0.1]);
    let class_names = vec!["Cat", "Dog", "Bird"];

    let probabilities = softmax(logits.view())?;

    println!("Network outputs (logits): {:?}", logits.to_vec());
    println!("Class probabilities:");
    for (_i, (&prob, &name)) in probabilities.iter().zip(class_names.iter()).enumerate() {
        println!("  {}: {:.4} ({:.1}%)", name, prob, prob * 100.0);
    }

    let predicted_class = probabilities
        .iter()
        .enumerate()
        .max_by(|(_, a), (_, b)| a.partial_cmp(b).unwrap())
        .unwrap()
        .0;

    println!("Predicted class: {} âœ“", class_names[predicted_class]);

    Ok(())
}

#[allow(dead_code)]
fn interactive_proofs_section() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“‹ INTERACTIVE MATHEMATICAL PROOFS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ” PROOF WALKTHROUGH: Logistic Derivative");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("Let's prove that d/dx[Ïƒ(x)] = Ïƒ(x)(1 - Ïƒ(x)) step by step:");
    println!();

    println!("Step 1: Start with Ïƒ(x) = 1/(1 + e^(-x))");
    println!("Step 2: Use the chain rule: d/dx[1/u] = -u'/uÂ²");
    println!("        where u = 1 + e^(-x), so u' = -e^(-x)");
    println!();
    println!("Step 3: Ïƒ'(x) = -(-e^(-x))/(1 + e^(-x))Â² = e^(-x)/(1 + e^(-x))Â²");
    println!();
    println!("Step 4: Factorize: Ïƒ'(x) = [1/(1 + e^(-x))] Ã— [e^(-x)/(1 + e^(-x))]");
    println!("                          = Ïƒ(x) Ã— [e^(-x)/(1 + e^(-x))]");
    println!();
    println!("Step 5: Note that e^(-x)/(1 + e^(-x)) = 1 - 1/(1 + e^(-x)) = 1 - Ïƒ(x)");
    println!();
    println!("Therefore: Ïƒ'(x) = Ïƒ(x)(1 - Ïƒ(x)) Q.E.D. âœ“");
    println!();

    println!("ğŸ§ª NUMERICAL VERIFICATION");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    let test_points = vec![0.0, 1.0, -1.0, 2.0];

    for &x in &test_points {
        let sigma_x = logistic(x);
        let analytical_derivative = sigma_x * (1.0 - sigma_x);
        let computed_derivative = logistic_derivative(x);
        let error = (analytical_derivative - computed_derivative).abs();

        println!(
            "x={:4.1}: Analytical={:.8}, Computed={:.8}, Error={:.2e}",
            x, analytical_derivative, computed_derivative, error
        );
    }

    Ok(())
}

#[allow(dead_code)]
fn computational_experiments() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª COMPUTATIONAL EXPERIMENTS");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("â±ï¸ PERFORMANCE COMPARISON");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    use std::time::Instant;

    let large_array = Array1::linspace(-10.0, 10.0, 100_000);

    // Time logistic function
    let start = Instant::now();
    let _: Vec<f64> = large_array.iter().map(|&x| logistic(x)).collect();
    let logistic_time = start.elapsed();

    // Time softmax function on chunks
    let chunksize = 1000;
    let start = Instant::now();
    for chunk in large_array.exact_chunks(chunksize) {
        let _ = softmax(chunk)?;
    }
    let softmax_time = start.elapsed();

    println!("Logistic function (100k elements): {:?}", logistic_time);
    println!("Softmax function (100 chunks):     {:?}", softmax_time);

    println!();
    println!("ğŸ¯ ACCURACY ANALYSIS");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");

    // Test extreme precision
    let precision_test_x = 1e-15;
    let result = logistic(precision_test_x);
    let expected = 0.5 + precision_test_x / 4.0; // First-order Taylor approximation
    let relative_error = ((result - expected) / expected).abs();

    println!("Advanced-small input test:");
    println!("x = {:.2e}", precision_test_x);
    println!("Ïƒ(x) = {:.15}", result);
    println!("Expected â‰ˆ {:.15}", expected);
    println!("Relative error: {:.2e}", relative_error);

    Ok(())
}

#[allow(dead_code)]
fn quiz_and_challenges() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ† QUIZ & CHALLENGES");
    println!("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    println!();

    println!("ğŸ“ Challenge 1: Symmetry Property");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("If Ïƒ(2) = 0.8808, what is Ïƒ(-2)?");

    let user_answer = get_user_input("Your answer: ")?;
    let correct_answer = 1.0 - logistic(2.0);
    let user_value: f64 = user_answer.parse().unwrap_or(0.0);

    if (user_value - correct_answer).abs() < 0.001 {
        println!("âœ… Correct! Ïƒ(-2) = 1 - Ïƒ(2) = {:.4}", correct_answer);
    } else {
        println!("âŒ Not quite. The correct answer is {:.4}", correct_answer);
        println!("Remember: Ïƒ(-x) = 1 - Ïƒ(x)");
    }

    println!();
    println!("ğŸ“ Challenge 2: Derivative Maximum");
    println!("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€");
    println!("At what value of x is the logistic function's derivative maximized?");

    let user_answer = get_user_input("Your answer: ")?;

    if user_answer.trim() == "0" || user_answer.trim() == "0.0" {
        println!("âœ… Correct! The derivative Ïƒ'(x) = Ïƒ(x)(1-Ïƒ(x)) is maximized");
        println!("when Ïƒ(x) = 0.5, which occurs at x = 0.");
        println!("Maximum value: Ïƒ'(0) = 0.5 Ã— 0.5 = 0.25");
    } else {
        println!("âŒ Not quite. The derivative is maximized at x = 0.");
        println!("At this point, Ïƒ(0) = 0.5, giving maximum derivative of 0.25.");
    }

    println!();
    println!("ğŸ‰ Congratulations on completing the statistical functions tutorial!");

    Ok(())
}

// Helper functions
#[allow(dead_code)]
fn get_user_input(prompt: &str) -> Result<String, Box<dyn std::error::Error>> {
    print!("{}", prompt);
    io::stdout().flush()?;
    let mut input = String::new();
    io::stdin().read_line(&mut input)?;
    Ok(input.trim().to_string())
}

#[allow(dead_code)]
fn pause() {
    print!("\nPress Enter to continue...");
    io::stdout().flush().unwrap();
    let mut input = String::new();
    io::stdin().read_line(&mut input).unwrap();
}
