//! Extended precision matrix factorizations
//!
//! This module provides functions for computing matrix factorizations
//! using extended precision arithmetic for improved accuracy.

use ndarray::{Array1, Array2, ArrayView2};
use num_traits::{Float, One, Zero};

use crate::error::LinalgResult;
use super::{DemotableTo, PromotableTo};

/// LU decomposition with partial pivoting using extended precision
///
/// This function computes the LU decomposition of a matrix using higher precision
/// arithmetic for improved numerical stability.
///
/// # Parameters
///
/// * `a` - Input matrix
///
/// # Returns
///
/// * Tuple containing (P, L, U) where:
///   - P is the permutation matrix
///   - L is the lower triangular matrix with unit diagonal
///   - U is the upper triangular matrix
///
/// # Examples
///
/// ```
/// use ndarray::{array, ArrayView2};
/// use scirs2_linalg::extended_precision::factorizations::extended_lu;
///
/// let a = array![
///     [2.0_f32, 1.0, 1.0],
///     [4.0, 3.0, 3.0],
///     [8.0, 7.0, 9.0]
/// ];
///
/// // Compute LU decomposition with extended precision
/// let (p, l, u) = extended_lu::<_, f64>(&a.view()).unwrap();
///
/// // Check result: P*A ≈ L*U
/// let pa = p.dot(&a);
/// let lu = l.dot(&u);
/// for i in 0..a.nrows() {
///     for j in 0..a.ncols() {
///         assert!((pa[[i, j]] - lu[[i, j]]).abs() < 1e-5);
///     }
/// }
/// ```
pub fn extended_lu<A, I>(a: &ArrayView2<A>) -> LinalgResult<(Array2<A>, Array2<A>, Array2<A>)>
where
    A: Float + Zero + One + PromotableTo<I> + DemotableTo<A> + Copy,
    I: Float + Zero + One + DemotableTo<A> + Copy + PartialOrd,
{
    let m = a.nrows();
    let n = a.ncols();
    
    // Convert matrix to higher precision
    let mut a_high = Array2::zeros((m, n));
    for i in 0..m {
        for j in 0..n {
            a_high[[i, j]] = a[[i, j]].promote();
        }
    }
    
    // Initialize permutation vector for pivoting
    let mut p_indices = Vec::with_capacity(m);
    for i in 0..m {
        p_indices.push(i);
    }
    
    // Perform LU decomposition with partial pivoting in high precision
    for k in 0..std::cmp::min(m, n) {
        // Find pivot
        let mut pivot_row = k;
        let mut max_val = a_high[[k, k]].abs();
        
        for i in k+1..m {
            let val = a_high[[i, k]].abs();
            if val > max_val {
                max_val = val;
                pivot_row = i;
            }
        }
        
        // Check for singularity
        if max_val < I::epsilon() {
            return Err(crate::error::LinalgError::SingularMatrixError(
                "Matrix is singular or nearly singular".to_string(),
            ));
        }
        
        // Swap rows in a_high and p_indices if necessary
        if pivot_row != k {
            p_indices.swap(k, pivot_row);
            for j in 0..n {
                let temp = a_high[[k, j]];
                a_high[[k, j]] = a_high[[pivot_row, j]];
                a_high[[pivot_row, j]] = temp;
            }
        }
        
        // Compute the Gauss transform
        for i in k+1..m {
            a_high[[i, k]] = a_high[[i, k]] / a_high[[k, k]];
            
            for j in k+1..n {
                a_high[[i, j]] = a_high[[i, j]] - a_high[[i, k]] * a_high[[k, j]];
            }
        }
    }
    
    // Extract L and U from a_high (still in high precision)
    let mut l_high = Array2::zeros((m, std::cmp::min(m, n)));
    let mut u_high = Array2::zeros((std::cmp::min(m, n), n));
    
    for i in 0..m {
        for j in 0..std::cmp::min(m, n) {
            if i > j {
                l_high[[i, j]] = a_high[[i, j]];
            } else if i == j {
                l_high[[i, j]] = I::one();
            }
        }
    }
    
    for i in 0..std::cmp::min(m, n) {
        for j in 0..n {
            if i <= j {
                u_high[[i, j]] = a_high[[i, j]];
            }
        }
    }
    
    // Build permutation matrix
    let mut p_high = Array2::zeros((m, m));
    for i in 0..m {
        p_high[[i, p_indices[i]]] = I::one();
    }
    
    // Convert results back to original precision
    let mut p = Array2::zeros((m, m));
    let mut l = Array2::zeros((m, std::cmp::min(m, n)));
    let mut u = Array2::zeros((std::cmp::min(m, n), n));
    
    for i in 0..m {
        for j in 0..m {
            p[[i, j]] = p_high[[i, j]].demote();
        }
    }
    
    for i in 0..m {
        for j in 0..std::cmp::min(m, n) {
            l[[i, j]] = l_high[[i, j]].demote();
        }
    }
    
    for i in 0..std::cmp::min(m, n) {
        for j in 0..n {
            u[[i, j]] = u_high[[i, j]].demote();
        }
    }
    
    Ok((p, l, u))
}

/// QR decomposition using extended precision
///
/// This function computes the QR decomposition of a matrix using higher precision
/// arithmetic for improved numerical stability.
///
/// # Parameters
///
/// * `a` - Input matrix
///
/// # Returns
///
/// * Tuple containing (Q, R) where:
///   - Q is the orthogonal matrix
///   - R is the upper triangular matrix
///
/// # Examples
///
/// ```
/// use ndarray::{array, ArrayView2};
/// use scirs2_linalg::extended_precision::factorizations::extended_qr;
///
/// let a = array![
///     [12.0_f32, -51.0, 4.0],
///     [6.0, 167.0, -68.0],
///     [-4.0, 24.0, -41.0]
/// ];
///
/// // Compute QR decomposition with extended precision
/// let (q, r) = extended_qr::<_, f64>(&a.view()).unwrap();
///
/// // Check orthogonality of Q (Q^T * Q ≈ I)
/// let qt = q.t();
/// let qtq = qt.dot(&q);
/// for i in 0..q.nrows() {
///     for j in 0..q.ncols() {
///         if i == j {
///             assert!((qtq[[i, j]] - 1.0).abs() < 1e-5);
///         } else {
///             assert!(qtq[[i, j]].abs() < 1e-5);
///         }
///     }
/// }
///
/// // Check that A = Q*R
/// let qr = q.dot(&r);
/// for i in 0..a.nrows() {
///     for j in 0..a.ncols() {
///         assert!((a[[i, j]] - qr[[i, j]]).abs() < 1e-5);
///     }
/// }
/// ```
pub fn extended_qr<A, I>(a: &ArrayView2<A>) -> LinalgResult<(Array2<A>, Array2<A>)>
where
    A: Float + Zero + One + PromotableTo<I> + DemotableTo<A> + Copy,
    I: Float + Zero + One + DemotableTo<A> + Copy + PartialOrd,
{
    let m = a.nrows();
    let n = a.ncols();
    
    // Convert matrix to higher precision
    let mut a_high = Array2::zeros((m, n));
    for i in 0..m {
        for j in 0..n {
            a_high[[i, j]] = a[[i, j]].promote();
        }
    }
    
    // Initialize Q as identity matrix
    let mut q_high = Array2::zeros((m, m));
    for i in 0..m {
        q_high[[i, i]] = I::one();
    }
    
    // Apply Householder reflections
    for k in 0..std::cmp::min(m-1, n) {
        // Extract column vector
        let mut x = Array1::zeros(m - k);
        for i in k..m {
            x[i - k] = a_high[[i, k]];
        }
        
        // Compute Householder vector
        let norm_x = x.iter().map(|&val| val * val).sum::<I>().sqrt();
        let mut v = x.clone();
        
        let sign = if v[0] >= I::zero() { I::one() } else { -I::one() };
        v[0] = v[0] + sign * norm_x;
        
        let norm_v = v.iter().map(|&val| val * val).sum::<I>().sqrt();
        
        // Normalize v if it's not zero
        if norm_v > I::epsilon() {
            for i in 0..v.len() {
                v[i] = v[i] / norm_v;
            }
            
            // Apply Householder reflection to A
            for j in k..n {
                let mut dot_product = I::zero();
                for i in 0..v.len() {
                    dot_product += v[i] * a_high[[i + k, j]];
                }
                
                for i in 0..v.len() {
                    a_high[[i + k, j]] -= I::from(2.0).unwrap() * dot_product * v[i];
                }
            }
            
            // Apply Householder reflection to Q
            for j in 0..m {
                let mut dot_product = I::zero();
                for i in 0..v.len() {
                    dot_product += v[i] * q_high[[i + k, j]];
                }
                
                for i in 0..v.len() {
                    q_high[[i + k, j]] -= I::from(2.0).unwrap() * dot_product * v[i];
                }
            }
        }
    }
    
    // Transpose Q to get the orthogonal matrix (since we've been applying reflections from the right)
    let mut q_high_t = Array2::zeros((m, m));
    for i in 0..m {
        for j in 0..m {
            q_high_t[[i, j]] = q_high[[j, i]];
        }
    }
    
    // Zero out the lower triangular part of A to get R
    let mut r_high = a_high.clone();
    for i in 0..m {
        for j in 0..std::cmp::min(i, n) {
            r_high[[i, j]] = I::zero();
        }
    }
    
    // Convert results back to original precision
    let mut q = Array2::zeros((m, m));
    let mut r = Array2::zeros((m, n));
    
    for i in 0..m {
        for j in 0..m {
            q[[i, j]] = q_high_t[[i, j]].demote();
        }
    }
    
    for i in 0..m {
        for j in 0..n {
            r[[i, j]] = r_high[[i, j]].demote();
        }
    }
    
    Ok((q, r))
}

/// Cholesky decomposition using extended precision
///
/// This function computes the Cholesky decomposition of a symmetric positive definite matrix
/// using higher precision arithmetic for improved numerical stability.
///
/// # Parameters
///
/// * `a` - Input symmetric positive definite matrix
///
/// # Returns
///
/// * Lower triangular matrix L such that A = L * L^T
///
/// # Examples
///
/// ```
/// use ndarray::{array, ArrayView2};
/// use scirs2_linalg::extended_precision::factorizations::extended_cholesky;
///
/// let a = array![
///     [4.0_f32, 12.0, -16.0],
///     [12.0, 37.0, -43.0],
///     [-16.0, -43.0, 98.0]
/// ];
///
/// // Compute Cholesky decomposition with extended precision
/// let l = extended_cholesky::<_, f64>(&a.view()).unwrap();
///
/// // Check result: A ≈ L*L^T
/// let lt = l.t();
/// let llt = l.dot(&lt);
/// for i in 0..a.nrows() {
///     for j in 0..a.ncols() {
///         assert!((a[[i, j]] - llt[[i, j]]).abs() < 1e-5);
///     }
/// }
/// ```
pub fn extended_cholesky<A, I>(a: &ArrayView2<A>) -> LinalgResult<Array2<A>>
where
    A: Float + Zero + One + PromotableTo<I> + DemotableTo<A> + Copy,
    I: Float + Zero + One + DemotableTo<A> + Copy + PartialOrd,
{
    if a.nrows() != a.ncols() {
        return Err(crate::error::LinalgError::ShapeError(format!(
            "Expected square matrix, got shape {:?}",
            a.shape()
        )));
    }
    
    // Check symmetry
    let n = a.nrows();
    for i in 0..n {
        for j in i+1..n {
            if (a[[i, j]] - a[[j, i]]).abs() > A::epsilon() * A::from(10.0).unwrap() {
                return Err(crate::error::LinalgError::InvalidArgumentError(
                    "Matrix must be symmetric".to_string(),
                ));
            }
        }
    }
    
    // Convert matrix to higher precision
    let mut a_high = Array2::zeros((n, n));
    for i in 0..n {
        for j in 0..n {
            a_high[[i, j]] = a[[i, j]].promote();
        }
    }
    
    // Initialize the result matrix
    let mut l_high = Array2::zeros((n, n));
    
    // Compute Cholesky decomposition
    for j in 0..n {
        let mut d = a_high[[j, j]];
        
        for k in 0..j {
            d = d - l_high[[j, k]] * l_high[[j, k]];
        }
        
        if d <= I::zero() {
            return Err(crate::error::LinalgError::InvalidArgumentError(
                "Matrix is not positive definite".to_string(),
            ));
        }
        
        l_high[[j, j]] = d.sqrt();
        
        for i in j+1..n {
            let mut s = a_high[[i, j]];
            
            for k in 0..j {
                s = s - l_high[[i, k]] * l_high[[j, k]];
            }
            
            l_high[[i, j]] = s / l_high[[j, j]];
        }
    }
    
    // Convert result back to original precision
    let mut l = Array2::zeros((n, n));
    for i in 0..n {
        for j in 0..=i {  // Only copy the lower triangular part
            l[[i, j]] = l_high[[i, j]].demote();
        }
    }
    
    Ok(l)
}

/// Singular Value Decomposition (SVD) using extended precision
///
/// This function computes the SVD of a matrix using higher precision
/// arithmetic for improved numerical stability.
///
/// # Parameters
///
/// * `a` - Input matrix
/// * `full_matrices` - If true, returns full U and Vh matrices; if false, returns reduced matrices
/// * `max_iter` - Maximum number of iterations (default: 100)
/// * `tol` - Convergence tolerance (default: 1e-8 for the working precision)
///
/// # Returns
///
/// * Tuple containing (U, S, Vh) where:
///   - U is the left singular vectors
///   - S is the singular values
///   - Vh is the right singular vectors (transposed)
///
/// # Examples
///
/// ```
/// use ndarray::{array, ArrayView2};
/// use scirs2_linalg::extended_precision::factorizations::extended_svd;
///
/// let a = array![
///     [1.0_f32, 0.0, 0.0],
///     [0.0, 0.5, 0.0],
///     [0.0, 0.0, 0.2]
/// ];
///
/// // Compute SVD with extended precision
/// let (u, s, vh) = extended_svd::<_, f64>(&a.view(), true, None, None).unwrap();
///
/// // Check that singular values are correct
/// assert!((s[0] - 1.0).abs() < 1e-5);
/// assert!((s[1] - 0.5).abs() < 1e-5);
/// assert!((s[2] - 0.2).abs() < 1e-5);
/// ```
pub fn extended_svd<A, I>(
    a: &ArrayView2<A>,
    full_matrices: bool,
    max_iter: Option<usize>,
    tol: Option<A>,
) -> LinalgResult<(Array2<A>, Array1<A>, Array2<A>)>
where
    A: Float + Zero + One + PromotableTo<I> + DemotableTo<A> + Copy,
    I: Float + Zero + One + DemotableTo<A> + Copy + PartialOrd,
{
    // For this example, we'll implement a basic SVD using QR iteration
    // In practice, more advanced algorithms like divide-and-conquer would be used
    
    let m = a.nrows();
    let n = a.ncols();
    let k = std::cmp::min(m, n);
    
    let max_iter = max_iter.unwrap_or(100 * k);
    let tol = tol.unwrap_or(A::epsilon().sqrt());
    
    // Convert matrix to higher precision
    let mut a_high = Array2::zeros((m, n));
    for i in 0..m {
        for j in 0..n {
            a_high[[i, j]] = a[[i, j]].promote();
        }
    }
    
    // Compute A^T * A (for n ≤ m) or A * A^T (for m < n)
    let mut ata = if n <= m {
        let mut result = Array2::zeros((n, n));
        for i in 0..n {
            for j in 0..n {
                for l in 0..m {
                    result[[i, j]] += a_high[[l, i]] * a_high[[l, j]];
                }
            }
        }
        result
    } else {
        let mut result = Array2::zeros((m, m));
        for i in 0..m {
            for j in 0..m {
                for l in 0..n {
                    result[[i, j]] += a_high[[i, l]] * a_high[[j, l]];
                }
            }
        }
        result
    };
    
    // Apply QR algorithm to find eigenvalues and eigenvectors of A^T * A or A * A^T
    // This is a simplified approach; a full implementation would use a more sophisticated algorithm
    
    // Initialize eigenvectors as identity matrix
    let mut v_high = Array2::zeros((if n <= m { n } else { m }, if n <= m { n } else { m }));
    for i in 0..v_high.nrows() {
        v_high[[i, i]] = I::one();
    }
    
    for _ in 0..max_iter {
        // QR decomposition of current matrix
        let (q, r) = householder_qr_high_precision(&ata.view());
        
        // Update matrix: A = R * Q
        ata = r.dot(&q);
        
        // Update eigenvectors: V = V * Q
        v_high = v_high.dot(&q);
        
        // Check convergence (off-diagonal elements approaching zero)
        let mut converged = true;
        for i in 0..ata.nrows() {
            for j in 0..ata.ncols() {
                if i != j && ata[[i, j]].abs() > I::from(tol.promote()).unwrap() {
                    converged = false;
                    break;
                }
            }
            if !converged {
                break;
            }
        }
        
        if converged {
            break;
        }
    }
    
    // Extract singular values from diagonal of converged matrix
    let mut s_high = Array1::zeros(k);
    for i in 0..k {
        s_high[i] = ata[[i, i]].sqrt();
    }
    
    // Sort singular values and corresponding vectors
    let mut indices: Vec<usize> = (0..k).collect();
    indices.sort_by(|&i, &j| s_high[j].partial_cmp(&s_high[i]).unwrap());
    
    let mut sorted_s_high = Array1::zeros(k);
    let mut sorted_v_high = Array2::zeros((if n <= m { n } else { m }, k));
    
    for (idx, &i) in indices.iter().enumerate() {
        sorted_s_high[idx] = s_high[i];
        for j in 0..v_high.nrows() {
            sorted_v_high[[j, idx]] = v_high[[j, i]];
        }
    }
    
    // Compute U from V and singular values
    let mut u_high = if n <= m {
        let mut u = Array2::zeros((m, k));
        for j in 0..k {
            if sorted_s_high[j] > I::epsilon() {
                for i in 0..m {
                    for l in 0..n {
                        u[[i, j]] += a_high[[i, l]] * sorted_v_high[[l, j]] / sorted_s_high[j];
                    }
                }
            }
        }
        u
    } else {
        sorted_v_high.clone()
    };
    
    let mut vh_high = if n <= m {
        sorted_v_high.clone()
    } else {
        let mut vh = Array2::zeros((k, n));
        for j in 0..k {
            if sorted_s_high[j] > I::epsilon() {
                for i in 0..n {
                    for l in 0..m {
                        vh[[j, i]] += a_high[[l, i]] * sorted_v_high[[l, j]] / sorted_s_high[j];
                    }
                }
            }
        }
        vh
    };
    
    // If full_matrices is true, pad U and Vh appropriately
    if full_matrices {
        let mut u_full = Array2::zeros((m, m));
        let mut vh_full = Array2::zeros((n, n));
        
        for i in 0..m {
            for j in 0..std::cmp::min(m, k) {
                u_full[[i, j]] = u_high[[i, j]];
            }
        }
        
        for i in 0..std::cmp::min(n, k) {
            for j in 0..n {
                vh_full[[i, j]] = vh_high[[i, j]];
            }
        }
        
        // Orthogonalize remaining columns
        if m > k {
            // Orthogonalize remaining columns of U
            for j in k..m {
                let mut v = Array1::zeros(m);
                v[j] = I::one();
                
                for l in 0..j {
                    let mut dot_prod = I::zero();
                    for i in 0..m {
                        dot_prod += u_full[[i, l]] * v[i];
                    }
                    
                    for i in 0..m {
                        v[i] -= dot_prod * u_full[[i, l]];
                    }
                }
                
                let norm = v.iter().map(|&x| x * x).sum::<I>().sqrt();
                if norm > I::epsilon() {
                    for i in 0..m {
                        u_full[[i, j]] = v[i] / norm;
                    }
                }
            }
        }
        
        if n > k {
            // Orthogonalize remaining rows of Vh
            for i in k..n {
                let mut v = Array1::zeros(n);
                v[i] = I::one();
                
                for l in 0..i {
                    let mut dot_prod = I::zero();
                    for j in 0..n {
                        dot_prod += vh_full[[l, j]] * v[j];
                    }
                    
                    for j in 0..n {
                        v[j] -= dot_prod * vh_full[[l, j]];
                    }
                }
                
                let norm = v.iter().map(|&x| x * x).sum::<I>().sqrt();
                if norm > I::epsilon() {
                    for j in 0..n {
                        vh_full[[i, j]] = v[j] / norm;
                    }
                }
            }
        }
        
        u_high = u_full;
        vh_high = vh_full;
    }
    
    // Convert results back to original precision
    let mut u = Array2::zeros(u_high.dim());
    let mut s = Array1::zeros(k);
    let mut vh = Array2::zeros(vh_high.dim());
    
    for i in 0..u_high.nrows() {
        for j in 0..u_high.ncols() {
            u[[i, j]] = u_high[[i, j]].demote();
        }
    }
    
    for i in 0..k {
        s[i] = sorted_s_high[i].demote();
    }
    
    for i in 0..vh_high.nrows() {
        for j in 0..vh_high.ncols() {
            vh[[i, j]] = vh_high[[i, j]].demote();
        }
    }
    
    Ok((u, s, vh))
}

// Helper function for QR decomposition using Householder reflections
fn householder_qr_high_precision<I>(a: &ArrayView2<I>) -> (Array2<I>, Array2<I>)
where
    I: Float + Zero + One + Copy + PartialOrd,
{
    let m = a.nrows();
    let n = a.ncols();
    
    let mut q = Array2::eye(m);
    let mut r = a.to_owned();
    
    for k in 0..std::cmp::min(m-1, n) {
        // Extract column vector
        let mut x = Array1::zeros(m - k);
        for i in k..m {
            x[i - k] = r[[i, k]];
        }
        
        // Compute Householder vector
        let norm_x = x.iter().map(|&val| val * val).sum::<I>().sqrt();
        let mut v = x.clone();
        
        let sign = if v[0] >= I::zero() { I::one() } else { -I::one() };
        v[0] = v[0] + sign * norm_x;
        
        let norm_v = v.iter().map(|&val| val * val).sum::<I>().sqrt();
        
        // Normalize v if it's not zero
        if norm_v > I::epsilon() {
            for i in 0..v.len() {
                v[i] = v[i] / norm_v;
            }
            
            // Apply Householder reflection to R
            for j in k..n {
                let mut dot_product = I::zero();
                for i in 0..v.len() {
                    dot_product += v[i] * r[[i + k, j]];
                }
                
                for i in 0..v.len() {
                    r[[i + k, j]] -= I::from(2.0).unwrap() * dot_product * v[i];
                }
            }
            
            // Apply Householder reflection to Q
            for j in 0..m {
                let mut dot_product = I::zero();
                for i in 0..v.len() {
                    dot_product += v[i] * q[[j, i + k]];
                }
                
                for i in 0..v.len() {
                    q[[j, i + k]] -= I::from(2.0).unwrap() * dot_product * v[i];
                }
            }
        }
    }
    
    // Zero out the lower triangular part of R
    for i in 1..m {
        for j in 0..std::cmp::min(i, n) {
            r[[i, j]] = I::zero();
        }
    }
    
    // Transpose Q to get the orthogonal matrix
    let q_t = q.t().to_owned();
    
    (q_t, r)
}